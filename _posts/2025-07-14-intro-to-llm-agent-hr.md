---
title: "2025æœ€æ–°Pythonå¤§æ¨¡å‹Agentå¼€å‘å®æˆ˜ï¼šä»é›¶æ„å»ºHRæ™ºèƒ½æ‹›è˜åŠ©æ‰‹å®Œæ•´æ•™ç¨‹"
date: 2025-07-14
layout: post
comments: true
author_profile: true
mermaid: true
description: "è¶…è¯¦ç»†Pythonå¤§æ¨¡å‹Agentå¼€å‘æ•™ç¨‹ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ ç”¨LangChain+OpenAIæ„å»ºHRæ™ºèƒ½æ‹›è˜åŠ©æ‰‹ï¼ŒåŒ…å«å®Œæ•´ä»£ç ã€éƒ¨ç½²æ–¹æ¡ˆã€æ€§èƒ½ä¼˜åŒ–å’Œä¼ä¸šçº§æœ€ä½³å®è·µï¼Œé€‚åˆAIå¼€å‘è€…å’ŒHRç§‘æŠ€ä»ä¸šè€…"
keywords: "Pythonå¤§æ¨¡å‹Agentå¼€å‘,HRæ™ºèƒ½æ‹›è˜åŠ©æ‰‹,LangChainæ•™ç¨‹,OpenAI API,AI Agentå¼€å‘,PythonèŠå¤©æœºå™¨äºº,HRè‡ªåŠ¨åŒ–ç³»ç»Ÿ,LangChain Agent,å¤§è¯­è¨€æ¨¡å‹åº”ç”¨,ä¼ä¸šçº§AIéƒ¨ç½²"
categories: [äººå·¥æ™ºèƒ½å¼€å‘, HRæ•°å­—åŒ–è½¬å‹, Pythonæ•™ç¨‹, å¤§æ¨¡å‹åº”ç”¨]
tags: [å¤§è¯­è¨€æ¨¡å‹, Agentç³»ç»Ÿ, Pythonç¼–ç¨‹, HRç§‘æŠ€, LangChain, OpenAI, æ‹›è˜è‡ªåŠ¨åŒ–, æ™ºèƒ½å®¢æœ, ä¼ä¸šçº§AI, æœºå™¨å­¦ä¹ ]
og_image: "/assets/images/llm-agent-hr-seo-2025.png"
---

# Pythonå¤§æ¨¡å‹Agentå¼€å‘å®æˆ˜ï¼šæ„å»ºHRæ™ºèƒ½æ‹›è˜åŠ©æ‰‹å®Œæ•´æŒ‡å—ï¼ˆ2025æœ€æ–°ç‰ˆï¼‰

## ğŸ“‹ ç›®å½•å¯¼èˆª
- [ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹Agentï¼Ÿæ ¸å¿ƒæ¦‚å¿µè§£æ](#ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹agentæ ¸å¿ƒæ¦‚å¿µè§£æ)
- [HRé¢†åŸŸAI Agentåº”ç”¨åœºæ™¯ä¸å•†ä¸šä»·å€¼](#hré¢†åŸŸai-agentåº”ç”¨åœºæ™¯ä¸å•†ä¸šä»·å€¼)
- [ç¯å¢ƒå‡†å¤‡ï¼šPythonå¼€å‘ç¯å¢ƒæ­å»º](#ç¯å¢ƒå‡†å¤‡pythonå¼€å‘ç¯å¢ƒæ­å»º)
- [å®æˆ˜é¡¹ç›®1ï¼šåŸºç¡€HRé—®ç­”Agentå¼€å‘](#å®æˆ˜é¡¹ç›®1åŸºç¡€hré—®ç­”agentå¼€å‘)
- [å®æˆ˜é¡¹ç›®2ï¼šæ™ºèƒ½ç®€å†è§£æç³»ç»Ÿ](#å®æˆ˜é¡¹ç›®2æ™ºèƒ½ç®€å†è§£æç³»ç»Ÿ)
- [å®æˆ˜é¡¹ç›®3ï¼šå‘˜å·¥å…¥èŒåŠ©æ‰‹å®Œæ•´æ–¹æ¡ˆ](#å®æˆ˜é¡¹ç›®3å‘˜å·¥å…¥èŒåŠ©æ‰‹å®Œæ•´æ–¹æ¡ˆ)
- [ä¼ä¸šçº§éƒ¨ç½²æ¶æ„ä¸æ€§èƒ½ä¼˜åŒ–](#ä¼ä¸šçº§éƒ¨ç½²æ¶æ„ä¸æ€§èƒ½ä¼˜åŒ–)
- [å¸¸è§é—®é¢˜FAQä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜faqä¸è§£å†³æ–¹æ¡ˆ)
- [2025å¹´HR AI Agentå‘å±•è¶‹åŠ¿](#2025å¹´hr-ai-agentå‘å±•è¶‹åŠ¿)

## ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹Agentï¼Ÿæ ¸å¿ƒæ¦‚å¿µè§£æ

### ğŸ” Agentå®šä¹‰ä¸å·¥ä½œåŸç†
å¤§æ¨¡å‹Agentæ˜¯åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ç³»ç»Ÿï¼Œèƒ½å¤Ÿ**è‡ªä¸»ç†è§£ã€è§„åˆ’ã€æ‰§è¡Œå¤æ‚ä»»åŠ¡**ã€‚ç›¸æ¯”ä¼ ç»ŸèŠå¤©æœºå™¨äººï¼ŒAgentå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

<div class="mermaid">
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[æ„å›¾è¯†åˆ«]
    B --> C[ä»»åŠ¡è§„åˆ’]
    C --> D[å·¥å…·é€‰æ‹©]
    D --> E[æ‰§è¡Œæ“ä½œ]
    E --> F[ç»“æœæ•´åˆ]
    F --> G[ç”Ÿæˆå›å¤]
    
    H[è®°å¿†ç³»ç»Ÿ] --> B
    H --> C
    I[çŸ¥è¯†åº“] --> D
    I --> F
    
    style A fill:#e3f2fd,stroke:#1976d2
    style G fill:#e8f5e9,stroke:#388e3c
    style H fill:#fff3e0,stroke:#f57c00
    style I fill:#fce4ec,stroke:#c2185b
</div>

### Agentæ ¸å¿ƒç»„ä»¶æ¶æ„

<div class="mermaid">
classDiagram
    class LLMAgent {
        +model_name: str
        +temperature: float
        +max_tokens: int
        +execute_task(task): str
    }
    
    class ToolManager {
        +tools: List[Tool]
        +select_tool(query): Tool
        +execute_tool(tool, input): Any
    }
    
    class MemorySystem {
        +short_term: ConversationBuffer
        +long_term: VectorStore
        +store_interaction(data)
        +retrieve_context(query): str
    }
    
    class PlanningEngine {
        +decompose_task(task): List[str]
        +create_workflow(steps): Workflow
        +optimize_plan(plan): Plan
    }
    
    LLMAgent --> ToolManager : uses
    LLMAgent --> MemorySystem : uses
    LLMAgent --> PlanningEngine : uses
    ToolManager --> Tool : manages
    MemorySystem --> VectorStore : uses
</div>

### ä¸ä¼ ç»ŸèŠå¤©æœºå™¨äººçš„åŒºåˆ«

| ç‰¹æ€§å¯¹æ¯” | ä¼ ç»ŸèŠå¤©æœºå™¨äºº | å¤§æ¨¡å‹Agent |
|---------|---------------|-------------|
| **ç†è§£èƒ½åŠ›** | åŸºäºå…³é”®è¯åŒ¹é… | æ·±åº¦è¯­ä¹‰ç†è§£ |
| **ä»»åŠ¡å¤„ç†** | å•è½®é—®ç­” | å¤šæ­¥éª¤å¤æ‚ä»»åŠ¡ |
| **å·¥å…·ä½¿ç”¨** | æ— å¤–éƒ¨å·¥å…· | å¯è°ƒç”¨APIã€æ•°æ®åº“ |
| **è®°å¿†èƒ½åŠ›** | ä¼šè¯çº§è®°å¿† | é•¿æœŸè®°å¿†+ä¸Šä¸‹æ–‡ |
| **å­¦ä¹ ä¼˜åŒ–** | äººå·¥è§„åˆ™æ›´æ–° | è‡ªä¸»å­¦ä¹ å’Œä¼˜åŒ– |

## HRé¢†åŸŸAI Agentåº”ç”¨åœºæ™¯ä¸å•†ä¸šä»·å€¼

### ğŸ’¼ æ ¸å¿ƒåº”ç”¨åœºæ™¯åˆ†æ

<div class="mermaid">
graph LR
    subgraph æ™ºèƒ½æ‹›è˜è‡ªåŠ¨åŒ–
        A1[AIç®€å†ç­›é€‰] --> A2[æ™ºèƒ½é¢è¯•å®‰æ’]
        A2 --> A3[å€™é€‰äººè¯„ä¼°æŠ¥å‘Š]
        A3 --> A4[offerè‡ªåŠ¨ç”Ÿæˆ]
    end
    
    subgraph å‘˜å·¥æœåŠ¡æ™ºèƒ½åŒ–
        B1[24/7æ™ºèƒ½å®¢æœ] --> B2[æ”¿ç­–è‡ªåŠ¨è§£ç­”]
        B2 --> B3[ä¼‘å‡æµç¨‹è‡ªåŠ¨åŒ–]
        B3 --> B4[ç¦åˆ©æ™ºèƒ½æ¨è]
    end
    
    subgraph äººæ‰å‘å±•AI
        C1[æŠ€èƒ½å·®è·åˆ†æ] --> C2[ä¸ªæ€§åŒ–åŸ¹è®­è·¯å¾„]
        C2 --> C3[å­¦ä¹ æ•ˆæœè¯„ä¼°]
        C3 --> C4[èŒä¸šå‘å±•è§„åˆ’]
    end
    
    style A1 fill:#e8f5e9,stroke:#2e7d32
    style B1 fill:#e3f2fd,stroke:#1976d2
    style C1 fill:#fce4ec,stroke:#c218b5
</div>

### ğŸ“Š å®é™…å•†ä¸šä»·å€¼æ¡ˆä¾‹

**æŸå¤´éƒ¨äº’è”ç½‘å…¬å¸éƒ¨ç½²æ•ˆæœï¼š**
- **ç®€å†ç­›é€‰æ•ˆç‡æå‡85%**ï¼šä»æ¯å¤©å¤„ç†100ä»½æå‡è‡³1500ä»½
- **HRå“åº”æ—¶é—´ç¼©çŸ­90%**ï¼šä»å¹³å‡4å°æ—¶é™è‡³15åˆ†é’Ÿ
- **æ‹›è˜æˆæœ¬é™ä½40%**ï¼šå¹´åº¦èŠ‚çœäººåŠ›æˆæœ¬200ä¸‡+
- **å€™é€‰äººæ»¡æ„åº¦æå‡35%**ï¼š24/7å³æ—¶å“åº”ï¼Œä½“éªŒæ˜¾è‘—æ”¹å–„

## ç¯å¢ƒå‡†å¤‡ï¼šPythonå¼€å‘ç¯å¢ƒæ­å»º

### ğŸ› ï¸ ç³»ç»Ÿè¦æ±‚ä¸ä¾èµ–å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èPython 3.9+ï¼‰
python -m venv hr_agent_env
source hr_agent_env/bin/activate  # Linux/Mac
# hr_agent_env\Scripts\activate  # Windows

# å®‰è£…æ ¸å¿ƒä¾èµ–åŒ…
pip install langchain==0.2.0
pip install openai==1.30.0
pip install faiss-cpu==1.8.0
pip install python-dotenv==1.0.0
pip install streamlit==1.35.0
pip install chromadb==0.5.0
pip install pydantic==2.7.0

# å¯é€‰ï¼šGPUåŠ é€Ÿï¼ˆå¦‚æœ‰NVIDIAæ˜¾å¡ï¼‰
pip install faiss-gpu==1.8.0
```

### ğŸ” APIå¯†é’¥é…ç½®

åˆ›å»º`.env`æ–‡ä»¶ï¼š
```bash
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_API_KEY=your_google_search_api_key
GOOGLE_CSE_ID=your_custom_search_engine_id
```

## å®æˆ˜é¡¹ç›®1ï¼šåŸºç¡€HRé—®ç­”Agentå¼€å‘

### ğŸ¯ é¡¹ç›®ç›®æ ‡
æ„å»ºä¸€ä¸ªèƒ½å¤Ÿå›ç­”å…¬å¸HRæ”¿ç­–ç›¸å…³é—®é¢˜çš„æ™ºèƒ½Agentï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡è®°å¿†ã€‚

### ğŸ“‹ å®Œæ•´ä»£ç å®ç°

```python
import os
from typing import List, Dict
from dotenv import load_dotenv
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.utilities import GoogleSearchAPIWrapper

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class HRAgent:
    """HRæ™ºèƒ½é—®ç­”Agentæ ¸å¿ƒç±»"""
    
    def __init__(self, model_name: str = "gpt-4-turbo-preview"):
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0.1,
            max_tokens=1000,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="output"
        )
        self.tools = self._setup_tools()
        self.agent = self._create_agent()
    
    def _setup_tools(self) -> List[Tool]:
        """é…ç½®Agentå·¥å…·é›†"""
        
        # Googleæœç´¢å·¥å…·ï¼ˆç”¨äºå®æ—¶ä¿¡æ¯ï¼‰
        search = GoogleSearchAPIWrapper(
            google_api_key=os.getenv("GOOGLE_API_KEY"),
            google_cse_id=os.getenv("GOOGLE_CSE_ID")
        )
        
        # è‡ªå®šä¹‰HRæ”¿ç­–æŸ¥è¯¢å·¥å…·
        def query_hr_policy(question: str) -> str:
            """æŸ¥è¯¢å…¬å¸HRæ”¿ç­–"""
            # è¿™é‡Œå¯ä»¥è¿æ¥å®é™…çš„å…¬å¸æ”¿ç­–æ•°æ®åº“
            policies = {
                "å¹´å‡": "å‘˜å·¥äº«æœ‰15å¤©å¸¦è–ªå¹´å‡ï¼Œå·¥ä½œæ»¡3å¹´å¢åŠ 1å¤©ï¼Œæœ€å¤š20å¤©",
                "ç—…å‡": "æ¯å¹´äº«æœ‰12å¤©å¸¦è–ªç—…å‡ï¼Œéœ€æä¾›åŒ»ç–—è¯æ˜",
                "å¼¹æ€§å·¥ä½œ": "æ ¸å¿ƒå·¥ä½œæ—¶é—´10:00-16:00ï¼Œå…¶ä½™æ—¶é—´å¼¹æ€§å®‰æ’",
                "è¿œç¨‹åŠå…¬": "æ¯å‘¨å¯ç”³è¯·2å¤©è¿œç¨‹åŠå…¬ï¼Œéœ€æå‰1å¤©ç”³è¯·"
            }
            
            for key, value in policies.items():
                if key in question:
                    return f"{key}æ”¿ç­–ï¼š{value}"
            
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚å»ºè®®æ‚¨ç›´æ¥è”ç³»HRéƒ¨é—¨ï¼šhr@company.com"
        
        # åˆ›å»ºå·¥å…·åˆ—è¡¨
        tools = [
            Tool(
                name="HR_Policy_Query",
                func=query_hr_policy,
                description="æŸ¥è¯¢å…¬å¸HRæ”¿ç­–ï¼ŒåŒ…æ‹¬å¹´å‡ã€ç—…å‡ã€å¼¹æ€§å·¥ä½œç­‰ç›¸å…³è§„å®š"
            ),
            Tool(
                name="Google_Search",
                func=search.run,
                description="æœç´¢æœ€æ–°çš„åŠ³åŠ¨æ³•è§„å’Œè¡Œä¸šæœ€ä½³å®è·µ"
            )
        ]
        
        return tools
    
    def _create_agent(self):
        """åˆ›å»ºAgentå®ä¾‹"""
        
        # è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
        prefix = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HRæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”å‘˜å·¥å…³äºå…¬å¸æ”¿ç­–ã€ç¦åˆ©å¾…é‡ã€å·¥ä½œæµç¨‹ç­‰é—®é¢˜ã€‚
        ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨ï¼š
        - HR_Policy_Query: æŸ¥è¯¢å…¬å¸å†…éƒ¨HRæ”¿ç­–
        - Google_Search: æœç´¢æœ€æ–°åŠ³åŠ¨æ³•è§„
        
        è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€å‹å¥½çš„æ€åº¦ï¼Œæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯ã€‚
        å¦‚æœæ— æ³•å›ç­”æŸä¸ªé—®é¢˜ï¼Œè¯·å»ºè®®ç”¨æˆ·è”ç³»HRéƒ¨é—¨ã€‚"""
        
        return initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.memory,
            verbose=True,
            max_iterations=3,
            early_stopping_method="generate",
            agent_kwargs={
                "prefix": prefix,
                "format_instructions": "è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚"
            }
        )
    
    def chat(self, message: str) -> str:
        """ä¸ç”¨æˆ·è¿›è¡Œå¯¹è¯"""
        try:
            response = self.agent.run(message)
            return response
        except Exception as e:
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ï¼š{str(e)}"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–HR Agent
    hr_bot = HRAgent()
    
    # æµ‹è¯•å¯¹è¯
    questions = [
        "è¯·é—®å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯æ€æ ·çš„ï¼Ÿ",
        "æˆ‘å¯ä»¥ç”³è¯·è¿œç¨‹åŠå…¬å—ï¼Ÿ",
        "å¦‚æœç”Ÿç—…äº†ï¼Œç—…å‡æ€ä¹ˆè®¡ç®—ï¼Ÿ"
    ]
    
    for question in questions:
        print(f"ç”¨æˆ·ï¼š{question}")
        response = hr_bot.chat(question)
        print(f"HRåŠ©æ‰‹ï¼š{response}")
        print("-" * 50)
```

### ğŸš€ è¿è¡Œæ•ˆæœå±•ç¤º

```bash
$ python hr_qa_agent.py

ç”¨æˆ·ï¼šè¯·é—®å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯æ€æ ·çš„ï¼Ÿ
HRåŠ©æ‰‹ï¼šæ ¹æ®å…¬å¸æ”¿ç­–ï¼Œå‘˜å·¥äº«æœ‰15å¤©å¸¦è–ªå¹´å‡ï¼Œå·¥ä½œæ»¡3å¹´å¢åŠ 1å¤©ï¼Œæœ€å¤š20å¤©ã€‚
--------------------------------------------------
ç”¨æˆ·ï¼šæˆ‘å¯ä»¥ç”³è¯·è¿œç¨‹åŠå…¬å—ï¼Ÿ
HRåŠ©æ‰‹ï¼šå¯ä»¥çš„ï¼å…¬å¸æ”¯æŒè¿œç¨‹åŠå…¬æ”¿ç­–ï¼šæ¯å‘¨å¯ç”³è¯·2å¤©è¿œç¨‹åŠå…¬ï¼Œéœ€æå‰1å¤©ç”³è¯·ã€‚
--------------------------------------------------
ç”¨æˆ·ï¼šå¦‚æœç”Ÿç—…äº†ï¼Œç—…å‡æ€ä¹ˆè®¡ç®—ï¼Ÿ
HRåŠ©æ‰‹ï¼šç—…å‡æ”¿ç­–ï¼šæ¯å¹´äº«æœ‰12å¤©å¸¦è–ªç—…å‡ï¼Œéœ€æä¾›åŒ»ç–—è¯æ˜ã€‚
```

## å®æˆ˜é¡¹ç›®2ï¼šæ™ºèƒ½ç®€å†è§£æç³»ç»Ÿ

### ğŸ¯ é¡¹ç›®ç›®æ ‡
å¼€å‘ä¸€ä¸ªèƒ½å¤Ÿè‡ªåŠ¨è§£æç®€å†ã€æå–å…³é”®ä¿¡æ¯ã€è¯„ä¼°å€™é€‰äººåŒ¹é…åº¦çš„æ™ºèƒ½ç³»ç»Ÿã€‚

### ğŸ“‹ ç³»ç»Ÿæ¶æ„è®¾è®¡

<div class="mermaid">
graph TD
    A[PDF/Wordç®€å†ä¸Šä¼ ] --> B[æ–‡æ¡£è§£æå¼•æ“]
    B --> C[ä¿¡æ¯æå–NLP]
    C --> D[æŠ€èƒ½å…³é”®è¯åŒ¹é…]
    D --> E[å€™é€‰äººè¯„åˆ†]
    E --> F[ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š]
    
    G[èŒä½éœ€æ±‚åº“] --> D
    H[æŠ€èƒ½è¯å…¸] --> C
    
    style A fill:#e3f2fd,stroke:#1976d2
    style F fill:#e8f5e9,stroke:#388e3c
    style G fill:#fff3e0,stroke:#f57c00
</div>

### ğŸ“„ å®Œæ•´ä»£ç å®ç°

```python
import re
import json
import PyPDF2
from typing import Dict, List, Optional
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import pandas as pd

@dataclass
class ResumeInfo:
    """ç®€å†ä¿¡æ¯æ•°æ®ç»“æ„"""
    name: str = ""
    email: str = ""
    phone: str = ""
    skills: List[str] = None
    experience: List[Dict] = None
    education: List[Dict] = None
    summary: str = ""
    score: float = 0.0
    
    def __post_init__(self):
        if self.skills is None:
            self.skills = []
        if self.experience is None:
            self.experience = []
        if self.education is None:
            self.education = []

class ResumeParser:
    """æ™ºèƒ½ç®€å†è§£æå™¨"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.1)
        self.skill_keywords = self._load_skill_keywords()
    
    def _load_skill_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½æŠ€èƒ½å…³é”®è¯è¯å…¸"""
        return {
            "python": ["Python", "Django", "Flask", "FastAPI", "Pandas", "NumPy"],
            "javascript": ["JavaScript", "React", "Vue.js", "Node.js", "TypeScript"],
            "data_science": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "æ•°æ®åˆ†æ", "æ•°æ®æŒ–æ˜", "TensorFlow", "PyTorch"],
            "cloud": ["AWS", "Azure", "GCP", "Docker", "Kubernetes", "å¾®æœåŠ¡"],
            "database": ["MySQL", "PostgreSQL", "MongoDB", "Redis", "Elasticsearch"]
        }
    
    def parse_pdf(self, file_path: str) -> str:
        """è§£æPDFç®€å†"""
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text()
                return text
        except Exception as e:
            raise Exception(f"PDFè§£æå¤±è´¥: {str(e)}")
    
    def extract_info(self, resume_text: str) -> ResumeInfo:
        """ä½¿ç”¨LLMæå–ç®€å†ä¿¡æ¯"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†è§£æä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹ç®€å†æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ã€‚
            éœ€è¦æå–çš„ä¿¡æ¯åŒ…æ‹¬ï¼š
            - name: å€™é€‰äººå§“å
            - email: é‚®ç®±åœ°å€
            - phone: ç”µè¯å·ç 
            - skills: æŠ€èƒ½åˆ—è¡¨
            - experience: å·¥ä½œç»å†ï¼ˆå…¬å¸ã€èŒä½ã€æ—¶é—´ã€æè¿°ï¼‰
            - education: æ•™è‚²èƒŒæ™¯ï¼ˆå­¦æ ¡ã€ä¸“ä¸šã€å­¦å†ã€æ—¶é—´ï¼‰
            - summary: ä¸ªäººç®€ä»‹
            
            è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"""),
            ("human", "{resume_text}")
        ])
        
        chain = prompt | self.llm
        response = chain.invoke({"resume_text": resume_text})
        
        try:
            data = json.loads(response.content)
            return ResumeInfo(**data)
        except:
            # å¤‡ç”¨è§£ææ–¹æ¡ˆï¼šæ­£åˆ™è¡¨è¾¾å¼
            return self._fallback_parse(resume_text)
    
    def _fallback_parse(self, text: str) -> ResumeInfo:
        """å¤‡ç”¨è§£ææ–¹æ¡ˆï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰"""
        info = ResumeInfo()
        
        # æå–é‚®ç®±
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_match = re.search(email_pattern, text)
        if email_match:
            info.email = email_match.group()
        
        # æå–ç”µè¯
        phone_pattern = r'(\+?\d{1,3}[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}'
        phone_match = re.search(phone_pattern, text)
        if phone_match:
            info.phone = phone_match.group()
        
        # æå–æŠ€èƒ½ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰
        for category, keywords in self.skill_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text.lower():
                    info.skills.append(keyword)
        
        info.skills = list(set(info.skills))  # å»é‡
        return info
    
    def evaluate_candidate(self, resume_info: ResumeInfo, job_requirements: Dict) -> Dict:
        """è¯„ä¼°å€™é€‰äººä¸èŒä½çš„åŒ¹é…åº¦"""
        
        score = 0.0
        feedback = []
        
        # æŠ€èƒ½åŒ¹é…åº¦è®¡ç®—
        required_skills = set(job_requirements.get("skills", []))
        candidate_skills = set(resume_info.skills)
        
        if required_skills:
            skill_match = len(required_skills.intersection(candidate_skills)) / len(required_skills)
            score += skill_match * 40  # æŠ€èƒ½å 40åˆ†
            feedback.append(f"æŠ€èƒ½åŒ¹é…åº¦: {skill_match*100:.1f}%")
        
        # ç»éªŒåŒ¹é…åº¦è®¡ç®—
        required_exp = job_requirements.get("experience_years", 0)
        actual_exp = sum([exp.get("years", 0) for exp in resume_info.experience])
        
        if actual_exp >= required_exp:
            score += 30  # ç»éªŒå 30åˆ†
            feedback.append(f"ç»éªŒåŒ¹é…: {actual_exp}å¹´ï¼ˆè¦æ±‚{required_exp}å¹´ï¼‰")
        else:
            exp_ratio = actual_exp / required_exp if required_exp > 0 else 0
            score += exp_ratio * 30
            feedback.append(f"ç»éªŒä¸è¶³: {actual_exp}å¹´ï¼ˆè¦æ±‚{required_exp}å¹´ï¼‰")
        
        # æ•™è‚²èƒŒæ™¯åŒ¹é…
        required_degree = job_requirements.get("education", "").lower()
        candidate_degrees = [edu.get("degree", "").lower() for edu in resume_info.education]
        
        if any(required_degree in deg for deg in candidate_degrees):
            score += 20
            feedback.append("å­¦å†åŒ¹é…")
        else:
            feedback.append("å­¦å†ä¸åŒ¹é…")
        
        # ä¸ªäººç®€ä»‹è´¨é‡è¯„ä¼°
        if len(resume_info.summary) > 100:
            score += 10
            feedback.append("ä¸ªäººç®€ä»‹å®Œæ•´")
        
        resume_info.score = min(score, 100)
        
        return {
            "score": resume_info.score,
            "feedback": feedback,
            "recommendation": "æ¨èé¢è¯•" if resume_info.score >= 70 else "ä¸æ¨è"
        }

class ResumeProcessor:
    """æ‰¹é‡ç®€å†å¤„ç†å™¨"""
    
    def __init__(self):
        self.parser = ResumeParser()
    
    def process_batch(self, resume_folder: str, job_requirements: Dict) -> pd.DataFrame:
        """æ‰¹é‡å¤„ç†ç®€å†æ–‡ä»¶å¤¹"""
        results = []
        
        import os
        for filename in os.listdir(resume_folder):
            if filename.endswith(('.pdf', '.docx')):
                file_path = os.path.join(resume_folder, filename)
                
                try:
                    # è§£æç®€å†
                    if filename.endswith('.pdf'):
                        text = self.parser.parse_pdf(file_path)
                    else:
                        # å¤„ç†Wordæ–‡æ¡£
                        import docx
                        doc = docx.Document(file_path)
                        text = "\n".join([para.text for para in doc.paragraphs])
                    
                    # æå–ä¿¡æ¯
                    resume_info = self.parser.extract_info(text)
                    
                    # è¯„ä¼°åŒ¹é…åº¦
                    evaluation = self.parser.evaluate_candidate(resume_info, job_requirements)
                    
                    # ä¿å­˜ç»“æœ
                    results.append({
                        "filename": filename,
                        "name": resume_info.name,
                        "email": resume_info.email,
                        "skills": ", ".join(resume_info.skills),
                        "score": evaluation["score"],
                        "recommendation": evaluation["recommendation"],
                        "feedback": "; ".join(evaluation["feedback"])
                    })
                    
                except Exception as e:
                    results.append({
                        "filename": filename,
                        "error": str(e)
                    })
        
        return pd.DataFrame(results)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # èŒä½è¦æ±‚é…ç½®
    job_requirements = {
        "skills": ["Python", "æœºå™¨å­¦ä¹ ", "æ•°æ®åˆ†æ", "SQL"],
        "experience_years": 3,
        "education": "æœ¬ç§‘"
    }
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ResumeProcessor()
    
    # æ‰¹é‡å¤„ç†ç®€å†
    results_df = processor.process_batch("resumes/", job_requirements)
    
    # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
    results_df = results_df.sort_values("score", ascending=False)
    print(results_df[["filename", "name", "score", "recommendation"]])
    
    # ä¿å­˜ç»“æœåˆ°Excel
    results_df.to_excel("resume_evaluation_results.xlsx", index=False)
```

### ğŸ“Š è¿è¡Œæ•ˆæœç¤ºä¾‹

```bash
$ python resume_parser.py

ç®€å†è¯„ä¼°ç»“æœï¼š
            filename        name  score recommendation
0     zhang_san.pdf      å¼ ä¸‰   85.0         æ¨èé¢è¯•
1     li_si_resume.pdf    æå››   72.0         æ¨èé¢è¯•
2     wang_wu.pdf        ç‹äº”   65.0         ä¸æ¨è
3     zhao_liu.docx      èµµå…­   45.0         ä¸æ¨è
```

## å®æˆ˜é¡¹ç›®3ï¼šå‘˜å·¥å…¥èŒåŠ©æ‰‹å®Œæ•´æ–¹æ¡ˆ

### ğŸ¯ é¡¹ç›®ç›®æ ‡
æ„å»ºä¸€ä¸ªå…¨æµç¨‹çš„å‘˜å·¥å…¥èŒè‡ªåŠ¨åŒ–åŠ©æ‰‹ï¼Œä»offeræ¥å—åˆ°æ­£å¼å…¥èŒçš„å®Œæ•´å¼•å¯¼ç³»ç»Ÿã€‚

### ğŸ—ï¸ ç³»ç»ŸåŠŸèƒ½æ¨¡å—

<div class="mermaid">
graph TD
    A[Offeræ¥å—ç¡®è®¤] --> B[å…¥èŒææ–™æ¸…å•]
    B --> C[è´¦å·æƒé™ç”³è¯·]
    C --> D[åŠå…¬è®¾å¤‡é¢„è®¢]
    D --> E[å…¥èŒåŸ¹è®­å®‰æ’]
    E --> F[å¯¼å¸ˆåŒ¹é…]
    F --> G[å…¥èŒæ—¥æé†’]
    
    H[HRç³»ç»Ÿ] --> A
    I[ITç³»ç»Ÿ] --> C
    J[è¡Œæ”¿éƒ¨é—¨] --> D
    
    style A fill:#e3f2fd,stroke:#1976d2
    style G fill:#e8f5e9,stroke:#388e3c
</div>

### ğŸ“‹ å®Œæ•´ä»£ç å®ç°

```python
import datetime
from typing import Dict, List
from dataclasses import dataclass
from enum import Enum
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class OnboardingStatus(Enum):
    """å…¥èŒçŠ¶æ€æšä¸¾"""
    OFFER_ACCEPTED = "offer_accepted"
    DOCUMENTS_PENDING = "documents_pending"
    IT_SETUP = "it_setup"
    EQUIPMENT_READY = "equipment_ready"
    TRAINING_SCHEDULED = "training_scheduled"
    MENTOR_ASSIGNED = "mentor_assigned"
    COMPLETED = "completed"

@dataclass
class Employee:
    """å‘˜å·¥ä¿¡æ¯æ•°æ®ç»“æ„"""
    name: str
    email: str
    position: str
    department: str
    start_date: datetime.date
    employee_id: str = ""
    status: OnboardingStatus = OnboardingStatus.OFFER_ACCEPTED
    documents: List[str] = None
    equipment: List[str] = None
    training_schedule: Dict = None
    mentor: str = ""

class OnboardingAssistant:
    """å‘˜å·¥å…¥èŒæ™ºèƒ½åŠ©æ‰‹"""
    
    def __init__(self):
        self.employees = {}
        self.checklist_template = self._load_checklist_template()
        self.email_templates = self._load_email_templates()
    
    def _load_checklist_template(self) -> Dict:
        """åŠ è½½å…¥èŒæ¸…å•æ¨¡æ¿"""
        return {
            "documents": [
                "èº«ä»½è¯å¤å°ä»¶",
                "å­¦å†è¯ä¹¦å¤å°ä»¶",
                "ç¦»èŒè¯æ˜",
                "é“¶è¡Œå¡ä¿¡æ¯",
                "ç¤¾ä¿å…¬ç§¯é‡‘è½¬ç§»å•",
                "ä½“æ£€æŠ¥å‘Š"
            ],
            "equipment": [
                "ç¬”è®°æœ¬ç”µè„‘",
                "æ˜¾ç¤ºå™¨",
                "é”®ç›˜é¼ æ ‡",
                "å·¥ä½å®‰æ’",
                "é—¨ç¦å¡",
                "ä¼ä¸šé‚®ç®±"
            ],
            "accounts": [
                "ä¼ä¸šé‚®ç®±",
                "VPNè´¦å·",
                "GitLabæƒé™",
                "Jiraè´¦å·",
                "Confluenceæƒé™",
                "HRç³»ç»Ÿæƒé™"
            ]
        }
    
    def _load_email_templates(self) -> Dict:
        """åŠ è½½é‚®ä»¶æ¨¡æ¿"""
        return {
            "welcome": """
            äº²çˆ±çš„{name}ï¼Œ
            
            æ¬¢è¿åŠ å…¥{company}ï¼æˆ‘ä»¬å¾ˆé«˜å…´ä½ æˆä¸ºæˆ‘ä»¬å›¢é˜Ÿçš„ä¸€å‘˜ã€‚
            
            ä½ çš„å…¥èŒæ—¥æœŸæ˜¯ï¼š{start_date}
            èŒä½ï¼š{position}
            éƒ¨é—¨ï¼š{department}
            
            æ¥ä¸‹æ¥æˆ‘ä¼šååŠ©ä½ å®Œæˆå…¥èŒæµç¨‹ï¼Œè¯·éšæ—¶å‘æˆ‘æé—®ã€‚
            
            ç¥å¥½ï¼
            HRå…¥èŒåŠ©æ‰‹
            """,
            "documents_reminder": """
            {name}ï¼Œä½ å¥½ï¼
            
            è¯·å‡†å¤‡ä»¥ä¸‹å…¥èŒææ–™ï¼š
            {documents_list}
            
            è¯·åœ¨å…¥èŒå‰3å¤©æäº¤è¿™äº›ææ–™ã€‚
            """,
            "it_setup": """
            ITéƒ¨é—¨æ­£åœ¨ä¸º{name}å‡†å¤‡ï¼š
            {equipment_list}
            
            é¢„è®¡å®Œæˆæ—¶é—´ï¼š{completion_date}
            """
        }
    
    def register_employee(self, employee: Employee):
        """æ³¨å†Œæ–°å‘˜å·¥"""
        self.employees[employee.email] = employee
        self._send_welcome_email(employee)
        self._create_onboarding_plan(employee)
    
    def _send_welcome_email(self, employee: Employee):
        """å‘é€æ¬¢è¿é‚®ä»¶"""
        template = self.email_templates["welcome"]
        content = template.format(
            name=employee.name,
            company="ABCç§‘æŠ€æœ‰é™å…¬å¸",
            start_date=employee.start_date.strftime("%Y-%m-%d"),
            position=employee.position,
            department=employee.department
        )
        
        self._send_email(employee.email, "æ¬¢è¿åŠ å…¥ABCç§‘æŠ€ï¼", content)
    
    def _create_onboarding_plan(self, employee: Employee):
        """åˆ›å»ºä¸ªæ€§åŒ–å…¥èŒè®¡åˆ’"""
        start_date = employee.start_date
        
        plan = {
            "day_-7": {
                "task": "æäº¤å…¥èŒææ–™",
                "description": "å‡†å¤‡å¹¶æäº¤æ‰€æœ‰å¿…éœ€çš„å…¥èŒæ–‡ä»¶",
                "status": "pending"
            },
            "day_-5": {
                "task": "ITè®¾å¤‡å‡†å¤‡",
                "description": "ITéƒ¨é—¨å‡†å¤‡ç”µè„‘ã€è´¦å·ç­‰",
                "status": "pending"
            },
            "day_-3": {
                "task": "å…¥èŒåŸ¹è®­å®‰æ’",
                "description": "å®‰æ’å…¥èŒåŸ¹è®­è¯¾ç¨‹",
                "status": "pending"
            },
            "day_-1": {
                "task": "æœ€ç»ˆç¡®è®¤",
                "description": "ç¡®è®¤æ‰€æœ‰å‡†å¤‡å·¥ä½œå®Œæˆ",
                "status": "pending"
            },
            "day_0": {
                "task": "æ­£å¼å…¥èŒ",
                "description": "ç¬¬ä¸€å¤©å…¥èŒå¼•å¯¼",
                "status": "pending"
            }
        }
        
        return plan
    
    def get_next_action(self, employee_email: str) -> Dict:
        """è·å–ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®"""
        employee = self.employees.get(employee_email)
        if not employee:
            return {"error": "å‘˜å·¥æœªæ‰¾åˆ°"}
        
        # æ ¹æ®å½“å‰çŠ¶æ€æ¨èä¸‹ä¸€æ­¥
        if employee.status == OnboardingStatus.OFFER_ACCEPTED:
            return {
                "action": "æäº¤å…¥èŒææ–™",
                "description": "è¯·å‡†å¤‡ä»¥ä¸‹ææ–™ï¼š",
                "items": self.checklist_template["documents"],
                "deadline": (employee.start_date - datetime.timedelta(days=7)).strftime("%Y-%m-%d")
            }
        
        elif employee.status == OnboardingStatus.DOCUMENTS_PENDING:
            return {
                "action": "ç­‰å¾…ææ–™å®¡æ ¸",
                "description": "HRæ­£åœ¨å®¡æ ¸æ‚¨æäº¤çš„ææ–™",
                "estimated_time": "1-2ä¸ªå·¥ä½œæ—¥"
            }
        
        elif employee.status == OnboardingStatus.IT_SETUP:
            return {
                "action": "ITè®¾å¤‡å‡†å¤‡ä¸­",
                "description": "ITéƒ¨é—¨æ­£åœ¨å‡†å¤‡æ‚¨çš„è®¾å¤‡",
                "equipment": self.checklist_template["equipment"]
            }
        
        return {"action": "æ‰€æœ‰å‡†å¤‡å°±ç»ª", "message": "æœŸå¾…æ‚¨çš„åŠ å…¥ï¼"}
    
    def send_reminder(self, employee_email: str):
        """å‘é€æé†’é‚®ä»¶"""
        employee = self.employees.get(employee_email)
        if not employee:
            return
        
        next_action = self.get_next_action(employee_email)
        
        if next_action["action"] == "æäº¤å…¥èŒææ–™":
            template = self.email_templates["documents_reminder"]
            content = template.format(
                name=employee.name,
                documents_list="\n".join([f"- {doc}" for doc in next_action["items"]])
            )
            self._send_email(employee.email, "å…¥èŒææ–™å‡†å¤‡æé†’", content)
    
    def _send_email(self, to_email: str, subject: str, content: str):
        """å‘é€é‚®ä»¶ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        # å®é™…é¡¹ç›®ä¸­éœ€è¦é…ç½®SMTPæœåŠ¡å™¨
        print(f"å‘é€é‚®ä»¶åˆ°ï¼š{to_email}")
        print(f"ä¸»é¢˜ï¼š{subject}")
        print(f"å†…å®¹ï¼š{content}")
        print("-" * 50)
    
    def generate_onboarding_report(self, employee_email: str) -> Dict:
        """ç”Ÿæˆå…¥èŒè¿›åº¦æŠ¥å‘Š"""
        employee = self.employees.get(employee_email)
        if not employee:
            return {"error": "å‘˜å·¥æœªæ‰¾åˆ°"}
        
        return {
            "employee_name": employee.name,
            "current_status": employee.status.value,
            "days_until_start": (employee.start_date - datetime.date.today()).days,
            "completed_tasks": self._get_completed_tasks(employee),
            "pending_tasks": self._get_pending_tasks(employee),
            "overall_progress": self._calculate_progress(employee)
        }
    
    def _get_completed_tasks(self, employee: Employee) -> List[str]:
        """è·å–å·²å®Œæˆçš„ä»»åŠ¡"""
        # æ ¹æ®çŠ¶æ€è¿”å›å·²å®Œæˆçš„ä»»åŠ¡
        completed = []
        if employee.status.value in ["documents_pending", "it_setup", "equipment_ready", "training_scheduled", "mentor_assigned", "completed"]:
            completed.append("Offeræ¥å—ç¡®è®¤")
        return completed
    
    def _get_pending_tasks(self, employee: Employee) -> List[str]:
        """è·å–å¾…å®Œæˆçš„ä»»åŠ¡"""
        pending = []
        if employee.status == OnboardingStatus.OFFER_ACCEPTED:
            pending.extend(["æäº¤å…¥èŒææ–™", "ææ–™å®¡æ ¸"])
        return pending
    
    def _calculate_progress(self, employee: Employee) -> float:
        """è®¡ç®—å…¥èŒè¿›åº¦ç™¾åˆ†æ¯”"""
        status_order = [
            OnboardingStatus.OFFER_ACCEPTED,
            OnboardingStatus.DOCUMENTS_PENDING,
            OnboardingStatus.IT_SETUP,
            OnboardingStatus.EQUIPMENT_READY,
            OnboardingStatus.TRAINING_SCHEDULED,
            OnboardingStatus.MENTOR_ASSIGNED,
            OnboardingStatus.COMPLETED
        ]
        
        current_index = status_order.index(employee.status)
        return (current_index + 1) / len(status_order) * 100

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–å…¥èŒåŠ©æ‰‹
    assistant = OnboardingAssistant()
    
    # åˆ›å»ºæ–°å‘˜å·¥
    new_employee = Employee(
        name="ææ˜",
        email="liming@example.com",
        position="é«˜çº§Pythonå·¥ç¨‹å¸ˆ",
        department="æŠ€æœ¯éƒ¨",
        start_date=datetime.date(2025, 8, 1)
    )
    
    # æ³¨å†Œå‘˜å·¥
    assistant.register_employee(new_employee)
    
    # è·å–ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    next_action = assistant.get_next_action("liming@example.com")
    print("ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š", next_action)
    
    # ç”Ÿæˆè¿›åº¦æŠ¥å‘Š
    report = assistant.generate_onboarding_report("liming@example.com")
    print("å…¥èŒè¿›åº¦æŠ¥å‘Šï¼š", report)
```

## ä¼ä¸šçº§éƒ¨ç½²æ¶æ„ä¸æ€§èƒ½ä¼˜åŒ–

### ğŸ—ï¸ å¾®æœåŠ¡æ¶æ„è®¾è®¡

<div class="mermaid">
graph TB
    subgraph å‰ç«¯å±‚
        A[Webç•Œé¢] --> B[ç§»åŠ¨ç«¯App]
        B --> C[å°ç¨‹åº]
    end
    
    subgraph APIç½‘å…³
        D[Nginxè´Ÿè½½å‡è¡¡]
        E[API Gateway]
    end
    
    subgraph æœåŠ¡å±‚
        F[HRé—®ç­”æœåŠ¡]
        G[ç®€å†è§£ææœåŠ¡]
        H[å…¥èŒåŠ©æ‰‹æœåŠ¡]
        I[ç”¨æˆ·ç®¡ç†æœåŠ¡]
    end
    
    subgraph æ•°æ®å±‚
        J[PostgreSQL]
        K[Redisç¼“å­˜]
        L[Elasticsearch]
        M[MinIOæ–‡ä»¶å­˜å‚¨]
    end
    
    subgraph AIæ¨¡å‹å±‚
        N[OpenAI API]
        O[æœ¬åœ°æ¨¡å‹æœåŠ¡]
        P[å‘é‡æ•°æ®åº“]
    end
    
    A --> D
    D --> E
    E --> F
    E --> G
    E --> H
    E --> I
    
    F --> J
    G --> M
    H --> K
    I --> J
    
    F --> N
    G --> O
    H --> P
</div>

### ğŸ“Š æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 1. ç¼“å­˜ä¼˜åŒ–
```python
import redis
from functools import wraps
import hashlib
import json

class CacheManager:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
    
    def cache_result(self, expiration=3600):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜key
                cache_key = self._generate_key(func.__name__, args, kwargs)
                
                # å°è¯•ä»ç¼“å­˜è·å–
                cached = self.redis_client.get(cache_key)
                if cached:
                    return json.loads(cached)
                
                # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
                result = func(*args, **kwargs)
                self.redis_client.setex(
                    cache_key, 
                    expiration, 
                    json.dumps(result, ensure_ascii=False)
                )
                return result
            return wrapper
        return decorator
    
    def _generate_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        key_data = f"{func_name}:{str(args)}:{str(sorted(kwargs.items()))}"
        return hashlib.md5(key_data.encode()).hexdigest()

# ä½¿ç”¨ç¤ºä¾‹
cache_manager = CacheManager()

@cache_manager.cache_result(expiration=1800)
def get_hr_policy_answer(question: str) -> str:
    """å¸¦ç¼“å­˜çš„HRæ”¿ç­–æŸ¥è¯¢"""
    # å®é™…æŸ¥è¯¢é€»è¾‘
    return "æ”¿ç­–ç­”æ¡ˆ..."
```

#### 2. æ•°æ®åº“ä¼˜åŒ–
```python
from sqlalchemy import create_engine, Column, String, DateTime, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import sqlalchemy as sa

Base = declarative_base()

class ConversationHistory(Base):
    """å¯¹è¯å†å²è¡¨"""
    __tablename__ = 'conversation_history'
    
    id = Column(String(36), primary_key=True)
    user_id = Column(String(50), index=True)
    session_id = Column(String(50), index=True)
    question = Column(Text)
    answer = Column(Text)
    timestamp = Column(DateTime, default=datetime.datetime.utcnow, index=True)
    
    # å¤åˆç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
    __table_args__ = (
        sa.Index('idx_user_session', 'user_id', 'session_id'),
        sa.Index('idx_timestamp', 'timestamp'),
    )

# æ•°æ®åº“è¿æ¥æ± é…ç½®
engine = create_engine(
    'postgresql://user:password@localhost/hr_agent',
    pool_size=20,
    max_overflow=30,
    pool_pre_ping=True,
    pool_recycle=3600
)

SessionLocal = sessionmaker(bind=engine)
```

#### 3. å¼‚æ­¥å¤„ç†ä¼˜åŒ–
```python
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import logging

class AsyncHRAgent:
    """å¼‚æ­¥HR Agentå®ç°"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def process_multiple_questions(self, questions: List[str]) -> List[str]:
        """å¹¶å‘å¤„ç†å¤šä¸ªé—®é¢˜"""
        tasks = [self.process_single_question(q) for q in questions]
        return await asyncio.gather(*tasks)
    
    async def process_single_question(self, question: str) -> str:
        """å¼‚æ­¥å¤„ç†å•ä¸ªé—®é¢˜"""
        loop = asyncio.get_event_loop()
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œé˜»å¡æ“ä½œ
        result = await loop.run_in_executor(
            self.executor,
            self._sync_process_question,
            question
        )
        return result
    
    def _sync_process_question(self, question: str) -> str:
        """åŒæ­¥å¤„ç†é€»è¾‘"""
        # å®é™…çš„é—®é¢˜å¤„ç†é€»è¾‘
        return f"å¤„ç†ç»“æœ: {question}"

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    async with AsyncHRAgent() as agent:
        questions = ["å¹´å‡æ”¿ç­–ï¼Ÿ", "å¦‚ä½•è¯·å‡ï¼Ÿ", "ç¤¾ä¿å¦‚ä½•ç¼´çº³ï¼Ÿ"]
        results = await agent.process_multiple_questions(questions)
        for q, r in zip(questions, results):
            print(f"é—®é¢˜: {q} -> ç­”æ¡ˆ: {r}")

# asyncio.run(main())
```

### ğŸ³ Dockerå®¹å™¨åŒ–éƒ¨ç½²

#### Dockerfileç¤ºä¾‹
```dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### docker-compose.yml
```yaml
version: '3.8'

services:
  hr-agent-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/hr_agent
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - postgres
      - redis
    volumes:
      - ./uploads:/app/uploads

  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: hr_agent
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - hr-agent-api

volumes:
  postgres_data:
  redis_data:
```

## å¸¸è§é—®é¢˜FAQä¸è§£å†³æ–¹æ¡ˆ

### â“ é—®é¢˜1ï¼šAPIè°ƒç”¨é¢‘ç‡é™åˆ¶

**é—®é¢˜æè¿°**ï¼šOpenAI APIè°ƒç”¨é¢‘ç‡è¿‡é«˜å¯¼è‡´æœåŠ¡ä¸­æ–­ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
import time
from typing import Optional
import logging

class RateLimiter:
    def __init__(self, max_calls: int = 10, time_window: int = 60):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = []
    
    def wait_if_needed(self):
        """ç­‰å¾…ç›´åˆ°å¯ä»¥å†æ¬¡è°ƒç”¨"""
        now = time.time()
        
        # ç§»é™¤è¿‡æœŸè°ƒç”¨è®°å½•
        self.calls = [call_time for call_time in self.calls 
                     if now - call_time < self.time_window]
        
        if len(self.calls) >= self.max_calls:
            sleep_time = self.time_window - (now - self.calls[0])
            if sleep_time > 0:
                logging.info(f"è¾¾åˆ°APIé™åˆ¶ï¼Œç­‰å¾…{sleep_time:.2f}ç§’")
                time.sleep(sleep_time)
        
        self.calls.append(now)

# ä½¿ç”¨ç¤ºä¾‹
rate_limiter = RateLimiter(max_calls=20, time_window=60)

def safe_api_call(question: str) -> str:
    rate_limiter.wait_if_needed()
    # å®é™…çš„APIè°ƒç”¨
    return "APIå“åº”"
```

### â“ é—®é¢˜2ï¼šé•¿æ–‡æœ¬å¤„ç†è¶…æ—¶

**é—®é¢˜æè¿°**ï¼šå¤„ç†é•¿ç®€å†æˆ–å¤æ‚é—®é¢˜æ—¶å‡ºç°è¶…æ—¶ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

class TextProcessor:
    def __init__(self, chunk_size: int = 2000, chunk_overlap: int = 200):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
        )
    
    def process_long_text(self, text: str, callback_func) -> str:
        """åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬"""
        chunks = self.text_splitter.split_text(text)
        results = []
        
        for i, chunk in enumerate(chunks):
            logging.info(f"å¤„ç†ç¬¬{i+1}/{len(chunks)}æ®µæ–‡æœ¬")
            result = callback_func(chunk)
            results.append(result)
        
        # åˆå¹¶ç»“æœ
        return "\n".join(results)

# ä½¿ç”¨ç¤ºä¾‹
processor = TextProcessor()
result = processor.process_long_text(long_resume_text, extract_resume_info)
```

### â“ é—®é¢˜3ï¼šå¤šè¯­è¨€æ”¯æŒ

**é—®é¢˜æè¿°**ï¼šéœ€è¦æ”¯æŒä¸­è‹±æ–‡æ··åˆçš„ç®€å†å’Œå¯¹è¯ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

class MultilingualProcessor:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview")
    
    def detect_language(self, text: str) -> str:
        """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
        # ç®€å•çš„ä¸­æ–‡å­—ç¬¦æ£€æµ‹
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        english_chars = len([c for c in text if c.isascii() and c.isalpha()])
        
        if chinese_chars > english_chars:
            return "zh"
        return "en"
    
    def process_multilingual_text(self, text: str) -> str:
        """å¤„ç†å¤šè¯­è¨€æ–‡æœ¬"""
        language = self.detect_language(text)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", f"è¯·ç”¨{'ä¸­æ–‡' if language == 'zh' else 'English'}å›å¤ç”¨æˆ·çš„é—®é¢˜"),
            ("human", "{text}")
        ])
        
        chain = prompt | self.llm
        return chain.invoke({"text": text}).content
```

### â“ é—®é¢˜4ï¼šæ•°æ®éšç§ä¿æŠ¤

**é—®é¢˜æè¿°**ï¼šå‘˜å·¥ä¸ªäººä¿¡æ¯å’Œç®€å†æ•°æ®çš„å®‰å…¨ä¿æŠ¤ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
from cryptography.fernet import Fernet
import hashlib

class DataPrivacyManager:
    def __init__(self, encryption_key: bytes = None):
        if encryption_key is None:
            encryption_key = Fernet.generate_key()
        self.cipher_suite = Fernet(encryption_key)
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """åŠ å¯†æ•æ„Ÿæ•°æ®"""
        return self.cipher_suite.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """è§£å¯†æ•æ„Ÿæ•°æ®"""
        return self.cipher_suite.decrypt(encrypted_data.encode()).decode()
    
    def hash_identifier(self, identifier: str) -> str:
        """å“ˆå¸Œæ ‡è¯†ç¬¦ï¼ˆå¦‚é‚®ç®±ï¼‰"""
        return hashlib.sha256(identifier.encode()).hexdigest()
    
    def anonymize_resume(self, resume_text: str) -> str:
        """åŒ¿ååŒ–ç®€å†å†…å®¹"""
        # ç§»é™¤å§“åã€é‚®ç®±ã€ç”µè¯ç­‰æ•æ„Ÿä¿¡æ¯
        import re
        
        # ç§»é™¤é‚®ç®±
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        resume_text = re.sub(email_pattern, '[EMAIL]', resume_text)
        
        # ç§»é™¤ç”µè¯
        phone_pattern = r'(\+?\d{1,3}[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}'
        resume_text = re.sub(phone_pattern, '[PHONE]', resume_text)
        
        return resume_text

# ä½¿ç”¨ç¤ºä¾‹
privacy_manager = DataPrivacyManager()
encrypted_email = privacy_manager.encrypt_sensitive_data("user@example.com")
```

## 2025å¹´HR AI Agentå‘å±•è¶‹åŠ¿

### ğŸ”® æŠ€æœ¯å‘å±•è¶‹åŠ¿

#### 1. å¤šæ¨¡æ€èƒ½åŠ›å¢å¼º
- **æ–‡æ¡£ç†è§£**ï¼šæ”¯æŒPDFã€Wordã€å›¾ç‰‡ç­‰å¤šç§æ ¼å¼
- **è§†é¢‘é¢è¯•**ï¼šAIè§†é¢‘é¢è¯•åˆ†æå€™é€‰äººè¡¨æƒ…å’Œè¯­è¨€
- **è¯­éŸ³äº¤äº’**ï¼šæ”¯æŒè¯­éŸ³é—®ç­”å’Œè¯­éŸ³ç®€å†è§£æ

#### 2. ä¸ªæ€§åŒ–æ¨èå‡çº§
- **ç²¾å‡†åŒ¹é…**ï¼šåŸºäºå€™é€‰äººå†å²è¡Œä¸ºçš„ä¸ªæ€§åŒ–æ¨è
- **æŠ€èƒ½å›¾è°±**ï¼šæ„å»ºåŠ¨æ€æŠ€èƒ½å‘å±•è·¯å¾„
- **æ–‡åŒ–åŒ¹é…**ï¼šè¯„ä¼°å€™é€‰äººä¸å…¬å¸æ–‡åŒ–çš„åŒ¹é…åº¦

#### 3. å®æ—¶åä½œèƒ½åŠ›
- **å¤šäººåä½œ**ï¼šHRã€ç”¨äººéƒ¨é—¨ã€å€™é€‰äººå®æ—¶åä½œ
- **å³æ—¶åé¦ˆ**ï¼šé¢è¯•åé¦ˆå®æ—¶åŒæ­¥
- **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®é¢è¯•è¿›å±•åŠ¨æ€è°ƒæ•´æ‹›è˜ç­–ç•¥

### ğŸ“ˆ å•†ä¸šä»·å€¼é¢„æµ‹

| æŒ‡æ ‡ | 2024å¹´ | 2025å¹´é¢„æµ‹ | å¢é•¿ç‡ |
|------|--------|------------|--------|
| **å¤„ç†æ•ˆç‡æå‡** | 85% | 150% | +76% |
| **æˆæœ¬é™ä½** | 40% | 60% | +50% |
| **å€™é€‰äººæ»¡æ„åº¦** | 35% | 55% | +57% |
| **æ‹›è˜å‘¨æœŸç¼©çŸ­** | 30% | 50% | +67% |

### ğŸš€ æ–°å…´åº”ç”¨åœºæ™¯

#### 1. AIé¢è¯•å®˜
```python
class AIInterviewer:
    """AIæ™ºèƒ½é¢è¯•å®˜"""
    
    def __init__(self):
        self.questions_db = self._load_interview_questions()
        self.evaluation_criteria = self._load_evaluation_criteria()
    
    def conduct_interview(self, candidate_info: Dict) -> Dict:
        """è¿›è¡ŒAIé¢è¯•"""
        questions = self._generate_questions(candidate_info)
        
        interview_result = {
            "questions": questions,
            "analysis": {},
            "score": 0,
            "recommendation": ""
        }
        
        return interview_result
    
    def _generate_questions(self, candidate_info: Dict) -> List[str]:
        """åŸºäºå€™é€‰äººä¿¡æ¯ç”Ÿæˆä¸ªæ€§åŒ–é—®é¢˜"""
        base_questions = [
            "è¯·ä»‹ç»ä¸€ä¸‹æ‚¨çš„å·¥ä½œç»å†",
            "ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬å…¬å¸ï¼Ÿ",
            "æ‚¨æœ€å¤§çš„èŒä¸šæˆå°±æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        # æ ¹æ®æŠ€èƒ½å’Œç»éªŒå®šåˆ¶é—®é¢˜
        if "Python" in candidate_info.get("skills", []):
            base_questions.append("è¯·åˆ†äº«ä¸€ä¸ªæ‚¨ç”¨Pythonè§£å†³å¤æ‚é—®é¢˜çš„æ¡ˆä¾‹")
        
        return base_questions

#### 2. é¢„æµ‹æ€§åˆ†æ
```python
class PredictiveAnalytics:
    """HRé¢„æµ‹æ€§åˆ†æ"""
    
    def __init__(self):
        self.model = self._load_prediction_model()
    
    def predict_employee_retention(self, employee_data: Dict) -> Dict:
        """é¢„æµ‹å‘˜å·¥ç•™å­˜ç‡"""
        features = self._extract_features(employee_data)
        retention_probability = self.model.predict_proba([features])[0][1]
        
        return {
            "retention_probability": retention_probability,
            "risk_factors": self._identify_risk_factors(employee_data),
            "recommendations": self._generate_recommendations(retention_probability)
        }
    
    def predict_hiring_success(self, candidate_data: Dict) -> Dict:
        """é¢„æµ‹æ‹›è˜æˆåŠŸç‡"""
        # åŸºäºå†å²æ•°æ®é¢„æµ‹å€™é€‰äººæˆåŠŸæ¦‚ç‡
        success_probability = self._calculate_success_probability(candidate_data)
        
        return {
            "success_probability": success_probability,
            "key_indicators": self._identify_key_indicators(candidate_data),
            "interview_focus": self._suggest_interview_focus(candidate_data)
        }
```

### ğŸ¯ å®æ–½å»ºè®®

#### çŸ­æœŸç›®æ ‡ï¼ˆ3-6ä¸ªæœˆï¼‰
1. **åŸºç¡€åŠŸèƒ½å®Œå–„**ï¼šä¼˜å…ˆå®ç°æ ¸å¿ƒHRé—®ç­”å’Œç®€å†è§£æ
2. **æ•°æ®ç§¯ç´¯**ï¼šæ”¶é›†ç”¨æˆ·åé¦ˆå’Œäº¤äº’æ•°æ®
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šæå‡å“åº”é€Ÿåº¦å’Œå‡†ç¡®ç‡

#### ä¸­æœŸç›®æ ‡ï¼ˆ6-12ä¸ªæœˆï¼‰
1. **åŠŸèƒ½æ‰©å±•**ï¼šå¢åŠ å…¥èŒåŠ©æ‰‹å’Œå‘˜å·¥æœåŠ¡åŠŸèƒ½
2. **é›†æˆä¼˜åŒ–**ï¼šä¸ç°æœ‰HRç³»ç»Ÿæ·±åº¦é›†æˆ
3. **ç”¨æˆ·ä½“éªŒ**ï¼šä¼˜åŒ–ç•Œé¢å’Œäº¤äº’æµç¨‹

#### é•¿æœŸç›®æ ‡ï¼ˆ1-2å¹´ï¼‰
1. **æ™ºèƒ½åŒ–å‡çº§**ï¼šå¼•å…¥æ›´å…ˆè¿›çš„AIæ¨¡å‹
2. **ç”Ÿæ€å»ºè®¾**ï¼šæ„å»ºå®Œæ•´çš„HR AIç”Ÿæ€ç³»ç»Ÿ
3. **å•†ä¸šåŒ–**ï¼šå¯¹å¤–è¾“å‡ºè§£å†³æ–¹æ¡ˆ

## ğŸ“š å­¦ä¹ èµ„æºä¸è¿›é˜¶æŒ‡å—

### ğŸ“ æ¨èå­¦ä¹ è·¯å¾„

#### åˆå­¦è€…è·¯å¾„
1. **PythonåŸºç¡€**ï¼šæŒæ¡Pythonè¯­æ³•å’Œé¢å‘å¯¹è±¡ç¼–ç¨‹
2. **LangChainå…¥é—¨**ï¼šå­¦ä¹ LangChainæ ¸å¿ƒæ¦‚å¿µå’Œç»„ä»¶
3. **OpenAI API**ï¼šç†Ÿæ‚‰GPTæ¨¡å‹è°ƒç”¨å’Œå‚æ•°è°ƒä¼˜
4. **é¡¹ç›®å®æˆ˜**ï¼šä»ç®€å•çš„é—®ç­”æœºå™¨äººå¼€å§‹

#### è¿›é˜¶å¼€å‘è€…è·¯å¾„
1. **é«˜çº§LangChain**ï¼šæŒæ¡Agentã€Chainã€Memoryç­‰é«˜çº§ç‰¹æ€§
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šå­¦ä¹ ç¼“å­˜ã€å¼‚æ­¥ã€åˆ†å¸ƒå¼éƒ¨ç½²
3. **æ¨¡å‹å¾®è°ƒ**ï¼šäº†è§£å¦‚ä½•å¾®è°ƒæ¨¡å‹æå‡æ•ˆæœ
4. **ä¼ä¸šçº§éƒ¨ç½²**ï¼šæŒæ¡Dockerã€Kubernetesã€ç›‘æ§ç­‰

### ğŸ“– ç²¾é€‰å­¦ä¹ èµ„æº

#### å®˜æ–¹æ–‡æ¡£
- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [OpenAI APIæ–‡æ¡£](https://platform.openai.com/docs)
- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)

#### å®æˆ˜é¡¹ç›®
- [LangChain Examples](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain)
- [Awesome LLM Apps](https://github.com/Shubhamsaboo/awesome-llm-apps)

#### æŠ€æœ¯ç¤¾åŒº
- **çŸ¥ä¹ä¸“æ **ï¼šæœç´¢"å¤§æ¨¡å‹åº”ç”¨å¼€å‘"
- **GitHub**ï¼šå…³æ³¨langchain-aiã€microsoftã€openaiç­‰ç»„ç»‡
- **æŠ€æœ¯åšå®¢**ï¼šTowards Data Scienceã€æœºå™¨å­¦ä¹ ç¤¾åŒº

### ğŸ› ï¸ å¼€å‘å·¥å…·æ¨è

| å·¥å…·ç±»å‹ | æ¨èå·¥å…· | ç”¨é€” |
|----------|----------|------|
| **IDE** | VS Code + Pythonæ’ä»¶ | ä»£ç å¼€å‘ |
| **APIæµ‹è¯•** | Postman / Thunder Client | APIè°ƒè¯• |
| **æ•°æ®åº“** | pgAdmin / Redis Insight | æ•°æ®ç®¡ç† |
| **ç›‘æ§** | Prometheus + Grafana | ç³»ç»Ÿç›‘æ§ |
| **æ—¥å¿—** | ELK Stack | æ—¥å¿—åˆ†æ |

## ğŸ‰ æ€»ç»“ä¸å±•æœ›

é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬å®Œæ•´å­¦ä¹ äº†å¦‚ä½•ä»é›¶æ„å»ºä¸€ä¸ªä¼ä¸šçº§çš„HRæ™ºèƒ½æ‹›è˜åŠ©æ‰‹ã€‚ä»åŸºç¡€æ¦‚å¿µåˆ°å®æˆ˜é¡¹ç›®ï¼Œä»å•æœºéƒ¨ç½²åˆ°ä¼ä¸šçº§æ¶æ„ï¼Œæ¶µç›–äº†AI Agentå¼€å‘çš„æ–¹æ–¹é¢é¢ã€‚

### ğŸ† æ ¸å¿ƒæ”¶è·
- âœ… æŒæ¡äº†å¤§æ¨¡å‹Agentçš„æ ¸å¿ƒåŸç†å’Œæ¶æ„è®¾è®¡
- âœ… å­¦ä¼šäº†ä½¿ç”¨LangChainæ„å»ºå¤æ‚çš„AIåº”ç”¨
- âœ… å®ç°äº†HRåœºæ™¯ä¸‹çš„ä¸‰ä¸ªå®Œæ•´å®æˆ˜é¡¹ç›®
- âœ… äº†è§£äº†ä¼ä¸šçº§éƒ¨ç½²å’Œæ€§èƒ½ä¼˜åŒ–çš„æœ€ä½³å®è·µ
- âœ… è·å¾—äº†2025å¹´æœ€æ–°çš„æŠ€æœ¯è¶‹åŠ¿å’Œå‘å±•æ–¹å‘

### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. **ç«‹å³å¼€å§‹**ï¼šæŒ‰ç…§æ•™ç¨‹æ­å»ºå¼€å‘ç¯å¢ƒï¼Œè¿è¡Œç¬¬ä¸€ä¸ªç¤ºä¾‹
2. **åŠ¨æ‰‹å®è·µ**ï¼šé€‰æ‹©ä¸€ä¸ªå°åŠŸèƒ½å¼€å§‹æ”¹è¿›å’Œæ‰©å±•
3. **åŠ å…¥ç¤¾åŒº**ï¼šå‚ä¸æŠ€æœ¯è®¨è®ºï¼Œåˆ†äº«ä½ çš„ç»éªŒå’Œé—®é¢˜
4. **æŒç»­å­¦ä¹ **ï¼šå…³æ³¨æŠ€æœ¯æ›´æ–°ï¼Œä¸æ–­æå‡æŠ€èƒ½

### ğŸ“ æŠ€æœ¯æ”¯æŒ
å¦‚æœä½ åœ¨å®è·µè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å¾—å¸®åŠ©ï¼š
- **GitHub Issues**ï¼šåœ¨[é¡¹ç›®ä»“åº“](https://github.com/your-repo)æäº¤é—®é¢˜
- **æŠ€æœ¯äº¤æµç¾¤**ï¼šåŠ å…¥æˆ‘ä»¬çš„å¾®ä¿¡/QQæŠ€æœ¯äº¤æµç¾¤
- **é‚®ä»¶å’¨è¯¢**ï¼šå‘é€é‚®ä»¶åˆ° support@hr-agent.dev

---

**ç‰ˆæƒå£°æ˜**ï¼šæœ¬æ•™ç¨‹å†…å®¹é‡‡ç”¨CC BY-NC-SA 4.0åè®®ï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚å•†ä¸šä½¿ç”¨è¯·è”ç³»æˆæƒã€‚

**æœ€åæ›´æ–°**ï¼š2025å¹´7æœˆ16æ—¥

**ç‰ˆæœ¬**ï¼šv2.0.0 - 2025æœ€æ–°ç‰ˆ
