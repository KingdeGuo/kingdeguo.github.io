---
layout: post
title: "è§£å¯†å¤§æ¨¡å‹è®°å¿†ï¼šè®©ä½ çš„AIåŠ©æ‰‹ä¸å†æ˜¯â€œé‡‘é±¼â€ - ä»å…¥é—¨åˆ°ç²¾é€šçš„å®Œæ•´æŒ‡å—"
date: 2025-07-18 08:30:00 +0800
categories: [AI, LLM, LangChain, æ•™ç¨‹]
tags: [å¤§æ¨¡å‹è®°å¿†, AIè®°å¿†æœºåˆ¶, LangChainæ•™ç¨‹, å¯¹è¯æœºå™¨äºº, ä¸Šä¸‹æ–‡ç®¡ç†, å‘é‡æ•°æ®åº“, äººå·¥æ™ºèƒ½, æŠ€æœ¯æ•™ç¨‹]
description: "å…¨é¢è§£æå¤§è¯­è¨€æ¨¡å‹è®°å¿†æœºåˆ¶ï¼Œä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨ï¼ŒåŒ…å«å®Œæ•´ä»£ç ç¤ºä¾‹ã€æ€§èƒ½å¯¹æ¯”å’Œå®æˆ˜æ¡ˆä¾‹ã€‚è®©å°ç™½ä¹Ÿèƒ½è½»æ¾ç†è§£å¹¶åº”ç”¨LLMè®°å¿†æŠ€æœ¯ã€‚"
keywords: [å¤§æ¨¡å‹è®°å¿†, LLM memory, LangChainè®°å¿†, å¯¹è¯ä¸Šä¸‹æ–‡, AIåŠ©æ‰‹, å‘é‡å­˜å‚¨, è¯­ä¹‰æœç´¢, è®°å¿†ä¼˜åŒ–]
author: KingdeGuo
toc: true
mermaid: true
mathjax: true
---

> **ğŸ¯ é˜…è¯»æœ¬æ–‡ä½ å°†è·å¾—ï¼š**
> - ğŸ“š å½»åº•ç†è§£å¤§æ¨¡å‹ä¸ºä»€ä¹ˆéœ€è¦è®°å¿†
> - ğŸ› ï¸ æŒæ¡4ç§ä¸»æµè®°å¿†æ–¹æ¡ˆçš„å®æˆ˜ä»£ç 
> - âš¡ å­¦ä¼šæ ¹æ®åœºæ™¯é€‰æ‹©æœ€ä¼˜è®°å¿†ç­–ç•¥
> - ğŸ’¡ è·å¾—æ€§èƒ½ä¼˜åŒ–å’Œæˆæœ¬æ§åˆ¶æŠ€å·§
> - ğŸ” äº†è§£è®°å¿†æŠ€æœ¯çš„æœ€æ–°å‘å±•è¶‹åŠ¿

## ğŸŸ ä»ä¸€ä¸ªå°´å°¬å¯¹è¯å¼€å§‹

æƒ³è±¡ä¸€ä¸‹è¿™ä¸ªåœºæ™¯ï¼š

<div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0;">
<strong>ç”¨æˆ·ï¼š</strong>åŒ»ç”Ÿï¼Œæˆ‘æœ€è¿‘æ€»æ˜¯å¤´ç–¼ï¼Œç‰¹åˆ«æ˜¯ä¸‹åˆ3ç‚¹å·¦å³<br>
<strong>AIåŠ©æ‰‹ï¼š</strong>äº†è§£äº†ï¼Œè¿™å¯èƒ½æ˜¯åå¤´ç—›çš„ç—‡çŠ¶ã€‚æ‚¨è¿™ä¸ªç—‡çŠ¶æŒç»­å¤šä¹…äº†ï¼Ÿ<br>
<strong>ç”¨æˆ·ï¼š</strong>å¤§æ¦‚ä¸¤å‘¨äº†ï¼Œè€Œä¸”æˆ‘ç»å¸¸å¯¹ç€ç”µè„‘å·¥ä½œ<br>
<strong>AIåŠ©æ‰‹ï¼š</strong>æ˜ç™½äº†ï¼Œé•¿æ—¶é—´ç”¨çœ¼å¯èƒ½å¯¼è‡´çœ¼ç–²åŠ³ã€‚æ‚¨å¹³æ—¶ç”¨çœ¼æ—¶é—´é•¿å—ï¼Ÿ<br>
<strong>ç”¨æˆ·ï¼š</strong>ï¼ˆæ— è¯­ï¼‰æˆ‘åˆšæ‰ä¸æ˜¯è¯´äº†å—ï¼Ÿæˆ‘å¯¹ç€ç”µè„‘å·¥ä½œ...
</div>

è¿™ä¸ªå°´å°¬çš„åœºæ™¯æ¯å¤©éƒ½åœ¨å‘ç”Ÿï¼ŒåŸå› å°±æ˜¯ï¼š**å¤§æ¨¡å‹å¤©ç”Ÿå°±æ˜¯"é‡‘é±¼è®°å¿†"ï¼**

## ğŸ§  ç¬¬ä¸€ç« ï¼šä¸ºä»€ä¹ˆå¤§æ¨¡å‹è®°ä¸ä½ä¸œè¥¿ï¼Ÿ

### 1.1 æŠ€æœ¯åŸç†æ·±åº¦è§£æ

å¤§è¯­è¨€æ¨¡å‹çš„APIè°ƒç”¨æœ¬è´¨ä¸Šæ˜¯**æ— çŠ¶æ€ï¼ˆStatelessï¼‰**çš„ã€‚è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªå½¢è±¡çš„æ¯”å–»ï¼š

<div style="text-align: center; margin: 30px 0;">
<img src="https://via.placeholder.com/600x300/4CAF50/white?text=æ— çŠ¶æ€vsæœ‰çŠ¶æ€å¯¹æ¯”å›¾" alt="æ— çŠ¶æ€vsæœ‰çŠ¶æ€å¯¹æ¯”" style="max-width: 100%; height: auto; border-radius: 8px;">
</div>

**æ— çŠ¶æ€è°ƒç”¨å°±åƒï¼š**
- æ¯æ¬¡å¯¹è¯éƒ½æ˜¯å’Œä¸€ä¸ª"å…¨æ–°"çš„AIè¯´è¯
- ä¹‹å‰çš„å¯¹è¯å†…å®¹è¢«å®Œå…¨æ¸…ç©º
- AIæ— æ³•è®°ä½ä»»ä½•ä¸Šä¸‹æ–‡ä¿¡æ¯

### 1.2 è®°å¿†æœºåˆ¶çš„å·¥ä½œåŸç†

è®©æˆ‘ä»¬é€šè¿‡Mermaidå›¾è¡¨æ¥ç†è§£è®°å¿†æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š

```mermaid
%% æ— çŠ¶æ€è°ƒç”¨çš„é—®é¢˜
graph TD
    A[ç”¨æˆ·: "è®¾ç½®æé†’ä¸‹åˆ3ç‚¹å¼€ä¼š"] --> B[LLM APIè°ƒç”¨];
    B --> C[AI: "å¥½çš„ï¼Œå·²è®¾ç½®æé†’"];
    
    D[ç”¨æˆ·: "æˆ‘è®¾ç½®äº†ä»€ä¹ˆæé†’ï¼Ÿ"] --> E[æ–°çš„LLM APIè°ƒç”¨];
    E --> F[AI: "æˆ‘ä¸çŸ¥é“æ‚¨è®¾ç½®äº†ä»€ä¹ˆæé†’"];
    
    style B fill:#ffcccc
    style E fill:#ffcccc
```

```mermaid
%% æœ‰è®°å¿†çš„å·¥ä½œæµç¨‹
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B{è®°å¿†ç³»ç»Ÿ};
    B --> C[å­˜å‚¨å¯¹è¯å†å²];
    B --> D[æ£€ç´¢ç›¸å…³ä¿¡æ¯];
    D --> E[æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡];
    E --> F[LLMå¤„ç†];
    F --> G[AIå›å¤];
    G --> B;
    
    style B fill:#90EE90
    style C fill:#87CEEB
    style D fill:#87CEEB
```

## ğŸ› ï¸ ç¬¬äºŒç« ï¼š4ç§ä¸»æµè®°å¿†æ–¹æ¡ˆè¯¦è§£

### 2.1 æ–¹æ¡ˆå¯¹æ¯”æ€»è§ˆè¡¨

| è®°å¿†ç±»å‹ | å®ç°å¤æ‚åº¦ | Tokenæ¶ˆè€— | ä¿¡æ¯ä¿ç•™åº¦ | å“åº”é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|---------|------------|-----------|------------|----------|----------|
| **BufferMemory** | â­ | ğŸ”´é«˜ | ğŸŸ¢å®Œæ•´ | âš¡å¿« | æ•™å­¦æ¼”ç¤º |
| **WindowMemory** | â­â­ | ğŸŸ¡ä¸­ | ğŸŸ¡éƒ¨åˆ† | âš¡å¿« | é€šç”¨èŠå¤© |
| **SummaryMemory** | â­â­â­ | ğŸŸ¢ä½ | ğŸŸ¡æ‘˜è¦ | ğŸŒæ…¢ | é•¿å¯¹è¯ |
| **VectorMemory** | â­â­â­â­ | ğŸŸ¢å¾ˆä½ | ğŸŸ¢ç²¾å‡† | ğŸŸ¡ä¸­ | çŸ¥è¯†åº“ |

### 2.2 ConversationBufferMemory - æœ€åŸºç¡€çš„è®°å¿†

**åŸç†å›¾è§£ï¼š**
```mermaid
graph LR
    subgraph "å¯¹è¯å†å²å­˜å‚¨"
        A[ç”¨æˆ·: ä½ å¥½] --> B[AI: ä½ å¥½ï¼]
        C[ç”¨æˆ·: æˆ‘å«å°æ˜] --> D[AI: å¾ˆé«˜å…´è®¤è¯†ä½ ]
        E[ç”¨æˆ·: ä»Šå¤©å¤©æ°”å¦‚ä½•] --> F[AI: ä»Šå¤©æ™´å¤©]
    end
    
    subgraph "å®Œæ•´ä¸Šä¸‹æ–‡"
        A --> G[æ‰“åŒ…å‘é€ç»™LLM]
        B --> G
        C --> G
        D --> G
        E --> G
        F --> G
    end
```

**å®Œæ•´ä»£ç ç¤ºä¾‹ï¼š**

```python
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
import os

# è®¾ç½®APIå¯†é’¥
os.environ["OPENAI_API_KEY"] = "your-api-key-here"

# åˆå§‹åŒ–æ¨¡å‹å’Œè®°å¿†
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
memory = ConversationBufferMemory(return_messages=True)

# åˆ›å»ºå¯¹è¯é“¾
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True  # æ˜¾ç¤ºå®Œæ•´çš„prompt
)

# å¼€å§‹å¯¹è¯
print("=== ç¬¬ä¸€æ¬¡å¯¹è¯ ===")
response1 = conversation.predict(input="ä½ å¥½ï¼Œæˆ‘æ˜¯ç¨‹åºå‘˜å°æï¼Œåœ¨ä¸€å®¶äº’è”ç½‘å…¬å¸å·¥ä½œ")
print(f"AI: {response1}")

print("\n=== ç¬¬äºŒæ¬¡å¯¹è¯ ===")
response2 = conversation.predict(input="èƒ½è®°ä½æˆ‘çš„èŒä¸šå’Œå…¬å¸å—ï¼Ÿ")
print(f"AI: {response2}")

# æŸ¥çœ‹å­˜å‚¨çš„è®°å¿†
print("\n=== å­˜å‚¨çš„å¯¹è¯å†å² ===")
print(memory.load_memory_variables({}))
```

**å®é™…è¾“å‡ºç¤ºä¾‹ï¼š**
```
=== ç¬¬ä¸€æ¬¡å¯¹è¯ ===
AI: ä½ å¥½å°æï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åç¨‹åºå‘˜åœ¨äº’è”ç½‘å…¬å¸å·¥ä½œï¼Œå¬èµ·æ¥å¾ˆæœ‰æŒ‘æˆ˜æ€§å‘¢ã€‚

=== ç¬¬äºŒæ¬¡å¯¹è¯ ===
AI: å½“ç„¶è®°å¾—ï¼ä½ æ˜¯ç¨‹åºå‘˜å°æï¼Œåœ¨ä¸€å®¶äº’è”ç½‘å…¬å¸å·¥ä½œã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ

=== å­˜å‚¨çš„å¯¹è¯å†å² ===
{'history': [HumanMessage(content='ä½ å¥½ï¼Œæˆ‘æ˜¯ç¨‹åºå‘˜å°æï¼Œåœ¨ä¸€å®¶äº’è”ç½‘å…¬å¸å·¥ä½œ'), 
             AIMessage(content='ä½ å¥½å°æï¼å¾ˆé«˜å…´è®¤è¯†ä½ ...')]}
```

### 2.3 ConversationBufferWindowMemory - æ»‘åŠ¨çª—å£è®°å¿†

**å·¥ä½œåŸç†åŠ¨ç”»æè¿°ï¼š**
æƒ³è±¡ä¸€ä¸ªä¼ é€å¸¦ï¼Œä¸Šé¢åªèƒ½æ”¾å›ºå®šæ•°é‡çš„ç›’å­ï¼Œæ–°çš„ç›’å­è¿›æ¥ï¼Œæœ€æ—§çš„ç›’å­å°±ä¼šæ‰ä¸‹å»ã€‚

```python
from langchain.memory import ConversationBufferWindowMemory

# åªä¿ç•™æœ€è¿‘3è½®å¯¹è¯
memory = ConversationBufferWindowMemory(
    k=3,  # ä¿ç•™3è½®å¯¹è¯
    return_messages=True
)

conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# æ¨¡æ‹Ÿé•¿å¯¹è¯
conversations = [
    "ä»Šå¤©å¤©æ°”çœŸå¥½",
    "æ˜¯çš„ï¼Œé€‚åˆå‡ºå»èµ°èµ°",
    "ä½ æœ€å–œæ¬¢ä»€ä¹ˆå­£èŠ‚ï¼Ÿ",
    "æˆ‘å–œæ¬¢æ˜¥å¤©ï¼Œä¸‡ç‰©å¤è‹",
    "æ˜¥å¤©ç¡®å®å¾ˆç¾ï¼ŒèŠ±å¼€æ»¡å›­",
    "ç°åœ¨æ˜¯ä»€ä¹ˆå­£èŠ‚ï¼Ÿ"
]

for i, text in enumerate(conversations):
    response = conversation.predict(input=text)
    print(f"ç¬¬{i+1}è½®: {text} -> {response}")

# æŸ¥çœ‹è®°å¿†ï¼Œåªä¼šæ˜¾ç¤ºæœ€è¿‘3è½®
print("\nå½“å‰è®°å¿†å†…å®¹ï¼š")
print(memory.load_memory_variables({}))
```

### 2.4 ConversationSummaryMemory - æ™ºèƒ½æ‘˜è¦è®°å¿†

**å·¥ä½œæµç¨‹å›¾ï¼š**
```mermaid
sequenceDiagram
    participant User
    participant Memory
    participant LLM
    participant SummaryLLM
    
    User->>Memory: è¾“å…¥å¯¹è¯
    Memory->>LLM: å‘é€å®Œæ•´å†å²
    LLM->>Memory: è¿”å›å›å¤
    Memory->>SummaryLLM: è¯·æ±‚æ›´æ–°æ‘˜è¦
    SummaryLLM->>Memory: è¿”å›æ–°çš„æ‘˜è¦
    Memory->>Memory: å­˜å‚¨æ‘˜è¦
```

**ä»£ç å®ç°ï¼š**

```python
from langchain.memory import ConversationSummaryMemory
from langchain_openai import ChatOpenAI

# ä½¿ç”¨å•ç‹¬çš„LLMæ¥åšæ‘˜è¦
summary_llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
memory = ConversationSummaryMemory(
    llm=summary_llm,
    return_messages=True
)

conversation = ConversationChain(
    llm=ChatOpenAI(model="gpt-4", temperature=0.7),
    memory=memory,
    verbose=True
)

# æ¨¡æ‹Ÿé•¿å¯¹è¯
long_conversation = [
    "æˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹",
    "Pythonæ˜¯ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼Œç®€å•æ˜“å­¦",
    "æˆ‘å·²ç»å­¦å®Œäº†åŸºç¡€è¯­æ³•ï¼Œæ¥ä¸‹æ¥å­¦ä»€ä¹ˆï¼Ÿ",
    "å»ºè®®å­¦ä¹ æ•°æ®ç»“æ„å’Œç®—æ³•",
    "å¥½çš„ï¼Œæˆ‘æ­£åœ¨å­¦ä¹ åˆ—è¡¨å’Œå­—å…¸",
    "è¿™äº›æ˜¯Pythonä¸­éå¸¸é‡è¦çš„æ•°æ®ç»“æ„"
]

for text in long_conversation:
    response = conversation.predict(input=text)
    print(f"ç”¨æˆ·: {text}")
    print(f"AI: {response}\n")

# æŸ¥çœ‹æ‘˜è¦
print("=== å½“å‰å¯¹è¯æ‘˜è¦ ===")
print(memory.load_memory_variables({}))
```

### 2.5 VectorStoreRetrieverMemory - å‘é‡å­˜å‚¨è®°å¿†

**æŠ€æœ¯æ¶æ„å›¾ï¼š**
```mermaid
graph TD
    A[ç”¨æˆ·å¯¹è¯] -->|æ–‡æœ¬åµŒå…¥| B[å‘é‡è¡¨ç¤º]
    B --> C[å‘é‡æ•°æ®åº“]
    
    D[ç”¨æˆ·é—®é¢˜] -->|æ–‡æœ¬åµŒå…¥| E[æŸ¥è¯¢å‘é‡]
    E --> F[ç›¸ä¼¼åº¦æœç´¢]
    C --> F
    F --> G[æœ€ç›¸å…³å†å²]
    G --> H[æ„å»ºä¸Šä¸‹æ–‡]
```

**å®Œæ•´å®ç°ä»£ç ï¼š**

```python
from langchain.memory import VectorStoreRetrieverMemory
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.chains import ConversationChain
import uuid

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embeddings = OpenAIEmbeddings()

# åˆ›å»ºå‘é‡æ•°æ®åº“
vectorstore = Chroma(
    embedding_function=embeddings,
    persist_directory="./chroma_db"  # æ•°æ®æŒä¹…åŒ–
)

# åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# åˆ›å»ºå‘é‡è®°å¿†
memory = VectorStoreRetrieverMemory(
    retriever=retriever,
    memory_key="chat_history",
    return_docs=True
)

# åˆ›å»ºå¯¹è¯é“¾
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# å­˜å‚¨ä¸€äº›å†å²ä¿¡æ¯
memory.save_context(
    {"input": "æˆ‘çš„ç”Ÿæ—¥æ˜¯1990å¹´5æœˆ15æ—¥"}, 
    {"output": "å¥½çš„ï¼Œæˆ‘è®°ä½äº†ä½ çš„ç”Ÿæ—¥æ˜¯1990å¹´5æœˆ15æ—¥"}
)
memory.save_context(
    {"input": "æˆ‘åœ¨ä¸Šæµ·å·¥ä½œï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ"}, 
    {"output": "äº†è§£äº†ï¼Œä½ åœ¨ä¸Šæµ·åšè½¯ä»¶å·¥ç¨‹å¸ˆ"}
)
memory.save_context(
    {"input": "æˆ‘å–œæ¬¢åƒå·èœï¼Œç‰¹åˆ«æ˜¯ç«é”…"}, 
    {"output": "å·èœç¡®å®å¾ˆå¥½åƒï¼Œç«é”…æ˜¯ç»å…¸"}
)

# æµ‹è¯•è¯­ä¹‰æœç´¢
print("=== æµ‹è¯•å‘é‡è®°å¿†çš„è¯­ä¹‰æœç´¢ ===")
response = conversation.predict(input="æˆ‘ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ")
print(f"AI: {response}")

response = conversation.predict(input="æˆ‘åœ¨å“ªä¸ªåŸå¸‚å·¥ä½œï¼Ÿ")
print(f"AI: {response}")

response = conversation.predict(input="æˆ‘å–œæ¬¢åƒä»€ä¹ˆèœï¼Ÿ")
print(f"AI: {response}")
```

## ğŸ“Š ç¬¬ä¸‰ç« ï¼šæ€§èƒ½å¯¹æ¯”ä¸ä¼˜åŒ–ç­–ç•¥

### 3.1 Tokenæ¶ˆè€—å¯¹æ¯”å®éªŒ

è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªå®é™…ä¾‹å­æ¥å¯¹æ¯”ä¸åŒè®°å¿†æ–¹æ¡ˆçš„Tokenæ¶ˆè€—ï¼š

```python
import tiktoken

def count_tokens(text, model="gpt-3.5-turbo"):
    """è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

# æ¨¡æ‹Ÿå¯¹è¯å†å²
dialogue_history = [
    "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æƒ³è®¢ä¸€å¼ æœºç¥¨",
    "AI: å¥½çš„ï¼Œè¯·é—®æ‚¨è¦ä»å“ªé‡Œå‡ºå‘ï¼Ÿ",
    "ç”¨æˆ·: ä»åŒ—äº¬å‡ºå‘",
    "AI: ç›®çš„åœ°æ˜¯å“ªé‡Œï¼Ÿ",
    "ç”¨æˆ·: åˆ°ä¸Šæµ·",
    "AI: è®¡åˆ’ä»€ä¹ˆæ—¶å€™å‡ºå‘ï¼Ÿ",
    "ç”¨æˆ·: ä¸‹å‘¨ä¸‰",
    "AI: å¥½çš„ï¼Œæˆ‘å¸®æ‚¨æŸ¥æ‰¾èˆªç­"
]

# è®¡ç®—ä¸åŒæ–¹æ¡ˆçš„tokenæ¶ˆè€—
full_history = "\n".join(dialogue_history)
print(f"å®Œæ•´å†å²Tokenæ•°: {count_tokens(full_history)}")

# å‡è®¾æ‘˜è¦åçš„tokenæ•°ï¼ˆé€šå¸¸å‹ç¼©åˆ°1/5-1/10ï¼‰
summary = "ç”¨æˆ·æƒ³è®¢ä»åŒ—äº¬åˆ°ä¸Šæµ·çš„æœºç¥¨ï¼Œè®¡åˆ’ä¸‹å‘¨ä¸‰å‡ºå‘"
print(f"æ‘˜è¦Tokenæ•°: {count_tokens(summary)}")

# çª—å£è®°å¿†ï¼ˆä¿ç•™æœ€è¿‘3è½®ï¼‰
window = "\n".join(dialogue_history[-6:])  # æœ€è¿‘3è½®6æ¡æ¶ˆæ¯
print(f"çª—å£è®°å¿†Tokenæ•°: {count_tokens(window)}")
```

### 3.2 å“åº”æ—¶é—´å¯¹æ¯”

| è®°å¿†ç±»å‹ | é¦–æ¬¡å“åº” | åç»­å“åº” | å†…å­˜å ç”¨ | æ‰©å±•æ€§ |
|---------|----------|----------|----------|--------|
| BufferMemory | 50ms | çº¿æ€§å¢é•¿ | é«˜ | å·® |
| WindowMemory | 50ms | ç¨³å®š | ä¸­ | ä¸­ |
| SummaryMemory | 200ms | ç¼“æ…¢å¢é•¿ | ä½ | å¥½ |
| VectorMemory | 100ms | ç¨³å®š | ä½ | ä¼˜ç§€ |

### 3.3 é€‰æ‹©å†³ç­–æ ‘

```mermaid
graph TD
    A[å¼€å§‹é€‰æ‹©è®°å¿†æ–¹æ¡ˆ] --> B{å¯¹è¯é•¿åº¦ï¼Ÿ}
    B -->|çŸ­å¯¹è¯ < 10è½®| C[BufferMemory]
    B -->|é•¿å¯¹è¯ > 10è½®| D{æ˜¯å¦éœ€è¦å®Œæ•´å†å²ï¼Ÿ}
    
    D -->|æ˜¯| E{æ˜¯å¦æœ‰å…³é”®æ—©æœŸä¿¡æ¯ï¼Ÿ}
    E -->|æ˜¯| F[VectorMemory]
    E -->|å¦| G[WindowMemory]
    
    D -->|å¦| H{æ˜¯å¦æ¥å—é¢å¤–å»¶è¿Ÿï¼Ÿ}
    H -->|æ˜¯| I[SummaryMemory]
    H -->|å¦| J[WindowMemory]
```

## ğŸ¯ ç¬¬å››ç« ï¼šå®æˆ˜æ¡ˆä¾‹ä¸æœ€ä½³å®è·µ

### 4.1 æ™ºèƒ½å®¢æœæœºå™¨äºº

**åœºæ™¯æè¿°ï¼š** ç”µå•†å®¢æœéœ€è¦è®°ä½ç”¨æˆ·çš„è®¢å•ä¿¡æ¯ã€å†å²å’¨è¯¢ã€ä¸ªäººåå¥½

```python
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

# å®¢æœä¸“ç”¨è®°å¿†é…ç½®
class CustomerServiceMemory:
    def __init__(self):
        # åŸºç¡€ä¿¡æ¯è®°å¿†ï¼ˆé•¿æœŸï¼‰
        self.profile_memory = ConversationBufferMemory(
            memory_key="user_profile",
            return_messages=True
        )
        
        # å½“å‰ä¼šè¯è®°å¿†ï¼ˆçŸ­æœŸï¼‰
        self.session_memory = ConversationBufferWindowMemory(
            k=5,
            memory_key="chat_history",
            return_messages=True
        )
    
    def get_prompt(self):
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†å®¢æœåŠ©æ‰‹ã€‚
            ç”¨æˆ·ä¿¡æ¯: {user_profile}
            è¯·åŸºäºç”¨æˆ·çš„å†å²ä¿¡æ¯æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}")
        ])
        return prompt

# ä½¿ç”¨ç¤ºä¾‹
service = CustomerServiceMemory()

# å­˜å‚¨ç”¨æˆ·ä¿¡æ¯
service.profile_memory.save_context(
    {"input": "æˆ‘çš„ä¼šå‘˜ç­‰çº§æ˜¯VIP3ï¼Œç»å¸¸ä¹°ç”µå­äº§å“"},
    {"output": "å·²è®°å½•æ‚¨çš„VIP3èº«ä»½å’Œç”µå­äº§å“åå¥½"}
)
```

### 4.2 ä¸ªäººå­¦ä¹ åŠ©æ‰‹

**åœºæ™¯æè¿°ï¼š** è®°ä½ç”¨æˆ·çš„å­¦ä¹ è¿›åº¦ã€è–„å¼±ç‚¹ã€åå¥½ç§‘ç›®

```python
from datetime import datetime
import json

class LearningAssistantMemory:
    def __init__(self):
        self.progress_tracker = {}  # å­¦ä¹ è¿›åº¦
        self.weak_points = []      # è–„å¼±çŸ¥è¯†ç‚¹
        self.preferences = {}      # å­¦ä¹ åå¥½
        
    def update_progress(self, topic, score):
        """æ›´æ–°å­¦ä¹ è¿›åº¦"""
        if topic not in self.progress_tracker:
            self.progress_tracker[topic] = []
        
        self.progress_tracker[topic].append({
            "score": score,
            "timestamp": datetime.now().isoformat()
        })
        
        # å¦‚æœåˆ†æ•°ä½äº60åˆ†ï¼Œæ ‡è®°ä¸ºè–„å¼±ç‚¹
        if score < 60 and topic not in self.weak_points:
            self.weak_points.append(topic)
    
    def get_study_plan(self):
        """åŸºäºè®°å¿†ç”Ÿæˆå­¦ä¹ è®¡åˆ’"""
        plan = {
            "next_topics": self.weak_points[:3],
            "strong_topics": [t for t in self.progress_tracker 
                            if t not in self.weak_points],
            "recommendations": []
        }
        
        if len(self.weak_points) > 3:
            plan["recommendations"].append(
                "å»ºè®®é‡ç‚¹å¤ä¹ è–„å¼±çŸ¥è¯†ç‚¹"
            )
        
        return plan

# ä½¿ç”¨ç¤ºä¾‹
assistant = LearningAssistantMemory()
assistant.update_progress("PythonåŸºç¡€", 85)
assistant.update_progress("æ•°æ®ç»“æ„", 45)
assistant.update_progress("ç®—æ³•", 72)

print("å­¦ä¹ è®¡åˆ’:", json.dumps(assistant.get_study_plan(), 
                           ensure_ascii=False, indent=2))
```

## ğŸ”® ç¬¬äº”ç« ï¼šæœªæ¥å‘å±•è¶‹åŠ¿

### 5.1 æ–°å…´è®°å¿†æŠ€æœ¯

1. **åˆ†å±‚è®°å¿†æ¶æ„**
   - å·¥ä½œè®°å¿†ï¼ˆçŸ­æœŸï¼‰
   - æƒ…æ™¯è®°å¿†ï¼ˆä¸­æœŸï¼‰
   - è¯­ä¹‰è®°å¿†ï¼ˆé•¿æœŸï¼‰

2. **è‡ªé€‚åº”è®°å¿†å‹ç¼©**
   - æ ¹æ®é‡è¦æ€§åŠ¨æ€è°ƒæ•´å‹ç¼©ç‡
   - å…³é”®ä¿¡æ¯æ— æŸå­˜å‚¨

3. **å¤šæ¨¡æ€è®°å¿†**
   - æ•´åˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘è®°å¿†
   - è·¨æ¨¡æ€æ£€ç´¢

### 5.2 æ€§èƒ½ä¼˜åŒ–æ–¹å‘

```mermaid
graph LR
    A[å½“å‰æŒ‘æˆ˜] --> B[Tokenæˆæœ¬]
    A --> C[å“åº”å»¶è¿Ÿ]
    A --> D[å­˜å‚¨æ•ˆç‡]
    
    B --> E[æ™ºèƒ½ç¼“å­˜ç­–ç•¥]
    C --> F[é¢„è®¡ç®—æ‘˜è¦]
    D --> G[å¢é‡æ›´æ–°æœºåˆ¶]
```

## ğŸ“‹ ç¬¬å…­ç« ï¼šå¿«é€Ÿä¸Šæ‰‹æŒ‡å—

### 6.1 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–
pip install langchain langchain-openai tiktoken chromadb

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your-api-key"

# 3. è¿è¡Œç¤ºä¾‹
python -c "
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain

llm = ChatOpenAI()
memory = ConversationBufferMemory()
chain = ConversationChain(llm=llm, memory=memory)

print(chain.predict(input='ä½ å¥½ï¼Œæˆ‘æ˜¯ç¨‹åºå‘˜å°ç‹'))
print(chain.predict(input='è®°ä½æˆ‘çš„èŒä¸šäº†å—ï¼Ÿ'))
"
```

### 6.2 è°ƒè¯•æŠ€å·§

```python
# è°ƒè¯•è®°å¿†å†…å®¹
def debug_memory(memory):
    """è°ƒè¯•è®°å¿†å†…å®¹çš„å®ç”¨å‡½æ•°"""
    variables = memory.load_memory_variables({})
    print("=== è®°å¿†å†…å®¹è°ƒè¯• ===")
    for key, value in variables.items():
        print(f"{key}: {value}")
    
    # å¦‚æœæ˜¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
    if isinstance(value, list):
        for i, msg in enumerate(value):
            print(f"  {i+1}. [{msg.__class__.__name__}] {msg.content[:100]}...")

# ä½¿ç”¨ç¤ºä¾‹
debug_memory(memory)
```

## ğŸ“ æ€»ç»“ä¸è¡ŒåŠ¨æŒ‡å—

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **è®°å¿†çš„å¿…è¦æ€§**ï¼šè®©AIä»"è®¡ç®—å™¨"å˜æˆ"ä¼™ä¼´"
2. **å››ç§æ–¹æ¡ˆ**ï¼šBufferã€Windowã€Summaryã€Vectorï¼Œå„æœ‰ä¼˜åŠ£
3. **é€‰æ‹©åŸåˆ™**ï¼šæ ¹æ®å¯¹è¯é•¿åº¦ã€æˆæœ¬ã€ç²¾åº¦éœ€æ±‚é€‰æ‹©
4. **å®æˆ˜åº”ç”¨**ï¼šå®¢æœã€æ•™è‚²ã€ä¸ªäººåŠ©æ‰‹ç­‰åœºæ™¯

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å°è¯•**ï¼šç”¨5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹ä»£ç ä½“éªŒ
2. **æ·±å…¥å­¦ä¹ **ï¼šé€‰æ‹©ä¸€ä¸ªå®é™…é¡¹ç›®åº”ç”¨
3. **ç¤¾åŒºäº¤æµ**ï¼šåˆ†äº«ä½ çš„ä½¿ç”¨ç»éªŒ
4. **æŒç»­å…³æ³¨**ï¼šå…³æ³¨LangChainçš„æ›´æ–°å’Œæ–°ç‰¹æ€§

---

<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white; margin: 30px 0;">
<h3 style="color: white; margin-top: 0;">ğŸ’¡ æ€è€ƒé¢˜</h3>
<p>å¦‚æœä½ è¦è®¾è®¡ä¸€ä¸ªåŒ»ç–—å’¨è¯¢AIï¼Œéœ€è¦è®°ä½ç—…äººçš„ç—…å²ã€ç”¨è¯è®°å½•ã€è¿‡æ•ä¿¡æ¯ï¼Œä½ ä¼šé€‰æ‹©å“ªç§è®°å¿†æ–¹æ¡ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ</p>
<p><em>æ¬¢è¿åœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„æƒ³æ³•ï¼</em></p>
</div>

### ğŸ“š å»¶ä¼¸é˜…è¯»èµ„æº

- [LangChainå®˜æ–¹æ–‡æ¡£ - Memory](https://python.langchain.com/docs/modules/memory/)
- [å‘é‡æ•°æ®åº“é€‰å‹æŒ‡å—](https://zilliz.com/learn/vector-database)
- [å¤§æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ–](https://platform.openai.com/docs/guides/rate-limits)
- [è®°å¿†æœºåˆ¶è®ºæ–‡åˆé›†](https://arxiv.org/list/cs.AI/recent)

<div style="text-align: center; margin: 40px 0;">
<p><strong>å¦‚æœè¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ï¼Œåˆ«å¿˜äº†ç‚¹èµæ”¶è—ï¼</strong></p>
<p>æœ‰é—®é¢˜å¯ä»¥åœ¨è¯„è®ºåŒºç•™è¨€ï¼Œæˆ‘ä¼šä¸€ä¸€è§£ç­”ã€‚</p>
</div>
