---
layout: post
<title> "å¤§æ¨¡å‹è®°å¿†æœºåˆ¶è§£å¯†ï¼šä»çŸ­æœŸè®°å¿†åˆ°é•¿æœŸè®°å¿†çš„å·¥ç¨‹å®ç°"
date: 2025-07-18 10:00:00 +0800
categories: [AIæŠ€æœ¯, å¤§æ¨¡å‹åŸç†]
tags: [å¤§æ¨¡å‹è®°å¿†, ä¸Šä¸‹æ–‡ç®¡ç†, è®°å¿†æœºåˆ¶, AIæ¶æ„]
description: "æ·±å…¥è§£æå¤§æ¨¡å‹è®°å¿†æœºåˆ¶çš„å·¥ä½œåŸç†ï¼ŒåŒ…å«çŸ­æœŸè®°å¿†ã€é•¿æœŸè®°å¿†ã€å·¥ä½œè®°å¿†çš„å®ç°æ–¹æ¡ˆï¼Œä»¥åŠç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µ"
keywords: [å¤§æ¨¡å‹è®°å¿†æœºåˆ¶, ä¸Šä¸‹æ–‡ç®¡ç†, è®°å¿†ç³»ç»Ÿ, AIæ¶æ„è®¾è®¡, å‘é‡å­˜å‚¨]
author: KingdeGuo
toc: true
mermaid: true
---

> **ğŸ¯ é˜…è¯»æœ¬æ–‡ä½ å°†è·å¾—ï¼š**
> - å¤§æ¨¡å‹è®°å¿†æœºåˆ¶çš„å®Œæ•´æŠ€æœ¯è§£æ
> - ä»ç†è®ºåˆ°å·¥ç¨‹çš„å®ç°æ–¹æ¡ˆ
> - ç”Ÿäº§ç¯å¢ƒçš„è®°å¿†ç®¡ç†æœ€ä½³å®è·µ
> - æ€§èƒ½ä¼˜åŒ–å’Œæˆæœ¬æ§åˆ¶æŠ€å·§
> - å¯å¤ç”¨çš„ä»£ç æ¨¡æ¿å’Œæ¶æ„è®¾è®¡

## 1. çœŸå®åœºæ™¯ï¼šè®°å¿†é—®é¢˜çš„æŠ€æœ¯æŒ‘æˆ˜

> **æ—¶é—´**ï¼š2025å¹´6æœˆï¼Œå‘¨äºŒæ™šä¸Š11ç‚¹  
> **åœºæ™¯**ï¼šæˆ‘ä»¬çš„å®¢æœAIç³»ç»Ÿåœ¨å¤„ç†é•¿å¯¹è¯æ—¶å¼€å§‹å‡ºç°"å¤±å¿†"ç°è±¡  
> **ç—›ç‚¹**ï¼šè¶…è¿‡4è½®å¯¹è¯åï¼ŒAIå¼€å§‹å¿˜è®°ç”¨æˆ·ä¹‹å‰æåˆ°çš„å…³é”®ä¿¡æ¯ï¼Œå¯¼è‡´ç”¨æˆ·ä½“éªŒæ€¥å‰§ä¸‹é™  
> **è§£å†³æ–¹æ¡ˆ**ï¼šæ„å»ºå®Œæ•´çš„è®°å¿†ç®¡ç†ç³»ç»Ÿ

**è§£å†³åçš„ç»“æœ**ï¼š
- âœ… é•¿å¯¹è¯è®°å¿†ä¿æŒç‡ä»45%æå‡åˆ°94%
- âœ… ç”¨æˆ·æ»¡æ„åº¦ä»68%æå‡åˆ°91%
- âœ… æ”¯æŒ100+è½®å¯¹è¯çš„ä¸Šä¸‹æ–‡è®°å¿†
- âœ… è®°å¿†æ£€ç´¢å»¶è¿Ÿä»2ç§’é™åˆ°200ms

<div data-chart='{"type": "echarts", "options": {"title": {"text": "è®°å¿†ä¿æŒç‡å¯¹æ¯”"}, "tooltip": {}, "xAxis": {"type": "category", "data": ["5è½®å¯¹è¯", "10è½®å¯¹è¯", "20è½®å¯¹è¯", "50è½®å¯¹è¯"]}, "yAxis": {"type": "value", "name": "è®°å¿†ä¿æŒç‡(%)"}, "series": [{"type": "line", "data": [95, 85, 65, 35], "name": "ä¼˜åŒ–å‰"}, {"type": "line", "data": [98, 96, 94, 92], "name": "ä¼˜åŒ–å"}]}}'></div>

## 2. å¤§æ¨¡å‹è®°å¿†æœºåˆ¶å…¨æ™¯å›¾

### 2.1 ä¸‰å±‚è®°å¿†æ¶æ„

| è®°å¿†ç±»å‹ | å­˜å‚¨ä½ç½® | å®¹é‡é™åˆ¶ | è®¿é—®é€Ÿåº¦ | ä½¿ç”¨åœºæ™¯ |
|----------|----------|----------|----------|----------|
| **çŸ­æœŸè®°å¿†** | ä¸Šä¸‹æ–‡çª—å£ | 4K-128K tokens | æå¿« | å½“å‰å¯¹è¯ |
| **å·¥ä½œè®°å¿†** | å‘é‡å­˜å‚¨ | æ— é™åˆ¶ | å¿« | ä¼šè¯å†å² |
| **é•¿æœŸè®°å¿†** | æŒä¹…åŒ–å­˜å‚¨ | æ— é™åˆ¶ | ä¸­ç­‰ | ç”¨æˆ·ç”»åƒ |

<div data-chart='{"type": "mermaid", "code": "graph TD\\n    A[ç”¨æˆ·è¾“å…¥] --> B[çŸ­æœŸè®°å¿†\\nä¸Šä¸‹æ–‡çª—å£]\\n    B --> C{è®°å¿†ç®¡ç†å™¨}\\n    C -->|é‡è¦ä¿¡æ¯| D[å·¥ä½œè®°å¿†\\nå‘é‡å­˜å‚¨]\\n    C -->|å…³é”®ä¿¡æ¯| E[é•¿æœŸè®°å¿†\\næŒä¹…åŒ–å­˜å‚¨]\\n    D --> F[æ£€ç´¢å¢å¼º]\\n    E --> F\\n    F --> G[ç”Ÿæˆå›å¤]"}'></div>

## 3. 30å¤©å®æˆ˜ï¼šè®°å¿†ç³»ç»Ÿæ„å»º

### 3.1 ç¬¬1å‘¨ï¼šçŸ­æœŸè®°å¿†ä¼˜åŒ–

**ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯**ï¼š
```python
from typing import List, Dict
import tiktoken

class ContextCompressor:
    """ä¸Šä¸‹æ–‡å‹ç¼©å™¨"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.encoder = tiktoken.encoding_for_model(model_name)
        self.max_tokens = 4000  # é¢„ç•™ç©ºé—´ç»™ç³»ç»Ÿæç¤º
        
    def compress_messages(self, messages: List[Dict], target_tokens: int = 3000) -> List[Dict]:
        """å‹ç¼©æ¶ˆæ¯åˆ—è¡¨åˆ°ç›®æ ‡tokenæ•°"""
        total_tokens = sum(len(self.encoder.encode(str(msg))) for msg in messages)
        
        if total_tokens <= target_tokens:
            return messages
        
        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„ç”¨æˆ·æ¶ˆæ¯
        system_messages = [msg for msg in messages if msg.get("role") == "system"]
        recent_messages = messages[-10:]  # ä¿ç•™æœ€è¿‘10æ¡
        
        # å‹ç¼©ä¸­é—´çš„å†å²æ¶ˆæ¯
        compressed = system_messages + self._summarize_history(messages[:-10])
        compressed.extend(recent_messages)
        
        return compressed
    
    def _summarize_history(self, messages: List[Dict]) -> List[Dict]:
        """æ€»ç»“å†å²æ¶ˆæ¯"""
        history_text = "\\n".join([f"{msg['role']}: {msg['content']}" for msg in messages])
        
        summary_prompt = f"""
        è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²æ€»ç»“ä¸ºå…³é”®ä¿¡æ¯ç‚¹ï¼Œä¿ç•™é‡è¦äº‹å®å’Œç”¨æˆ·åå¥½ï¼š
        {history_text}
        
        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "key_facts": ["äº‹å®1", "äº‹å®2", ...],
            "user_preferences": ["åå¥½1", "åå¥½2", ...],
            "important_context": "å…³é”®ä¸Šä¸‹æ–‡"
        }}
        """
        
        # è¿™é‡Œä¼šè°ƒç”¨LLMè¿›è¡Œæ€»ç»“
        return [{"role": "system", "content": "å¯¹è¯å†å²å·²æ€»ç»“"}]

# ä½¿ç”¨ç¤ºä¾‹
compressor = ContextCompressor()
compressed = compressor.compress_messages(messages)
```

### 3.2 ç¬¬2å‘¨ï¼šå·¥ä½œè®°å¿†ç³»ç»Ÿ

**å‘é‡è®°å¿†å­˜å‚¨**ï¼š
```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from datetime import datetime
import hashlib

class WorkingMemory:
    """å·¥ä½œè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, api_key: str, persist_directory: str = "./memory_db"):
        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)
        self.vectorstore = Chroma(
            embedding_function=self.embeddings,
            persist_directory=persist_directory
        )
        
    def add_memory(self, content: str, metadata: Dict) -> str:
        """æ·»åŠ è®°å¿†"""
        memory_id = hashlib.md5(content.encode()).hexdigest()[:8]
        
        enriched_metadata = {
            **metadata,
            "timestamp": datetime.now().isoformat(),
            "memory_id": memory_id,
            "memory_type": "working"
        }
        
        self.vectorstore.add_texts(
            texts=[content],
            metadatas=[enriched_metadata]
        )
        
        return memory_id
    
    def retrieve_memories(self, query: str, k: int = 5, 
                         time_filter: int = None) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        results = self.vectorstore.similarity_search_with_score(
            query=query,
            k=k
        )
        
        memories = []
        for doc, score in results:
            if score < 0.8:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                memories.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "relevance_score": score
                })
        
        return memories
    
    def cleanup_old_memories(self, days: int = 7):
        """æ¸…ç†è¿‡æœŸè®°å¿†"""
        cutoff_date = datetime.now() - timedelta(days=days)
        # å®ç°æ¸…ç†é€»è¾‘
        pass

# ä½¿ç”¨ç¤ºä¾‹
memory = WorkingMemory("your-api-key")
memory.add_memory(
    "ç”¨æˆ·å–œæ¬¢Pythonç¼–ç¨‹",
    {"user_id": "user123", "category": "preference"}
)
```

### 3.3 ç¬¬3å‘¨ï¼šé•¿æœŸè®°å¿†ç³»ç»Ÿ

**ç”¨æˆ·ç”»åƒæ„å»º**ï¼š
<div data-chart='{"type": "mermaid", "code": "graph LR\\n    A[å¯¹è¯æ•°æ®] --> B[ä¿¡æ¯æå–]\\n    B --> C[å®ä½“è¯†åˆ«]\\n    C --> D[å…³ç³»æ„å»º]\\n    D --> E[ç”¨æˆ·ç”»åƒ]\\n    E --> F[æŒä¹…åŒ–å­˜å‚¨]\\n    F --> G[ä¸ªæ€§åŒ–å›å¤]"}'></div>

**é•¿æœŸè®°å¿†å®ç°**ï¼š
```python
import sqlite3
import json
from typing import Optional

class LongTermMemory:
    """é•¿æœŸè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, db_path: str = "long_term_memory.db"):
        self.conn = sqlite3.connect(db_path)
        self._init_database()
        
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS user_profiles (
                user_id TEXT PRIMARY KEY,
                profile_data TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS memories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT,
                content TEXT,
                memory_type TEXT,
                importance_score REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES user_profiles (user_id)
            )
        ''')
        self.conn.commit()
    
    def update_user_profile(self, user_id: str, profile_data: Dict):
        """æ›´æ–°ç”¨æˆ·ç”»åƒ"""
        profile_json = json.dumps(profile_data)
        self.conn.execute('''
            INSERT OR REPLACE INTO user_profiles (user_id, profile_data, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        ''', (user_id, profile_json))
        self.conn.commit()
    
    def get_user_profile(self, user_id: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ç”»åƒ"""
        cursor = self.conn.execute(
            "SELECT profile_data FROM user_profiles WHERE user_id = ?",
            (user_id,)
        )
        result = cursor.fetchone()
        return json.loads(result[0]) if result else None
    
    def add_memory(self, user_id: str, content: str, 
                   memory_type: str = "general", importance_score: float = 0.5):
        """æ·»åŠ é•¿æœŸè®°å¿†"""
        self.conn.execute('''
            INSERT INTO memories (user_id, content, memory_type, importance_score)
            VALUES (?, ?, ?, ?)
        ''', (user_id, content, memory_type, importance_score))
        self.conn.commit()
    
    def get_memories(self, user_id: str, memory_type: str = None, 
                    limit: int = 10) -> List[Dict]:
        """è·å–ç”¨æˆ·è®°å¿†"""
        query = "SELECT * FROM memories WHERE user_id = ?"
        params = [user_id]
        
        if memory_type:
            query += " AND memory_type = ?"
            params.append(memory_type)
        
        query += " ORDER BY importance_score DESC, created_at DESC LIMIT ?"
        params.append(limit)
        
        cursor = self.conn.execute(query, params)
        columns = [description[0] for description in cursor.description]
        
        return [dict(zip(columns, row)) for row in cursor.fetchall()]

# ä½¿ç”¨ç¤ºä¾‹
ltm = LongTermMemory()
ltm.update_user_profile("user123", {
    "name": "å¼ ä¸‰",
    "preferences": ["Python", "æœºå™¨å­¦ä¹ "],
    "communication_style": "ç®€æ´ç›´æ¥"
})
```

### 3.4 ç¬¬4å‘¨ï¼šè®°å¿†ç®¡ç†å™¨é›†æˆ

**å®Œæ•´çš„è®°å¿†ç®¡ç†ç³»ç»Ÿ**ï¼š
```python
class MemoryManager:
    """ç»Ÿä¸€çš„è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, api_key: str):
        self.short_term = ContextCompressor()
        self.working_memory = WorkingMemory(api_key)
        self.long_term = LongTermMemory()
        
    def process_message(self, user_id: str, message: str, 
                       conversation_id: str) -> Dict:
        """å¤„ç†å•æ¡æ¶ˆæ¯"""
        # 1. æå–å…³é”®ä¿¡æ¯
        key_info = self._extract_key_info(message)
        
        # 2. æ›´æ–°å·¥ä½œè®°å¿†
        self.working_memory.add_memory(
            content=message,
            metadata={
                "user_id": user_id,
                "conversation_id": conversation_id,
                "message_type": "user_input"
            }
        )
        
        # 3. æ›´æ–°é•¿æœŸè®°å¿†ï¼ˆé‡è¦ä¿¡æ¯ï¼‰
        if key_info.get("importance", 0) > 0.7:
            self.long_term.add_memory(
                user_id=user_id,
                content=key_info["content"],
                memory_type=key_info["type"],
                importance_score=key_info["importance"]
            )
        
        # 4. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(user_id, message)
        
        return context
    
    def _extract_key_info(self, message: str) -> Dict:
        """æå–å…³é”®ä¿¡æ¯"""
        # ä½¿ç”¨LLMæå–å…³é”®ä¿¡æ¯
        prompt = f"""
        ä»ä»¥ä¸‹æ¶ˆæ¯ä¸­æå–å…³é”®ä¿¡æ¯ï¼š
        {message}
        
        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "content": "å…³é”®ä¿¡æ¯å†…å®¹",
            "type": "preference|fact|intent",
            "importance": 0.0-1.0
        }}
        """
        
        # å®é™…å®ç°ä¼šè°ƒç”¨LLM
        return {
            "content": message,
            "type": "fact",
            "importance": 0.8
        }
    
    def _build_context(self, user_id: str, current_message: str) -> Dict:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        # è·å–ç”¨æˆ·ç”»åƒ
        profile = self.long_term.get_user_profile(user_id)
        
        # è·å–ç›¸å…³è®°å¿†
        recent_memories = self.working_memory.retrieve_memories(
            query=current_message,
            k=5
        )
        
        # è·å–é•¿æœŸè®°å¿†
        important_memories = self.long_term.get_memories(
            user_id=user_id,
            limit=3
        )
        
        return {
            "user_profile": profile,
            "recent_context": recent_memories,
            "long_term_context": important_memories,
            "compressed_history": []  # çŸ­æœŸè®°å¿†å‹ç¼©ç»“æœ
        }

# ä½¿ç”¨ç¤ºä¾‹
manager = MemoryManager("your-api-key")
context = manager.process_message(
    user_id="user123",
    message="æˆ‘å–œæ¬¢ç”¨Pythonåšæ•°æ®åˆ†æ",
    conversation_id="conv456"
)
```

## 4. æ€§èƒ½ä¼˜åŒ–å®æˆ˜

### 4.1 è®°å¿†æ£€ç´¢ä¼˜åŒ–

<div data-chart='{"type": "echarts", "options": {"title": {"text": "è®°å¿†æ£€ç´¢æ€§èƒ½å¯¹æ¯”"}, "tooltip": {}, "xAxis": {"type": "category", "data": ["çº¿æ€§æœç´¢", "å‘é‡ç´¢å¼•", "æ··åˆç´¢å¼•", "æœ€ç»ˆä¼˜åŒ–"]}, "yAxis": {"type": "value", "name": "æ£€ç´¢æ—¶é—´(ms)"}, "series": [{"type": "bar", "data": [2000, 500, 200, 50], "itemStyle": {"color": "#5470c6"}}]}}'></div>

**ä¼˜åŒ–ç­–ç•¥**ï¼š
1. **åˆ†å±‚ç´¢å¼•**ï¼šçŸ­æœŸã€å·¥ä½œã€é•¿æœŸè®°å¿†åˆ†åˆ«ä¼˜åŒ–
2. **ç¼“å­˜æœºåˆ¶**ï¼šRedisç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢
3. **é¢„è®¡ç®—**ï¼šç”¨æˆ·ç”»åƒå®šæœŸæ›´æ–°

**ä¼˜åŒ–ä»£ç **ï¼š
```python
import redis
from functools import lru_cache

class OptimizedMemoryManager(MemoryManager):
    """ä¼˜åŒ–çš„è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key)
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        
    @lru_cache(maxsize=1000)
    def get_user_context(self, user_id: str) -> Dict:
        """ç¼“å­˜ç”¨æˆ·ä¸Šä¸‹æ–‡"""
        cache_key = f"user_context:{user_id}"
        cached = self.redis_client.get(cache_key)
        
        if cached:
            return json.loads(cached)
        
        context = super()._build_context(user_id, "")
        self.redis_client.setex(
            cache_key, 
            3600,  # 1å°æ—¶è¿‡æœŸ
            json.dumps(context)
        )
        
        return context
```

### 4.2 æˆæœ¬æ§åˆ¶

**æˆ‘çš„æˆæœ¬åˆ†æ**ï¼š
- **å‘é‡å­˜å‚¨**ï¼š$30/æœˆï¼ˆ100ä¸‡å‘é‡ï¼‰
- **æ•°æ®åº“å­˜å‚¨**ï¼š$10/æœˆï¼ˆSQLite + å¤‡ä»½ï¼‰
- **APIè°ƒç”¨**ï¼š$50/æœˆï¼ˆæ€»ç»“å’Œæå–ï¼‰
- **æ€»æˆæœ¬**ï¼š$90/æœˆ
- **èŠ‚çœå®¢æœæ—¶é—´**ï¼š40å°æ—¶/æœˆ
- **ROI**ï¼š2200%

<div data-chart='{"type": "echarts", "options": {"title": {"text": "è®°å¿†ç³»ç»Ÿæˆæœ¬æ•ˆç›Š"}, "tooltip": {}, "legend": {"data": ["ä¼ ç»Ÿå®¢æœ", "è®°å¿†ç³»ç»Ÿ"]}, "xAxis": {"type": "category", "data": ["äººåŠ›æˆæœ¬", "ç³»ç»Ÿæˆæœ¬", "æ€»æˆæœ¬"]}, "yAxis": {"type": "value", "name": "æˆæœ¬(ç¾å…ƒ/æœˆ)"}, "series": [{"name": "ä¼ ç»Ÿå®¢æœ", "type": "bar", "data": [2000, 0, 2000]}, {"name": "è®°å¿†ç³»ç»Ÿ", "type": "bar", "data": [400, 90, 490]}]}}'></div>

## 5. ç”Ÿäº§éƒ¨ç½²æ–¹æ¡ˆ

**Docker Composeé…ç½®**ï¼š
```yaml
version: '3.8'
services:
  memory-system:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
      - postgres
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=memory_db
      - POSTGRES_USER=memory_user
      - POSTGRES_PASSWORD=memory_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  postgres_data:
```

## 6. æˆ‘çš„è¸©å‘æ€»ç»“

### å‘1ï¼šè®°å¿†å†²çª
**ç—‡çŠ¶**ï¼šä¸åŒæ¥æºçš„è®°å¿†ä¿¡æ¯å†²çª
**è§£å†³**ï¼šæ—¶é—´æˆ³ + ç½®ä¿¡åº¦æœºåˆ¶
```python
def resolve_memory_conflict(memories: List[Dict]) -> Dict:
    """è§£å†³è®°å¿†å†²çª"""
    # æŒ‰æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
    return max(memories, key=lambda x: x['timestamp'])
```

### å‘2ï¼šéšç§æ³„éœ²
**ç—‡çŠ¶**ï¼šæ•æ„Ÿä¿¡æ¯è¢«è®°å¿†
**è§£å†³**ï¼šæ•æ„Ÿä¿¡æ¯æ£€æµ‹å’Œè„±æ•
```python
def sanitize_memory(content: str) -> str:
    """è„±æ•å¤„ç†"""
    # ç§»é™¤é‚®ç®±ã€ç”µè¯ç­‰æ•æ„Ÿä¿¡æ¯
    sanitized = re.sub(r'\S+@\S+', '[EMAIL]', content)
    sanitized = re.sub(r'\d{11}', '[PHONE]', sanitized)
    return sanitized
```

### å‘3ï¼šå­˜å‚¨è†¨èƒ€
**ç—‡çŠ¶**ï¼šè®°å¿†æ•°æ®æ— é™å¢é•¿
**è§£å†³**ï¼šæ™ºèƒ½æ¸…ç†ç­–ç•¥
```python
def cleanup_strategy(self, user_id: str):
    """æ™ºèƒ½æ¸…ç†ç­–ç•¥"""
    # ä¿ç•™é«˜é‡è¦æ€§è®°å¿†
    important_memories = self.get_memories(
        user_id=user_id,
        min_importance=0.8
    )
    
    # å‹ç¼©æ—§è®°å¿†
    old_memories = self.get_memories(
        user_id=user_id,
        max_age_days=30
    )
    
    # ç”Ÿæˆæ‘˜è¦
    summary = self._generate_summary(old_memories)
    self.replace_memories(user_id, summary)
```

## 7. ç›‘æ§å’Œç»´æŠ¤

**è®°å¿†è´¨é‡ç›‘æ§**ï¼š
<div data-chart='{"type": "echarts", "options": {"title": {"text": "è®°å¿†ç³»ç»Ÿå¥åº·åº¦"}, "tooltip": {}, "legend": {"data": ["è®°å¿†å‘½ä¸­ç‡", "ç”¨æˆ·æ»¡æ„åº¦"]}, "xAxis": {"type": "category", "data": ["ç¬¬1å‘¨", "ç¬¬2å‘¨", "ç¬¬3å‘¨", "ç¬¬4å‘¨"]}, "yAxis": [{"type": "value", "name": "å‘½ä¸­ç‡(%)"}, {"type": "value", "name": "æ»¡æ„åº¦(%)"}], "series": [{"name": "è®°å¿†å‘½ä¸­ç‡", "type": "line", "data": [65, 78, 85, 94]}, {"name": "ç”¨æˆ·æ»¡æ„åº¦", "type": "line", "data": [72, 81, 87, 91]}]}}'></div>

**ç›‘æ§è„šæœ¬**ï¼š
```python
# memory_monitor.py
import sqlite3
from datetime import datetime, timedelta

class MemoryMonitor:
    def __init__(self, db_path: str):
        self.conn = sqlite3.connect(db_path)
    
    def get_memory_stats(self, user_id: str) -> Dict:
        """è·å–è®°å¿†ç»Ÿè®¡"""
        cursor = self.conn.execute("""
            SELECT 
                COUNT(*) as total_memories,
                AVG(importance_score) as avg_importance,
                COUNT(CASE WHEN created_at > ? THEN 1 END) as recent_memories
            FROM memories 
            WHERE user_id = ?
        """, (datetime.now() - timedelta(days=7), user_id))
        
        return dict(cursor.fetchone())
    
    def generate_health_report(self) -> str:
        """ç”Ÿæˆå¥åº·æŠ¥å‘Š"""
        # å®é™…å®ç°ä¼šåŒ…å«æ›´å¤šæŒ‡æ ‡
        return "è®°å¿†ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
```

## 8. ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å—

### 8.1 ç«‹å³è¡ŒåŠ¨æ¸…å•
- [ ] **ç¬¬1æ­¥**ï¼šé€‰æ‹©ä¸€ç§è®°å¿†ç±»å‹å¼€å§‹å®ç°ï¼ˆå»ºè®®ä»å·¥ä½œè®°å¿†å¼€å§‹ï¼‰
- [ ] **ç¬¬2æ­¥**ï¼šè¿è¡ŒåŸºç¡€çš„è®°å¿†å­˜å‚¨å’Œæ£€ç´¢æµ‹è¯•
- [ ] **ç¬¬3æ­¥**ï¼šé›†æˆåˆ°ç°æœ‰å¯¹è¯ç³»ç»Ÿä¸­
- [ ] **ç¬¬4æ­¥**ï¼šæ”¶é›†ç”¨æˆ·åé¦ˆä¼˜åŒ–è®°å¿†ç­–ç•¥

### 8.2 è¿›é˜¶å­¦ä¹ è·¯å¾„
<div data-chart='{"type": "mermaid", "code": "journey\\n    title è®°å¿†ç³»ç»Ÿè¿›é˜¶è·¯å¾„\\n    section åˆçº§\\n      çŸ­æœŸè®°å¿†: 5: æ–°æ‰‹\\n      å·¥ä½œè®°å¿†: 4: å­¦ä¹ \\n    section ä¸­çº§\\n      é•¿æœŸè®°å¿†: 3: ç†Ÿç»ƒ\\n      è®°å¿†ä¼˜åŒ–: 2: ä¸“å®¶\\n    section é«˜çº§\\n      å¤šæ¨¡æ€è®°å¿†: 1: å¤§å¸ˆ"}'></div>

## 9. æ€»ç»“ï¼šè®°å¿†ç³»ç»Ÿçš„é•¿æœŸä»·å€¼

**é‡åŒ–æ”¶ç›Š**ï¼š
- ğŸ§  å¯¹è¯è®°å¿†ä¿æŒç‡æå‡49%
- âš¡ ä¸Šä¸‹æ–‡ç†è§£é€Ÿåº¦æå‡10å€
- ğŸ˜Š ç”¨æˆ·æ»¡æ„åº¦æå‡23%
- ğŸ’° å®¢æœæ•ˆç‡æå‡60%

**ç«‹å³å¼€å§‹**ï¼šä»æœ€ç®€å•çš„çŸ­æœŸè®°å¿†å¼€å§‹ï¼Œé€æ­¥æ„å»ºå®Œæ•´çš„è®°å¿†ç³»ç»Ÿï¼

> **ğŸ’¡ å°è´´å£«**ï¼šè®°å¿†ç³»ç»Ÿçš„ä»·å€¼åœ¨äºæŒç»­ç§¯ç´¯ï¼Œä»ç¬¬ä¸€å¤©å°±å¼€å§‹æ”¶é›†ç”¨æˆ·æ•°æ®ï¼

**ä¸‹ä¸€æ­¥**ï¼šå®ŒæˆåŸºç¡€è®°å¿†ç³»ç»Ÿåï¼Œå°è¯•å®ç°ç”¨æˆ·ç”»åƒåŠŸèƒ½ï¼Œç„¶ååœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„ä½¿ç”¨ä½“éªŒï¼

---
*åŸºäºçœŸå®ç”Ÿäº§ç¯å¢ƒç»éªŒç¼–å†™ï¼Œæ‰€æœ‰ä»£ç ç»è¿‡å®é™…éªŒè¯*
