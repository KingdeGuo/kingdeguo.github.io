---
layout: post
title: "æ·±å…¥æµ…å‡º LangChainï¼šä»å°ç™½åˆ°é«˜æ‰‹ï¼Œæ„å»ºä½ çš„ç¬¬ä¸€ä¸ª LLM åº”ç”¨"
date: 2025-07-17 23:10:00 +0800
categories: [AI, LLM, LangChain]
tags: [äººå·¥æ™ºèƒ½, å¤§è¯­è¨€æ¨¡å‹, LangChain, RAG, Agent]
mermaid: true
---

## ğŸ½ï¸ å¼€åœºæ•…äº‹ï¼šå½“ç±³å…¶æ—å¨å¸ˆè¢«å…³åœ¨å¨æˆ¿é‡Œ

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æœ‰ä¸€ä½ç±³å…¶æ—ä¸‰æ˜Ÿå¨å¸ˆï¼ˆGPT-4ï¼‰ï¼Œä»–æ‹¥æœ‰æ— ä¸ä¼¦æ¯”çš„çƒ¹é¥ªæŠ€å·§ï¼Œä½†è¢«å›°åœ¨ä¸€ä¸ªå°é—­çš„å¨æˆ¿é‡Œï¼š

- **ä»–çŸ¥é“å…¨ä¸–ç•Œçš„èœè°±**ï¼Œä½†çœ‹ä¸åˆ°ä½ å†°ç®±é‡Œçš„é£Ÿæ
- **ä»–ç²¾é€šå„ç§çƒ¹é¥ªæŠ€æ³•**ï¼Œä½†ä¸ä¼šä½¿ç”¨ä½ æ–°ä¹°çš„ç©ºæ°”ç‚¸é”…
- **ä»–èƒ½åˆ›é€ ç¾å‘³ä½³è‚´**ï¼Œä½†ä¸çŸ¥é“ä½ ä»Šæ™šæƒ³åƒä»€ä¹ˆ

è¿™å°±æ˜¯ä»Šå¤©çš„å¤§è¯­è¨€æ¨¡å‹é¢ä¸´çš„å›°å¢ƒï¼

<div class="mermaid">
graph TD
    A[ç±³å…¶æ—å¨å¸ˆ<br>LLM] -->|çŸ¥é“æ‰€æœ‰èœè°±| B[ç†è®ºçŸ¥è¯†]
    A -->|ä½†ä¸ä¼š| C[æŸ¥çœ‹ä½ çš„å†°ç®±<br>ç§æœ‰æ•°æ®]
    A -->|ä¹Ÿä¸ä¼š| D[ä½¿ç”¨æ–°å¨å…·<br>å¤–éƒ¨å·¥å…·]
    A -->|æ›´ä¸çŸ¥é“| E[ä½ ä»Šæ™šçš„å£å‘³<br>å®æ—¶éœ€æ±‚]
    
    style A fill:#ffcccc
    style B fill:#ccffcc
    style C fill:#ffcccc
    style D fill:#ffcccc
    style E fill:#ffcccc
</div>

**LangChain å°±æ˜¯æ‰“å¼€å¨æˆ¿é—¨çš„é’¥åŒ™** ğŸ”‘

å®ƒè®©è¿™ä½"å¨å¸ˆ"èƒ½å¤Ÿï¼š
- ğŸ“– é˜…è¯»ä½ çš„ç§äººé£Ÿè°±ï¼ˆæ¥å…¥ç§æœ‰æ•°æ®ï¼‰
- ğŸ”§ ä½¿ç”¨å„ç§ç°ä»£å¨å…·ï¼ˆè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼‰
- ğŸ¯ æ ¹æ®ä½ çš„éœ€æ±‚å®šåˆ¶èœå“ï¼ˆä¸ªæ€§åŒ–æœåŠ¡ï¼‰

---

## ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šæ ¸å¿ƒæ¦‚å¿µå›¾è§£ - ç”¨ä¹é«˜ç§¯æœ¨çš„æ–¹å¼ç†è§£

### 1.1 LangChain çš„é­”æ³•ç›’å­

LangChain å°±åƒä¸€ä¸ªé­”æ³•å·¥å…·ç®±ï¼Œé‡Œé¢è£…æ»¡äº†å„ç§ä¹é«˜ç§¯æœ¨ã€‚æ¯ä¸ªç§¯æœ¨éƒ½æœ‰ç‰¹å®šçš„åŠŸèƒ½ï¼Œä½ å¯ä»¥è‡ªç”±ç»„åˆå®ƒä»¬æ¥å»ºé€ ä»»ä½•ä½ æƒ³è¦çš„ä¸œè¥¿ã€‚

<div class="mermaid">
graph TB
    subgraph "LangChain é­”æ³•å·¥å…·ç®±"
        A[Models<br>ğŸ¤– å¤§è„‘] 
        B[Prompts<br>ğŸ“ æŒ‡ä»¤]
        C[Chains<br>ğŸ”— æµæ°´çº¿]
        D[Memory<br>ğŸ§  è®°å¿†]
        E[Agents<br>ğŸ•µï¸ ç‰¹å·¥]
        F[Tools<br>ğŸ› ï¸ å·¥å…·]
        G[Indexes<br>ğŸ“š çŸ¥è¯†åº“]
    end
    
    A --> C
    B --> C
    C --> D
    C --> E
    E --> F
    C --> G
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fff8e1
    style F fill:#fce4ec
    style G fill:#e0f2f1
</div>

### 1.2 ä»5è¡Œä»£ç å¼€å§‹ï¼šä½ çš„ç¬¬ä¸€ä¸ªLLMè°ƒç”¨

è®©æˆ‘ä»¬ä»æœ€ç®€å•çš„ä¾‹å­å¼€å§‹ï¼Œæ„Ÿå—ä¸€ä¸‹LangChainçš„é­…åŠ›ï¼š

```python
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ–å¨å¸ˆ ğŸ‘¨â€ğŸ³
chef = ChatOpenAI(model="gpt-3.5-turbo")

# åšä¸€é“ç®€å•çš„èœ
response = chef.invoke("è¯·ç”¨ç®€å•çš„ä¸­æ–‡è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½")
print(response.content)
```

**è¾“å‡ºï¼š**
```
äººå·¥æ™ºèƒ½å°±æ˜¯è®©è®¡ç®—æœºåƒäººä¸€æ ·æ€è€ƒå’Œå­¦ä¹ çš„æŠ€æœ¯ã€‚å°±åƒå°å­©å­¦è®¤å­—ä¸€æ ·ï¼Œé€šè¿‡å¤§é‡ä¾‹å­å’Œç»ƒä¹ ï¼Œè®¡ç®—æœºä¹Ÿèƒ½å­¦ä¼šè¯†åˆ«å›¾åƒã€ç†è§£è¯­è¨€ã€åšå‡ºå†³ç­–...
```

å°±è¿™ä¹ˆç®€å•ï¼ä½ å·²ç»æˆåŠŸè°ƒç”¨äº†å¤§è¯­è¨€æ¨¡å‹ã€‚

---

## ğŸ—ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šé€æ­¥æ·±å…¥ - æ„å»ºä½ çš„æ™ºèƒ½åŠ©æ‰‹

### 2.1 åŠ å…¥æç¤ºæ¨¡æ¿ï¼šè®©å¯¹è¯æ›´æ™ºèƒ½

ç°åœ¨è®©æˆ‘ä»¬å‡çº§ä¸€ä¸‹ï¼ŒåŠ å…¥æç¤ºæ¨¡æ¿ï¼Œå°±åƒç»™å¨å¸ˆä¸€ä¸ªè¯¦ç»†çš„è®¢å•ï¼š

<div class="mermaid">
graph LR
    A[ç”¨æˆ·é—®é¢˜] --> B[æç¤ºæ¨¡æ¿]
    B --> C[æ ¼å¼åŒ–çš„é—®é¢˜]
    C --> D[LLM]
    D --> E[å›ç­”]
    
    style B fill:#fff3e0
    style C fill:#e3f2fd
</div>

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# åˆ›å»ºä¸“ä¸šçš„ç‚¹é¤æ¨¡æ¿
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{role}ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚"),
    ("human", "{question}")
])

# åˆå§‹åŒ–å¨å¸ˆ
chef = ChatOpenAI(model="gpt-3.5-turbo")

# åˆ›å»ºé“¾
chain = prompt_template | chef

# ä½¿ç”¨
response = chain.invoke({
    "role": "ç§‘æŠ€è§£è¯´å‘˜",
    "question": "ä»€ä¹ˆæ˜¯LangChainï¼Ÿ"
})
print(response.content)
```

### 2.2 åŠ å…¥è®°å¿†ï¼šè®©å¨å¸ˆè®°ä½ä½ çš„å–œå¥½

<div class="mermaid">
sequenceDiagram
    participant User
    participant Chain
    participant Memory
    participant LLM
    
    User->>Chain: ä½ å¥½ï¼Œæˆ‘å–œæ¬¢å·èœ
    Chain->>Memory: å­˜å‚¨åå¥½ï¼šå–œæ¬¢å·èœ
    Chain->>LLM: ç”Ÿæˆå›ç­”
    LLM-->>User: å¾ˆé«˜å…´è®¤è¯†ä½ ï¼
    
    User->>Chain: æ¨èä¸€é“èœ
    Chain->>Memory: è¯»å–åå¥½
    Memory-->>Chain: å–œæ¬¢å·èœ
    Chain->>LLM: åŸºäºå·èœåå¥½æ¨è
    LLM-->>User: æˆ‘æ¨èéº»å©†è±†è…...
</div>
```

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# åˆå§‹åŒ–å¸¦è®°å¿†çš„å¨å¸ˆ
chef = ChatOpenAI(model="gpt-3.5-turbo")
memory = ConversationBufferMemory()

conversation = ConversationChain(
    llm=chef,
    memory=memory,
    verbose=True  # å¯ä»¥çœ‹åˆ°å†…éƒ¨è¿‡ç¨‹
)

# å¼€å§‹å¯¹è¯
print(conversation.predict(input="ä½ å¥½ï¼Œæˆ‘å«å°æ˜ï¼Œæˆ‘å–œæ¬¢åƒå·èœ"))
print(conversation.predict(input="é‚£ä½ èƒ½æ¨èä¸€é“èœç»™æˆ‘å—ï¼Ÿ"))
```

---

## ğŸ“š ç¬¬ä¸‰éƒ¨åˆ†ï¼šRAGå®æˆ˜ - è®©å¨å¸ˆè¯»ä½ çš„ç§äººé£Ÿè°±

### 3.1 RAGæ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ

**RAG (Retrieval-Augmented Generation)** å°±åƒç»™å¨å¸ˆä¸€æœ¬ä½ çš„ç§äººé£Ÿè°±ï¼Œè®©ä»–æ ¹æ®é£Ÿè°±æ¥å›ç­”é—®é¢˜ã€‚

<div class="mermaid">
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[æœç´¢ç›¸å…³é£Ÿè°±æ®µè½]
    B --> C[æ‰¾åˆ°ç›¸å…³å†…å®¹]
    C --> D[ç»“åˆé£Ÿè°±å†…å®¹ç”Ÿæˆå›ç­”]
    D --> E[ä¸ªæ€§åŒ–å›ç­”]
    
    style A fill:#ffcccc
    style B fill:#fff3e0
    style C fill:#e3f2fd
    style D fill:#f3e5f5
    style E fill:#e8f5e9
</div>

### 3.2 å®æˆ˜ï¼šæ„å»ºæ–‡æ¡£é—®ç­”ç³»ç»Ÿ

è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ„å»ºä¸€ä¸ªèƒ½å›ç­”PDFæ–‡æ¡£é—®é¢˜çš„ç³»ç»Ÿï¼š

#### æ­¥éª¤1ï¼šå‡†å¤‡ç¯å¢ƒ
```bash
pip install langchain langchain-openai langchain-community faiss-cpu pypdf python-dotenv
```

#### æ­¥éª¤2ï¼šåˆ›å»ºæ–‡æ¡£åŠ è½½å™¨
```python
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
import os

# åŠ è½½PDFæ–‡æ¡£ï¼ˆè¿™é‡Œç”¨ä»»ä½•PDFéƒ½å¯ä»¥ï¼‰
loader = PyPDFLoader("sample.pdf")
documents = loader.load()

# å°†æ–‡æ¡£åˆ‡æˆå°å—
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # æ¯å—1000å­—ç¬¦
    chunk_overlap=200  # é‡å 200å­—ç¬¦ï¼Œä¿æŒè¿è´¯æ€§
)
texts = text_splitter.split_documents(documents)

print(f"æ–‡æ¡£è¢«åˆ†æˆ {len(texts)} ä¸ªæ®µè½")
```

#### æ­¥éª¤3ï¼šåˆ›å»ºå‘é‡æ•°æ®åº“
```python
# ä½¿ç”¨OpenAIçš„åµŒå…¥æ¨¡å‹
embeddings = OpenAIEmbeddings()

# åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆå°±åƒç»™æ¯ä¸ªé£Ÿè°±æ®µè½ç¼–ç´¢å¼•ï¼‰
vectorstore = FAISS.from_documents(texts, embeddings)

# ä¿å­˜åˆ°æœ¬åœ°
vectorstore.save_local("faiss_index")
```

#### æ­¥éª¤4ï¼šåˆ›å»ºé—®ç­”é“¾
```python
# åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever(
    search_kwargs={"k": 3}  # è¿”å›æœ€ç›¸å…³çš„3ä¸ªæ®µè½
)

# åˆ›å»ºé—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    chain_type="stuff",  # ç®€å•ç›´æ¥çš„æ–¹å¼
    retriever=retriever,
    return_source_documents=True  # è¿”å›å‚è€ƒçš„æ–‡æ¡£
)

# ä½¿ç”¨
query = "è¿™ç¯‡æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"
result = qa_chain({"query": query})

print("å›ç­”ï¼š", result["result"])
print("\nå‚è€ƒçš„æ–‡æ¡£æ®µè½ï¼š")
for doc in result["source_documents"]:
    print("-" * 40)
    print(doc.page_content[:200] + "...")
```

---

## ğŸ•µï¸ ç¬¬å››éƒ¨åˆ†ï¼šAgent - è®©å¨å¸ˆæˆä¸ºä¸‡èƒ½ç®¡å®¶

### 4.1 Agentæ˜¯ä»€ä¹ˆï¼Ÿ

å¦‚æœè¯´RAGæ˜¯è®©å¨å¸ˆè¯»ä¹¦ï¼Œé‚£ä¹ˆAgentå°±æ˜¯è®©å¨å¸ˆ**åŠ¨æ‰‹åšäº‹** - æœç´¢ä¿¡æ¯ã€è®¡ç®—æ•°æ®ã€è°ƒç”¨APIç­‰ç­‰ã€‚

<div class="mermaid">
stateDiagram-v2
    [*] --> æ¥æ”¶ä»»åŠ¡
    æ¥æ”¶ä»»åŠ¡ --> æ€è€ƒéœ€è¦ä»€ä¹ˆå·¥å…·
    æ€è€ƒéœ€è¦ä»€ä¹ˆå·¥å…· --> é€‰æ‹©åˆé€‚å·¥å…·
    é€‰æ‹©åˆé€‚å·¥å…· --> ä½¿ç”¨å·¥å…·
    ä½¿ç”¨å·¥å…· --> è§‚å¯Ÿç»“æœ
    è§‚å¯Ÿç»“æœ --> ä»»åŠ¡å®Œæˆï¼Ÿ
    ä»»åŠ¡å®Œæˆï¼Ÿ --> æ˜¯: è¿”å›ç»“æœ
    ä»»åŠ¡å®Œæˆï¼Ÿ --> å¦: æ€è€ƒéœ€è¦ä»€ä¹ˆå·¥å…·
    è¿”å›ç»“æœ --> [*]
</div>
```

### 4.2 å®æˆ˜ï¼šåˆ›å»ºèƒ½ä¸Šç½‘æœç´¢çš„åŠ©æ‰‹

```python
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.tools import DuckDuckGoSearchRun
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ–å·¥å…·
search = DuckDuckGoSearchRun()
tools = [
    Tool(
        name="æœç´¢",
        func=search.run,
        description="å½“ä½ éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯æ—¶ä½¿ç”¨è¿™ä¸ªå·¥å…·"
    )
]

# åˆ›å»ºAgentæ¨¡æ¿
template = """ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚
ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨ï¼š
{tools}

ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
é—®é¢˜ï¼šä½ éœ€è¦å›ç­”çš„é—®é¢˜
æ€è€ƒï¼šä½ åº”è¯¥å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜
è¡ŒåŠ¨ï¼šé€‰æ‹©è¦ä½¿ç”¨çš„å·¥å…· [{tool_names}]
è¡ŒåŠ¨è¾“å…¥ï¼šå·¥å…·çš„è¾“å…¥
è§‚å¯Ÿï¼šå·¥å…·è¿”å›çš„ç»“æœ
...ï¼ˆè¿™ä¸ªæ€è€ƒ/è¡ŒåŠ¨/è§‚å¯Ÿå¯ä»¥é‡å¤å¤šæ¬¡ï¼‰
æ€è€ƒï¼šæˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
æœ€ç»ˆç­”æ¡ˆï¼šå¯¹åŸå§‹é—®é¢˜çš„å›ç­”

å¼€å§‹ï¼

é—®é¢˜ï¼š{input}
æ€è€ƒï¼š{agent_scratchpad}"""

# åˆ›å»ºAgent
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
agent = create_react_agent(llm, tools, PromptTemplate.from_template(template))
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# ä½¿ç”¨
result = agent_executor.invoke({
    "input": "ä»Šå¤©ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆæ–°é—»ï¼Ÿ"
})
print(result['output'])
```

---

## âš¡ ç¬¬äº”éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ– - ä»ç©å…·åˆ°ç”Ÿäº§

### 5.1 ä¸åŒæ–¹æ¡ˆçš„å¯¹æ¯”

| æ–¹æ¡ˆ | å“åº”æ—¶é—´ | æˆæœ¬ | å‡†ç¡®ç‡ | é€‚ç”¨åœºæ™¯ |
|------|----------|------|--------|----------|
| ç›´æ¥LLM | 1-2ç§’ | ä½ | ä¸­ | ç®€å•é—®ç­” |
| RAG | 2-4ç§’ | ä¸­ | é«˜ | æ–‡æ¡£é—®ç­” |
| Agent | 5-10ç§’ | é«˜ | é«˜ | å¤æ‚ä»»åŠ¡ |
| æµå¼å“åº” | å®æ—¶ | ä½ | ä¸­ | èŠå¤©åº”ç”¨ |

### 5.2 ä¼˜åŒ–æŠ€å·§

#### æŠ€å·§1ï¼šä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—
```python
from langchain.cache import InMemoryCache
import langchain

langchain.llm_cache = InMemoryCache()

# ç°åœ¨ç›¸åŒçš„æŸ¥è¯¢ä¼šè¢«ç¼“å­˜
response1 = chain.invoke({"question": "ä»€ä¹ˆæ˜¯AIï¼Ÿ"})
response2 = chain.invoke({"question": "ä»€ä¹ˆæ˜¯AIï¼Ÿ"})  # è¿™æ¬¡ä¼šæ›´å¿«
```

#### æŠ€å·§2ï¼šé€‰æ‹©åˆé€‚çš„æ¨¡å‹
```python
# æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹
def get_model_for_task(task_type):
    if task_type == "ç®€å•é—®ç­”":
        return ChatOpenAI(model="gpt-3.5-turbo")
    elif task_type == "å¤æ‚åˆ†æ":
        return ChatOpenAI(model="gpt-4")
    elif task_type == "å¿«é€Ÿå“åº”":
        return ChatOpenAI(model="gpt-3.5-turbo-16k")
```

#### æŠ€å·§3ï¼šä¼˜åŒ–æ£€ç´¢ç­–ç•¥
```python
# ä½¿ç”¨ä¸åŒçš„æ£€ç´¢ç­–ç•¥
from langchain.retrievers import MultiQueryRetriever

# åŸºç¡€æ£€ç´¢å™¨
base_retriever = vectorstore.as_retriever()

# å¤šæŸ¥è¯¢æ£€ç´¢å™¨ï¼ˆç”Ÿæˆå¤šä¸ªç›¸å…³é—®é¢˜ï¼‰
multi_retriever = MultiQueryRetriever.from_llm(
    retriever=base_retriever,
    llm=ChatOpenAI(model="gpt-3.5-turbo")
)

# ä½¿ç”¨
results = multi_retriever.get_relevant_documents("æœºå™¨å­¦ä¹ æ˜¯ä»€ä¹ˆï¼Ÿ")
print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ®µè½")
```

---

## ğŸ› ç¬¬å…­éƒ¨åˆ†ï¼šè°ƒè¯•æŠ€å·§ - è§£å†³å¸¸è§é—®é¢˜

### 6.1 æŸ¥çœ‹å®é™…å‘é€çš„æç¤º

```python
# æ‰“å°å®é™…å‘é€ç»™LLMçš„æç¤º
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ª{role}"),
    ("human", "{question}")
])

# æŸ¥çœ‹æ ¼å¼åŒ–çš„æç¤º
formatted = prompt.format_messages(role="è€å¸ˆ", question="ä»€ä¹ˆæ˜¯Pythonï¼Ÿ")
print("å®é™…å‘é€çš„æç¤ºï¼š")
for msg in formatted:
    print(f"{msg.type}: {msg.content}")
```

### 6.2 è°ƒè¯•æ£€ç´¢ç»“æœ

```python
# æ£€æŸ¥æ£€ç´¢åˆ°çš„æ–‡æ¡£
def debug_retrieval(query, retriever):
    docs = retriever.get_relevant_documents(query)
    print(f"æŸ¥è¯¢: {query}")
    print(f"æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
    
    for i, doc in enumerate(docs):
        print(f"\næ–‡æ¡£ {i+1}:")
        print(f"å†…å®¹: {doc.page_content[:200]}...")
        print(f"å…ƒæ•°æ®: {doc.metadata}")

# ä½¿ç”¨
debug_retrieval("PythonåŸºç¡€", retriever)
```

---

## ğŸ¯ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šä¸‰ä¸ªçœŸå®æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæ™ºèƒ½å®¢æœæœºå™¨äºº
```python
# å¤„ç†å®¢æˆ·å’¨è¯¢çš„å®Œæ•´ç³»ç»Ÿ
class CustomerServiceBot:
    def __init__(self, faq_path):
        # åŠ è½½FAQæ–‡æ¡£
        loader = PyPDFLoader(faq_path)
        docs = loader.load()
        
        # åˆ›å»ºå‘é‡æ•°æ®åº“
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        texts = text_splitter.split_documents(docs)
        
        embeddings = OpenAIEmbeddings()
        self.vectorstore = FAISS.from_documents(texts, embeddings)
        
        # åˆ›å»ºé—®ç­”é“¾
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=ChatOpenAI(model="gpt-3.5-turbo"),
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever()
        )
    
    def answer(self, question):
        return self.qa_chain.run(question)

# ä½¿ç”¨
bot = CustomerServiceBot("company_faq.pdf")
print(bot.answer("ä½ ä»¬çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ"))
```

### æ¡ˆä¾‹2ï¼šæ•°æ®åˆ†æåŠ©æ‰‹
```python
import pandas as pd
from langchain_experimental.agents import create_pandas_dataframe_agent

# åŠ è½½æ•°æ®
df = pd.read_csv("sales_data.csv")

# åˆ›å»ºæ•°æ®åˆ†æAgent
agent = create_pandas_dataframe_agent(
    ChatOpenAI(model="gpt-4"),
    df,
    verbose=True
)

# åˆ†ææ•°æ®
result = agent.run("å“ªä¸ªæœˆçš„é”€å”®é¢æœ€é«˜ï¼Ÿå¹³å‡é”€å”®é¢æ˜¯å¤šå°‘ï¼Ÿ")
print(result)
```

### æ¡ˆä¾‹3ï¼šä»£ç å®¡æŸ¥åŠ©æ‰‹
```python
from langchain.schema import Document

def create_code_review_agent():
    # ä»£ç å®¡æŸ¥æç¤º
    review_prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·åˆ†ææä¾›çš„ä»£ç ï¼Œå…³æ³¨ï¼š
        1. æ½œåœ¨çš„bug
        2. æ€§èƒ½é—®é¢˜
        3. ä»£ç é£æ ¼
        4. å®‰å…¨æ¼æ´
        è¯·æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚"""),
        ("human", "è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š\n\n{code}")
    ])
    
    return review_prompt | ChatOpenAI(model="gpt-4")

# ä½¿ç”¨
reviewer = create_code_review_agent()
code = """
def calculate_total(items):
    total = 0
    for item in items:
        total = total + item.price
    return total
"""

review = reviewer.invoke({"code": code})
print(review.content)
```

---

## ğŸš€ ç¬¬å…«éƒ¨åˆ†ï¼šå­¦ä¹ è·¯å¾„å’Œè¿›é˜¶æŒ‡å—

### 8.1 30å¤©å­¦ä¹ è®¡åˆ’

| å‘¨æ¬¡ | å­¦ä¹ å†…å®¹ | å®è·µé¡¹ç›® |
|------|----------|----------|
| ç¬¬1å‘¨ | åŸºç¡€æ¦‚å¿µã€ç®€å•è°ƒç”¨ | èŠå¤©æœºå™¨äºº |
| ç¬¬2å‘¨ | RAGç³»ç»Ÿã€æ–‡æ¡£å¤„ç† | ä¸ªäººçŸ¥è¯†åº“ |
| ç¬¬3å‘¨ | Agentã€å·¥å…·ä½¿ç”¨ | è‡ªåŠ¨åŒ–åŠ©æ‰‹ |
| ç¬¬4å‘¨ | ä¼˜åŒ–ã€è°ƒè¯•ã€éƒ¨ç½² | ç”Ÿäº§çº§åº”ç”¨ |

### 8.2 æ¨èèµ„æº

**å®˜æ–¹èµ„æºï¼š**
- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [LangSmithè°ƒè¯•å¹³å°](https://smith.langchain.com/)
- [LangServeéƒ¨ç½²å·¥å…·](https://github.com/langchain-ai/langserve)

**å­¦ä¹ å¹³å°ï¼š**
- [DeepLearning.AIè¯¾ç¨‹](https://www.deeplearning.ai/short-courses/)
- [å®˜æ–¹ç¤ºä¾‹ä»£ç ](https://github.com/langchain-ai/langchain/tree/master/templates)

**ç¤¾åŒºèµ„æºï¼š**
- [Discordç¤¾åŒº](https://discord.gg/langchain)
- [GitHubè®¨è®º](https://github.com/langchain-ai/langchain/discussions)

### 8.3 ä¸‹ä¸€æ­¥å­¦ä¹ æ–¹å‘

1. **é«˜çº§RAGæŠ€æœ¯ï¼š**
   - å¤šæ¨¡æ€æ£€ç´¢ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ï¼‰
   - å›¾æ•°æ®åº“é›†æˆ
   - å®æ—¶æ•°æ®æ›´æ–°

2. **å¤æ‚Agentç³»ç»Ÿï¼š**
   - å¤šAgentåä½œ
   - é•¿æœŸè§„åˆ’
   - äººæœºåä½œ

3. **ç”Ÿäº§éƒ¨ç½²ï¼š**
   - å®¹å™¨åŒ–éƒ¨ç½²
   - ç›‘æ§å’Œæ—¥å¿—
   - A/Bæµ‹è¯•

---

## ğŸ‰ ç»“è¯­ï¼šä½ çš„LangChainä¹‹æ—…åˆšåˆšå¼€å§‹

æ­å–œä½ ï¼ä½ å·²ç»ä»"å°ç™½"æˆé•¿ä¸ºèƒ½å¤Ÿæ„å»ºå®ç”¨LLMåº”ç”¨çš„å¼€å‘è€…ã€‚è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹å­¦åˆ°çš„å†…å®¹ï¼š

<div class="mermaid">
journey
    title ä½ çš„LangChainå­¦ä¹ ä¹‹æ—…
    section åŸºç¡€å…¥é—¨
      äº†è§£æ¦‚å¿µ: 5: æ–°æ‰‹
      è¿è¡Œç¬¬ä¸€ä¸ªä¾‹å­: 4: æ–°æ‰‹
    section åŠ¨æ‰‹å®è·µ
      æ„å»ºRAGç³»ç»Ÿ: 3: å­¦ä¹ 
      åˆ›å»ºAgent: 3: å­¦ä¹ 
    section ä¼˜åŒ–è¿›é˜¶
      æ€§èƒ½è°ƒä¼˜: 2: ç†Ÿç»ƒ
      ç”Ÿäº§éƒ¨ç½²: 1: ä¸“å®¶
</div>
```

è®°ä½ï¼š
- **ä»ç®€å•å¼€å§‹**ï¼šä¸è¦è¯•å›¾ä¸€å¼€å§‹å°±æ„å»ºå¤æ‚çš„ç³»ç»Ÿ
- **å¤šåŠ¨æ‰‹å®è·µ**ï¼šæ¯ä¸ªä¾‹å­éƒ½è¦äº²è‡ªè·‘ä¸€é
- **åŠ å…¥ç¤¾åŒº**ï¼šé‡åˆ°é—®é¢˜åŠæ—¶å¯»æ±‚å¸®åŠ©
- **ä¿æŒå¥½å¥‡**ï¼šè¿™ä¸ªé¢†åŸŸæ¯å¤©éƒ½åœ¨å¿«é€Ÿå‘å±•

ç°åœ¨ï¼Œè½®åˆ°ä½ ç”¨LangChainåˆ›é€ ç¥å¥‡äº†ï¼ä½ çš„ç¬¬ä¸€ä¸ªLLMåº”ç”¨ä¼šæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

---

## ğŸ“‹ é™„å½•ï¼šå¿«é€Ÿå‚è€ƒ

### ç¯å¢ƒå˜é‡è®¾ç½®
```bash
# .envæ–‡ä»¶
OPENAI_API_KEY=your_api_key_here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_key
```

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥
```python
# å®‰è£…
pip install langchain langchain-openai langchain-community

# åŸºç¡€å¯¼å…¥
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
```

### è°ƒè¯•æ¨¡å¼
```python
import langchain
langchain.debug = True  # å¼€å¯è°ƒè¯•æ¨¡å¼
```

ç¥ä½ ç¼–ç¨‹æ„‰å¿«ï¼ğŸš€
