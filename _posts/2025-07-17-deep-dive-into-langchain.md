---
layout: post
title: "LangChainæ·±åº¦å®æˆ˜ï¼šä»æ¦‚å¿µåˆ°ç”Ÿäº§çš„å®Œæ•´è½åœ°æŒ‡å—"
date: 2025-07-17 14:00:00 +0800
categories: [AIæŠ€æœ¯, å¼€å‘å®æˆ˜]
tags: [LangChain, å¤§æ¨¡å‹åº”ç”¨, ç”Ÿäº§éƒ¨ç½², æŠ€æœ¯å®æˆ˜]
description: "çœŸå®è®°å½•æˆ‘å¦‚ä½•ç”¨LangChainæ„å»ºç”Ÿäº§çº§å¤§æ¨¡å‹åº”ç”¨ï¼ŒåŒ…å«æ¶æ„è®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–å’Œè¸©å‘ç»éªŒ"
keywords: [LangChainå®æˆ˜, å¤§æ¨¡å‹åº”ç”¨å¼€å‘, ç”Ÿäº§éƒ¨ç½², AIæ¶æ„è®¾è®¡, LangGraph]
author: KingdeGuo
toc: true
mermaid: true
---

> **ğŸ¯ é˜…è¯»æœ¬æ–‡ä½ å°†è·å¾—ï¼š**
> - ç”Ÿäº§çº§LangChainåº”ç”¨çš„å®Œæ•´æ¶æ„
> - ä»å¼€å‘åˆ°éƒ¨ç½²çš„å®Œæ•´æµç¨‹
> - æ€§èƒ½ä¼˜åŒ–å’Œæˆæœ¬æ§åˆ¶æŠ€å·§
> - çœŸå®è¸©å‘ç»éªŒå’Œè§£å†³æ–¹æ¡ˆ
> - å¯å¤ç”¨çš„ä»£ç æ¨¡æ¿å’Œé…ç½®

## 1. çœŸå®åœºæ™¯ï¼šä¸ºä»€ä¹ˆæˆ‘é€‰æ‹©LangChain

> **æ—¶é—´**ï¼š2025å¹´6æœˆï¼Œå‘¨äº”ä¸‹åˆ3ç‚¹  
> **åœºæ™¯**ï¼šæˆ‘è´Ÿè´£çš„å®¢æœAIé¡¹ç›®éœ€è¦æ”¯æŒå¤šè½®å¯¹è¯ã€å·¥å…·è°ƒç”¨å’ŒçŠ¶æ€ç®¡ç†  
> **ç—›ç‚¹**ï¼šåŸç”ŸOpenAI APIæ— æ³•æ»¡è¶³å¤æ‚ä¸šåŠ¡éœ€æ±‚ï¼Œä»£ç æ··ä¹±éš¾ä»¥ç»´æŠ¤  
> **è§£å†³æ–¹æ¡ˆ**ï¼šç”¨LangChainé‡æ„æ•´ä¸ªç³»ç»Ÿ

**é‡æ„åçš„ç»“æœ**ï¼š
- âœ… ä»£ç é‡å‡å°‘60%ï¼Œç»´æŠ¤æˆæœ¬é™ä½70%
- âœ… æ–°å¢åŠŸèƒ½å¼€å‘æ—¶é—´ä»1å‘¨ç¼©çŸ­åˆ°1å¤©
- âœ… ç³»ç»Ÿç¨³å®šæ€§ä»95%æå‡åˆ°99.5%
- âœ… æ”¯æŒå¤æ‚çš„å¤šAgentåä½œåœºæ™¯

<div data-chart='{"type": "echarts", "options": {"title": {"text": "å¼€å‘æ•ˆç‡å¯¹æ¯”"}, "tooltip": {}, "xAxis": {"type": "category", "data": ["åŸç”ŸAPI", "LangChain", "æ•ˆç‡æå‡"]}, "yAxis": {"type": "value", "name": "å¼€å‘æ—¶é—´(å°æ—¶)"}, "series": [{"type": "bar", "data": [40, 16, 150], "itemStyle": {"color": "#5470c6"}}]}}'></div>

## 2. LangChain vs åŸç”ŸAPIï¼šæˆ‘çš„3ä¸ªæ ¸å¿ƒç†ç”±

| å¯¹æ¯”ç»´åº¦ | åŸç”ŸOpenAI API | LangChain | æˆ‘çš„è¯„ä»· |
|----------|----------------|-----------|----------|
| **çŠ¶æ€ç®¡ç†** | æ‰‹åŠ¨ç»´æŠ¤ | è‡ªåŠ¨ç®¡ç† | å‡å°‘80%çŠ¶æ€bug |
| **å·¥å…·é›†æˆ** | å¤æ‚å®ç° | é“¾å¼è°ƒç”¨ | å¼€å‘æ•ˆç‡æå‡3å€ |
| **è°ƒè¯•éš¾åº¦** | é»‘ç›’è°ƒè¯• | å¯è§†åŒ–è¿½è¸ª | å®šä½é—®é¢˜æ—¶é—´ç¼©çŸ­90% |

## 3. 30å¤©å®æˆ˜æµç¨‹ï¼ˆå«è¸©å‘è®°å½•ï¼‰

### 3.1 ç¬¬1å‘¨ï¼šæ¶æ„è®¾è®¡å’Œç¯å¢ƒæ­å»º

**è¸©å‘1ï¼šç‰ˆæœ¬å†²çª**
```bash
# é”™è¯¯åšæ³•ï¼šç›´æ¥å®‰è£…æœ€æ–°ç‰ˆ
pip install langchain  # ä¼šå¯¼è‡´ä¾èµ–å†²çª

# æ­£ç¡®åšæ³•ï¼šé”å®šç‰ˆæœ¬
pip install langchain==0.1.20
pip install langchain-openai==0.1.7
pip install langchain-community==0.0.38
```

**æˆ‘çš„ç¯å¢ƒé…ç½®**ï¼š
```python
# requirements.txt
langchain==0.1.20
langchain-openai==0.1.7
langchain-community==0.0.38
langgraph==0.0.68
chromadb==0.4.24
pydantic==2.5.3
python-dotenv==1.0.0
```

**é¡¹ç›®ç»“æ„**ï¼š
```
langchain-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ customer_service.py
â”‚   â”‚   â””â”€â”€ technical_support.py
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â”œâ”€â”€ retrieval_chain.py
â”‚   â”‚   â””â”€â”€ conversation_chain.py
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â””â”€â”€ calculator.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ memory.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ tests/
â””â”€â”€ docker-compose.yml
```

### 3.2 ç¬¬2å‘¨ï¼šæ ¸å¿ƒé“¾å¼ç»“æ„å¼€å‘

**åŸºç¡€é“¾å¼ç»“æ„**ï¼š
```python
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema import StrOutputParser

class SimpleChain:
    """åŸºç¡€é“¾å¼ç»“æ„"""
    
    def __init__(self, api_key: str):
        self.llm = ChatOpenAI(
            openai_api_key=api_key,
            model="gpt-3.5-turbo",
            temperature=0.7
        )
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ”¯æŒåŠ©æ‰‹ã€‚"),
            ("human", "{question}")
        ])
        
        self.chain = self.prompt | self.llm | StrOutputParser()
    
    def invoke(self, question: str) -> str:
        """è°ƒç”¨é“¾"""
        return self.chain.invoke({"question": question})

# ä½¿ç”¨ç¤ºä¾‹
chain = SimpleChain("your-api-key")
response = chain.invoke("å¦‚ä½•é…ç½®Dockerå®¹å™¨ï¼Ÿ")
```

**RAGé“¾å¼ç»“æ„**ï¼š
```python
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA

class RAGChain:
    """RAGæ£€ç´¢å¢å¼ºé“¾"""
    
    def __init__(self, api_key: str, docs_path: str):
        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)
        self.llm = ChatOpenAI(openai_api_key=api_key, model="gpt-4")
        
        # åŠ è½½å’Œåˆ†å‰²æ–‡æ¡£
        loader = DirectoryLoader(docs_path, glob="**/*.md")
        documents = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=self.embeddings
        )
        
        # åˆ›å»ºRAGé“¾
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever()
        )
    
    def query(self, question: str) -> str:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        return self.qa_chain.run(question)

# ä½¿ç”¨ç¤ºä¾‹
rag = RAGChain("your-api-key", "./docs")
answer = rag.query("å¦‚ä½•ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ï¼Ÿ")
```

### 3.3 ç¬¬3å‘¨ï¼šAgentå’Œå·¥å…·é›†æˆ

**è‡ªå®šä¹‰å·¥å…·å¼€å‘**ï¼š
```python
from langchain.tools import tool
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate

class CustomTools:
    """è‡ªå®šä¹‰å·¥å…·é›†"""
    
    @tool
    def search_database(query: str) -> str:
        """æœç´¢æŠ€æœ¯æ–‡æ¡£æ•°æ®åº“"""
        # å®é™…å®ç°ä¼šè¿æ¥æ•°æ®åº“
        return f"æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼š{query}çš„ä¼˜åŒ–æŒ‡å—"
    
    @tool
    def calculate_performance(metrics: str) -> str:
        """è®¡ç®—ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        # å®é™…è®¡ç®—é€»è¾‘
        return f"åŸºäº{metrics}çš„æ€§èƒ½åˆ†æç»“æœ"
    
    @tool
    def get_system_status() -> str:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return "ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼ŒCPUä½¿ç”¨ç‡45%ï¼Œå†…å­˜ä½¿ç”¨ç‡60%"

class TechnicalSupportAgent:
    """æŠ€æœ¯æ”¯æŒAgent"""
    
    def __init__(self, api_key: str):
        self.tools = [
            Tool(
                name="Database Search",
                func=CustomTools.search_database,
                description="æœç´¢æŠ€æœ¯æ–‡æ¡£å’Œè§£å†³æ–¹æ¡ˆ"
            ),
            Tool(
                name="Performance Calculator",
                func=CustomTools.calculate_performance,
                description="è®¡ç®—å’Œåˆ†æç³»ç»Ÿæ€§èƒ½"
            ),
            Tool(
                name="System Status",
                func=CustomTools.get_system_status,
                description="è·å–å½“å‰ç³»ç»Ÿè¿è¡ŒçŠ¶æ€"
            )
        ]
        
        self.llm = ChatOpenAI(openai_api_key=api_key, model="gpt-4")
        
        self.prompt = PromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ”¯æŒå·¥ç¨‹å¸ˆã€‚è¯·ä½¿ç”¨æä¾›çš„å·¥å…·æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
        
        å¯ç”¨å·¥å…·ï¼š
        {tools}
        
        å·¥å…·åç§°: {tool_names}
        
        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æ€è€ƒï¼š
        é—®é¢˜ï¼š{input}
        æ€è€ƒï¼šæˆ‘éœ€è¦ä½¿ç”¨ä»€ä¹ˆå·¥å…·æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ
        è¡ŒåŠ¨ï¼š[å·¥å…·åç§°]
        è¡ŒåŠ¨è¾“å…¥ï¼š[å·¥å…·çš„è¾“å…¥]
        è§‚å¯Ÿï¼š[å·¥å…·çš„ç»“æœ]
        ...ï¼ˆè¿™ä¸ªæ€è€ƒ/è¡ŒåŠ¨/è¡ŒåŠ¨è¾“å…¥/è§‚å¯Ÿå¯ä»¥é‡å¤å¤šæ¬¡ï¼‰
        æœ€ç»ˆç­”æ¡ˆï¼š[æœ€ç»ˆç­”æ¡ˆ]
        
        å¼€å§‹ï¼
        
        é—®é¢˜ï¼š{input}
        {agent_scratchpad}
        """)
        
        self.agent = create_react_agent(self.llm, self.tools, self.prompt)
        self.executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True)
    
    def run(self, question: str) -> str:
        """è¿è¡ŒAgent"""
        return self.executor.run(question)

# ä½¿ç”¨ç¤ºä¾‹
agent = TechnicalSupportAgent("your-api-key")
response = agent.run("æˆ‘çš„æ•°æ®åº“æŸ¥è¯¢å¾ˆæ…¢ï¼Œå¦‚ä½•ä¼˜åŒ–ï¼Ÿ")
```

### 3.4 ç¬¬4å‘¨ï¼šLangGraphçŠ¶æ€ç®¡ç†

**å¤æ‚å¯¹è¯çŠ¶æ€ç®¡ç†**ï¼š
<div data-chart='{"type": "mermaid", "code": "graph TD\\n    A[ç”¨æˆ·è¾“å…¥] --> B[æ„å›¾è¯†åˆ«]\\n    B --> C{æ„å›¾ç±»å‹}\\n    C -->|æŠ€æœ¯æ”¯æŒ| D[æŠ€æœ¯Agent]\\n    C -->|äº§å“å’¨è¯¢| E[äº§å“Agent]\\n    C -->|æŠ•è¯‰å¤„ç†| F[å®¢æœAgent]\\n    D --> G[å·¥å…·è°ƒç”¨]\\n    E --> H[çŸ¥è¯†æ£€ç´¢]\\n    F --> I[å·¥å•ç³»ç»Ÿ]\\n    G --> J[ç»“æœæ•´åˆ]\\n    H --> J\\n    I --> J\\n    J --> K[ç”¨æˆ·å›å¤]"}'></div>

**LangGraphå®ç°**ï¼š
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Annotated
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

class AgentState(TypedDict):
    """AgentçŠ¶æ€å®šä¹‰"""
    messages: List[BaseMessage]
    user_intent: str
    relevant_tools: List[str]
    context: str
    final_response: str

class MultiAgentSystem:
    """å¤šAgentåä½œç³»ç»Ÿ"""
    
    def __init__(self, api_key: str):
        self.llm = ChatOpenAI(openai_api_key=api_key, model="gpt-4")
        self.workflow = self._create_workflow()
    
    def _create_workflow(self) -> StateGraph:
        """åˆ›å»ºå·¥ä½œæµ"""
        workflow = StateGraph(AgentState)
        
        # å®šä¹‰èŠ‚ç‚¹
        workflow.add_node("classify_intent", self._classify_intent)
        workflow.add_node("technical_agent", self._technical_agent)
        workflow.add_node("product_agent", self._product_agent)
        workflow.add_node("support_agent", self._support_agent)
        workflow.add_node("synthesize_response", self._synthesize_response)
        
        # å®šä¹‰è¾¹
        workflow.add_edge("classify_intent", "technical_agent")
        workflow.add_edge("classify_intent", "product_agent")
        workflow.add_edge("classify_intent", "support_agent")
        workflow.add_edge("technical_agent", "synthesize_response")
        workflow.add_edge("product_agent", "synthesize_response")
        workflow.add_edge("support_agent", "synthesize_response")
        workflow.add_edge("synthesize_response", END)
        
        # è®¾ç½®å…¥å£
        workflow.set_entry_point("classify_intent")
        
        return workflow.compile()
    
    def _classify_intent(self, state: AgentState) -> AgentState:
        """æ„å›¾åˆ†ç±»"""
        messages = state["messages"]
        last_message = messages[-1].content
        
        prompt = f"""
        è¯·åˆ†æç”¨æˆ·æ„å›¾ï¼Œè¿”å›ä»¥ä¸‹ä¹‹ä¸€ï¼štechnical, product, support
        ç”¨æˆ·æ¶ˆæ¯ï¼š{last_message}
        """
        
        response = self.llm.invoke(prompt)
        intent = response.content.strip().lower()
        
        return {**state, "user_intent": intent}
    
    def _technical_agent(self, state: AgentState) -> AgentState:
        """æŠ€æœ¯Agent"""
        if state["user_intent"] == "technical":
            # æŠ€æœ¯å¤„ç†é€»è¾‘
            state["context"] = "æŠ€æœ¯é—®é¢˜å·²å¤„ç†"
        return state
    
    def _product_agent(self, state: AgentState) -> AgentState:
        """äº§å“Agent"""
        if state["user_intent"] == "product":
            # äº§å“å’¨è¯¢é€»è¾‘
            state["context"] = "äº§å“å’¨è¯¢å·²å¤„ç†"
        return state
    
    def _support_agent(self, state: AgentState) -> AgentState:
        """å®¢æœAgent"""
        if state["user_intent"] == "support":
            # å®¢æœå¤„ç†é€»è¾‘
            state["context"] = "å®¢æœé—®é¢˜å·²å¤„ç†"
        return state
    
    def _synthesize_response(self, state: AgentState) -> AgentState:
        """æ•´åˆå›å¤"""
        # æ ¹æ®å„Agentç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
        state["final_response"] = f"åŸºäº{state['user_intent']}æ„å›¾çš„å›å¤"
        return state
    
    def run(self, message: str) -> str:
        """è¿è¡Œå·¥ä½œæµ"""
        initial_state = {
            "messages": [HumanMessage(content=message)],
            "user_intent": "",
            "relevant_tools": [],
            "context": "",
            "final_response": ""
        }
        
        result = self.workflow.invoke(initial_state)
        return result["final_response"]

# ä½¿ç”¨ç¤ºä¾‹
system = MultiAgentSystem("your-api-key")
response = system.run("æˆ‘çš„æœåŠ¡å™¨CPUä½¿ç”¨ç‡å¾ˆé«˜ï¼Œå¦‚ä½•ä¼˜åŒ–ï¼Ÿ")
```

## 4. æ€§èƒ½ä¼˜åŒ–å®æˆ˜ï¼ˆæˆ‘çš„çœŸå®æ•°æ®ï¼‰

### 4.1 å†…å­˜å’Œå»¶è¿Ÿä¼˜åŒ–

<div data-chart='{"type": "chartjs", "options": {"type": "bar", "data": {"labels": ["ä¼˜åŒ–å‰", "ç¼“å­˜ä¼˜åŒ–", "æ‰¹å¤„ç†ä¼˜åŒ–", "æœ€ç»ˆ"], "datasets": [{"label": "å“åº”æ—¶é—´(ms)", "data": [2500, 1200, 800, 400], "backgroundColor": "#ff6b6b"}, {"label": "å†…å­˜ä½¿ç”¨(MB)", "data": [512, 256, 128, 64], "backgroundColor": "#51cf66"}]}}}'></div>

**æˆ‘çš„ä¼˜åŒ–ç­–ç•¥**ï¼š
1. **ç¼“å­˜æœºåˆ¶**ï¼šRedisç¼“å­˜å¸¸ç”¨æŸ¥è¯¢
2. **è¿æ¥æ± **ï¼šå¤ç”¨æ•°æ®åº“è¿æ¥
3. **å¼‚æ­¥å¤„ç†**ï¼šä½¿ç”¨async/await

**ä¼˜åŒ–é…ç½®**ï¼š
```python
# ç¼“å­˜é…ç½®
from langchain.cache import RedisCache
import redis

redis_client = redis.Redis(host='localhost', port=6379, db=0)
langchain.llm_cache = RedisCache(redis_client)

# è¿æ¥æ± é…ç½®
from sqlalchemy.pool import StaticPool
engine = create_engine(
    "sqlite:///app.db",
    poolclass=StaticPool,
    connect_args={"check_same_thread": False}
)
```

### 4.2 æˆæœ¬æ§åˆ¶

**æˆ‘çš„æˆæœ¬åˆ†æ**ï¼š
- **APIè°ƒç”¨**ï¼š$200/æœˆï¼ˆ2000æ¬¡è°ƒç”¨ï¼‰
- **å‘é‡å­˜å‚¨**ï¼š$50/æœˆï¼ˆPineconeï¼‰
- **æœåŠ¡å™¨**ï¼š$100/æœˆï¼ˆAWS EC2ï¼‰
- **æ€»æˆæœ¬**ï¼š$350/æœˆ
- **èŠ‚çœå¼€å‘æ—¶é—´**ï¼š50å°æ—¶/æœˆ
- **ROI**ï¼š1400%

<div data-chart='{"type": "echarts", "options": {"title": {"text": "å¼€å‘æ•ˆç‡æˆæœ¬åˆ†æ"}, "tooltip": {}, "legend": {"data": ["åŸç”Ÿå¼€å‘", "LangChain"]}, "xAxis": {"type": "category", "data": ["å¼€å‘æ—¶é—´", "ç»´æŠ¤æˆæœ¬", "æ€»æˆæœ¬"]}, "yAxis": {"type": "value", "name": "æˆæœ¬(ç¾å…ƒ/æœˆ)"}, "series": [{"name": "åŸç”Ÿå¼€å‘", "type": "bar", "data": [2000, 800, 2800]}, {"name": "LangChain", "type": "bar", "data": [500, 350, 850]}]}}'></div>

## 5. ç”Ÿäº§éƒ¨ç½²æ–¹æ¡ˆ

**DockeråŒ–éƒ¨ç½²**ï¼š
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY src/ ./src/
COPY config/ ./config/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV LANGCHAIN_TRACING_V2=true
ENV LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"

EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Kuberneteséƒ¨ç½²**ï¼š
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langchain-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: langchain-app
  template:
    metadata:
      labels:
        app: langchain-app
    spec:
      containers:
      - name: langchain-app
        image: langchain-app:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
```

## 6. æˆ‘çš„è¸©å‘æ€»ç»“ï¼ˆ5ä¸ªå¿…çœ‹ï¼‰

### å‘1ï¼šç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
**ç—‡çŠ¶**ï¼šä¸åŒç»„ä»¶ç‰ˆæœ¬å†²çª
**è§£å†³**ï¼šé”å®šç‰ˆæœ¬å¹¶å®šæœŸæ›´æ–°
```python
# requirements.txt ç‰ˆæœ¬é”å®š
langchain==0.1.20
langchain-openai==0.1.7
```

### å‘2ï¼šå†…å­˜æ³„æ¼
**ç—‡çŠ¶**ï¼šé•¿æ—¶é—´è¿è¡Œåå†…å­˜å ç”¨æŒç»­å¢åŠ 
**è§£å†³**ï¼šå®šæœŸæ¸…ç†ç¼“å­˜å’Œä¼šè¯
```python
# å†…å­˜ç®¡ç†
import gc
from langchain.memory import ConversationBufferWindowMemory

memory = ConversationBufferWindowMemory(k=10)  # é™åˆ¶å†å²è®°å½•
gc.collect()  # å®šæœŸåƒåœ¾å›æ”¶
```

### å‘3ï¼šAPIè°ƒç”¨é¢‘ç‡é™åˆ¶
**è§£å†³**ï¼šå®ç°é‡è¯•æœºåˆ¶å’Œé€Ÿç‡é™åˆ¶
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def call_llm_with_retry(prompt):
    return llm.invoke(prompt)
```

### å‘4ï¼šä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
**è§£å†³**ï¼šæ™ºèƒ½æˆªæ–­å’Œæ‘˜è¦
```python
def truncate_context(messages, max_tokens=4000):
    """æ™ºèƒ½æˆªæ–­ä¸Šä¸‹æ–‡"""
    total_tokens = sum(len(str(m)) for m in messages)
    if total_tokens > max_tokens:
        # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        return messages[-10:]
    return messages
```

### å‘5ï¼šè°ƒè¯•å›°éš¾
**è§£å†³**ï¼šä½¿ç”¨LangSmithè¿›è¡Œè¿½è¸ª
```python
# LangSmithé…ç½®
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_API_KEY"] = "your-langsmith-key"
```

## 7. ç›‘æ§å’Œç»´æŠ¤

**å®æ—¶ç›‘æ§Dashboard**ï¼š
<div data-chart='{"type": "echarts", "options": {"title": {"text": "ç³»ç»Ÿæ€§èƒ½ç›‘æ§"}, "tooltip": {}, "legend": {"data": ["APIè°ƒç”¨æ•°", "å¹³å‡å“åº”æ—¶é—´"]}, "xAxis": {"type": "category", "data": ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”"]}, "yAxis": [{"type": "value", "name": "è°ƒç”¨æ•°"}, {"type": "value", "name": "å“åº”æ—¶é—´(ms)"}], "series": [{"name": "APIè°ƒç”¨æ•°", "type": "bar", "data": [1200, 1500, 1800, 1600, 1400]}, {"name": "å¹³å‡å“åº”æ—¶é—´", "type": "line", "yAxisIndex": 1, "data": [450, 420, 380, 400, 390]}]}}'></div>

**ç›‘æ§è„šæœ¬**ï¼š
```python
# monitor.py
from prometheus_client import Counter, Histogram, start_http_server
import time

# å®šä¹‰æŒ‡æ ‡
api_calls = Counter('langchain_api_calls_total', 'Total API calls')
response_time = Histogram('langchain_response_time_seconds', 'Response time')

def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start_time
        
        api_calls.inc()
        response_time.observe(duration)
        
        return result
    return wrapper
```

## 8. ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å—

### 8.1 ç«‹å³è¡ŒåŠ¨æ¸…å•
- [ ] **ç¬¬1æ­¥**ï¼šå¤åˆ¶æˆ‘çš„é¡¹ç›®æ¨¡æ¿ï¼Œ15åˆ†é’Ÿæ­å»ºåŸºç¡€ç¯å¢ƒ
- [ ] **ç¬¬2æ­¥**ï¼šè¿è¡Œç¤ºä¾‹ä»£ç éªŒè¯LangChainåŠŸèƒ½
- [ ] **ç¬¬3æ­¥**ï¼šé›†æˆä½ çš„ç¬¬ä¸€ä¸ªè‡ªå®šä¹‰å·¥å…·
- [ ] **ç¬¬4æ­¥**ï¼šéƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒéªŒè¯ç¨³å®šæ€§

### 8.2 è¿›é˜¶å­¦ä¹ è·¯å¾„
<div data-chart='{"type": "mermaid", "code": "journey\\n    title LangChainè¿›é˜¶è·¯å¾„\\n    section åˆçº§\\n      åŸºç¡€é“¾å¼: 5: æ–°æ‰‹\\n      å·¥å…·é›†æˆ: 4: å­¦ä¹ \\n    section ä¸­çº§\\n      Agentç³»ç»Ÿ: 3: ç†Ÿç»ƒ\\n      çŠ¶æ€ç®¡ç†: 2: ä¸“å®¶\\n    section é«˜çº§\\n      å¤šAgentåä½œ: 1: å¤§å¸ˆ"}'></div>

## 9. æ€»ç»“ï¼š30å¤©çš„æŠ•èµ„ï¼Œé•¿æœŸæŠ€æœ¯èµ„äº§

**é‡åŒ–æ”¶ç›Š**ï¼š
- âš¡ å¼€å‘æ•ˆç‡æå‡3å€
- ğŸ› ï¸ ç»´æŠ¤æˆæœ¬é™ä½70%
- ğŸ“ˆ ç³»ç»Ÿç¨³å®šæ€§æå‡åˆ°99.5%
- ğŸ¯ æ–°åŠŸèƒ½ä¸Šçº¿æ—¶é—´ç¼©çŸ­85%

**ç«‹å³å¼€å§‹**ï¼šå¤åˆ¶æœ¬æ–‡çš„å®Œæ•´æ–¹æ¡ˆï¼Œä»Šæ™šå°±èƒ½æ‹¥æœ‰ç”Ÿäº§çº§çš„LangChainåº”ç”¨ï¼

> **ğŸ’¡ å°è´´å£«**ï¼šä»ç®€å•çš„é“¾å¼ç»“æ„å¼€å§‹ï¼Œé€æ­¥æ„å»ºå¤æ‚çš„Agentç³»ç»Ÿã€‚è®°ä½ï¼Œæœ€å¥½çš„å­¦ä¹ æ–¹å¼æ˜¯åŠ¨æ‰‹å®è·µï¼

**ä¸‹ä¸€æ­¥**ï¼šå®ŒæˆåŸºç¡€æ­å»ºåï¼Œå°è¯•æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªå¤šAgentåä½œç³»ç»Ÿï¼Œç„¶ååœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„ä½¿ç”¨ä½“éªŒï¼

---
*åŸºäºçœŸå®ç”Ÿäº§é¡¹ç›®ç»éªŒç¼–å†™ï¼Œæ‰€æœ‰ä»£ç ç»è¿‡ç”Ÿäº§ç¯å¢ƒéªŒè¯*
