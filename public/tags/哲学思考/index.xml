<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>哲学思考 on kingdeguo&#39;s blog</title>
    <link>https://www.kingdeguo.com/tags/%E5%93%B2%E5%AD%A6%E6%80%9D%E8%80%83/</link>
    <description>Recent content in 哲学思考 on kingdeguo&#39;s blog</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 16 Nov 2025 23:14:00 +0800</lastBuildDate>
    <atom:link href="https://www.kingdeguo.com/tags/%E5%93%B2%E5%AD%A6%E6%80%9D%E8%80%83/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>思维实验：从尼采看大语言模型边界</title>
      <link>https://www.kingdeguo.com/2025/11/16/%E6%80%9D%E7%BB%B4%E5%AE%9E%E9%AA%8C%E4%BB%8E%E5%B0%BC%E9%87%87%E7%9C%8B%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%BE%B9%E7%95%8C/</link>
      <pubDate>Sun, 16 Nov 2025 23:14:00 +0800</pubDate>
      <guid>https://www.kingdeguo.com/2025/11/16/%E6%80%9D%E7%BB%B4%E5%AE%9E%E9%AA%8C%E4%BB%8E%E5%B0%BC%E9%87%87%E7%9C%8B%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%BE%B9%E7%95%8C/</guid>
      <description>&lt;p&gt;最近几个月，朋友圈里聊得最多的，是&amp;quot;具身智能要来了&amp;quot;、&amp;ldquo;语言模型要到头了&amp;rdquo;、&amp;ldquo;下一波技术革命已经脱离文本了&amp;rdquo;。&lt;/p&gt;&#xA;&lt;p&gt;身在业务，我其实不太关心学术圈今天又发了什么论文，也不是要跟谁在显卡密度上比拼。&lt;/p&gt;&#xA;&lt;p&gt;可是语言模型在企业业务里的表现，确实慢慢露出了&amp;quot;天花板的影子&amp;quot;：越做越多的微调，越堆越大的提示词，越复杂越难的 RAG 管线……效果提升变得极慢，成本却蹭蹭往上走。&lt;/p&gt;&#xA;&lt;p&gt;今年行业里被戏称为 Agent 元年，民间甚至流传一句话：&amp;ldquo;工程优化没啥用了，不如等模型升级。&amp;ldquo;但体感上发现，模型升级仍在发生，但惊艳越来越少，阶跃式提升愈发罕见。&lt;/p&gt;&#xA;&lt;p&gt;就在这种时候，我想起了尼采。这个喜欢把哲学写成炸药包的人，曾经无数次提醒我们：语言不是世界本身，语言只是世界的影子。我们越相信语言，就越容易忘记这一点。&lt;/p&gt;&#xA;&lt;p&gt;于是我想试图用尼采的视角，做一个思维实验：语言模型的边界，是不是语言本身的边界？而当前 AI 的新的探索方向，又是不是在突破语言的围墙？&lt;/p&gt;&#xA;&lt;p&gt;尼采在《论真理与谎言》里说过一句特别好的可以用来解释 LLM 的话：人类在语言里生活得太久，以至于忘了语言只是隐喻，而不是现实本身。这句话如果搬到今天，就是：大语言模型并不是&amp;quot;理解&amp;rdquo;，它只是在影子里跳舞。&lt;/p&gt;&#xA;&lt;p&gt;当然，影子跳得很漂亮，跳得像是理解。但只要你让它做一点跨影子操作——比如把语言映射进真实动作、真实环境、真实物理——它立刻开始露馅。&lt;/p&gt;&#xA;&lt;p&gt;这不是模型不够聪明，而是语言本身的结构在限制它。语言只能描述那些&amp;quot;已经被分类过的经验&amp;rdquo;。而世界运转的方式，往往没那么干净利落——摩擦力、偶然性、模糊性、不可描述的感受、没有名字的现象……语言压根没法完全描述。模型再强，它也是在语言的维度里做插值。这一层楼建得再华丽，楼下那片更大的地基——真实世界——依旧没有被触碰。&lt;/p&gt;&#xA;&lt;p&gt;做业务落地的人都知道一个残酷事实：LLM 很能写，但不太能干。它能生成报告，但不能保证数据精准。它能给你方案，但不能确保流程可执行。它能聊天，但不能对现场复杂性做反应。在结构化、可控、可验证的任务上——模型越大，不一定越稳定。我们像是在用一张&amp;quot;语言滤镜&amp;quot;去看业务流程。很多时候，它能让流程更顺滑；但有些时候，这个滤镜本身就遮住了问题。&lt;/p&gt;&#xA;&lt;p&gt;尼采会提醒我们：&amp;ldquo;你把语言当做真理，本身就是最大的误解。&amp;ldquo;反过来讲：如果语言不是全部，那基于语言的智能，也就不可能是全部。&lt;/p&gt;&#xA;&lt;p&gt;有人马上会举手：不是早就让大模型&amp;quot;动手&amp;quot;了吗？ReAct、Function Call、Tool-use、ChatGPT 插件商店，甚至 AutoGPT，都在把&amp;quot;说&amp;quot;翻译成&amp;quot;做&amp;rdquo;。给模型一个搜索 API，它能自己查资料；给它一个下单接口，它真能帮你买机票。&lt;/p&gt;&#xA;&lt;p&gt;看起来语言模型已经长出胳膊了。但仔细观察，这些&amp;quot;行动&amp;quot;都绕不开两步：第一步，先把工具抽象成一段文本说明书——函数名、参数、返回值，全是语言；第二步，模型依旧只在语言空间里做&amp;quot;下一步该调用哪个函数&amp;quot;的概率选择，真正去拧螺丝、点鼠标、走物理流程的，是外面那层被封装好的小工蜂。&lt;/p&gt;&#xA;&lt;p&gt;换句话说，模型还是站在玻璃后面，用&amp;quot;语言手柄&amp;quot;遥控世界；手柄再长，玻璃还在。&lt;/p&gt;&#xA;&lt;p&gt;世界给出的实时摩擦力、阻尼、意外误差，被 API 的返回值阉割成了几行 JSON，再回传给模型。误差被阉割，反馈就失真，下一轮决策就继续飘在语言层。只要系统里出现 API 没覆盖的异常——快递延迟、网络丢包、机械臂打滑——整条链就断给你看。&lt;/p&gt;&#xA;&lt;p&gt;所以 ReAct 们解决的是&amp;quot;把语言模型连到数字世界的插座&amp;rdquo;，而不是&amp;quot;让模型长出自己的皮肤去蹭真实世界的粗糙&amp;quot;。插座再多，也替代不了肉身。&lt;/p&gt;&#xA;&lt;p&gt;这就回到尼采那句老话：语言只是隐喻。API 也是隐喻，而且是更狡猾的隐喻——它让开发者误以为&amp;quot;已经接地&amp;quot;，其实接的是一层薄薄的语义锡箔，一戳就破。&lt;/p&gt;&#xA;&lt;p&gt;真正难的是下一步：让模型的参数里直接编码&amp;quot;我把杯子摔到地上会碎&amp;quot;的因果，而不是&amp;quot;读到过很多句子说杯子会碎&amp;quot;。前者需要持续的动作–感官–后果闭环，后者只需要文本统计。文本统计再膨胀，也统计不出玻璃碴子的锋利温度。&lt;/p&gt;&#xA;&lt;p&gt;Yann LeCun 已决定近期离职 Meta，计划创业主攻世界模型。这不是更大的语言模型，而是带因果、带时间、带物理、带行动反馈的智能系统——脱离&amp;quot;语言影子&amp;quot;的智能。&lt;/p&gt;&#xA;&lt;p&gt;谷歌的 Genie 3、腾讯 HunyuanWorld-Voyager 与伯克利 LWM 等最新发布，也都在尝试实时交互、环境感知和因果推演，可见业界正形成共识：语言模型的极限，就是语言本身的极限；继续堆大模型，功效比会急剧下降。相比之下，如果让模型去&amp;quot;做&amp;quot;，而不是去&amp;quot;说&amp;quot;，它突然获得了一个全新的坐标系：反馈、试错、物理约束、环境复杂性。这是语言模型永远无法从文本中学到的东西。&lt;/p&gt;&#xA;&lt;p&gt;如果把尼采搬到今天，他很可能会说：&amp;ldquo;语言模型的伟大，在于它把语言榨干了。&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;语言模型的限制，在于它只能榨语言。&amp;ldquo;这句话其实能给研发和产品团队一个很务实的启发——把 LLM 当作语言系统，而不是世界系统。&lt;/p&gt;&#xA;&lt;p&gt;它在抽象思考、文本结构化、文本生成、推理的线性组织、把混乱的信息变得清晰这些地方特别强。但它在面对真实世界的连续反馈、操作性的物理任务、动态、非语言式的信息、完全未知领域的探索这些地方天然弱。&lt;/p&gt;&#xA;&lt;p&gt;当我们给它布置任务时，如果方式是&amp;quot;给我解释&amp;quot;&amp;ldquo;给我总结&amp;quot;&amp;ldquo;给我判断&amp;rdquo;，它表现得像个天才；但只要任务变成&amp;quot;给我行动&amp;quot;&amp;ldquo;给我试错&amp;quot;&amp;ldquo;给我反馈循环&amp;rdquo;，它立刻掉线。这不是模型的问题，是语言的天花板。&lt;/p&gt;&#xA;&lt;p&gt;如果说大语言模型是语言智能的珠峰，那下一座山应该叫&amp;quot;世界智能&amp;rdquo;。&lt;/p&gt;&#xA;&lt;p&gt;世界模型大概会有几个核心要素：不再只靠文本——开始大量引入感知、动作、物理控制的数据；不再只做概率预测——开始建立因果模型，能够解释、预判、修正；不再只在词和词之间运算——会在&amp;quot;行为和后果&amp;quot;之间运算；不再只输出句子——会直接输出行动策略。&lt;/p&gt;&#xA;&lt;p&gt;这听起来像科幻，但实际上已经开始发生。未来的模型不是能把论文写得更好，而是能把机器人动作做得更稳；不是更会讲道理，而是更能在真实世界的混沌里生存。&lt;/p&gt;&#xA;&lt;p&gt;这也意味着另一种边界正在浮现：语言模型不会消失，但会变成&amp;quot;智能系统中的一个模块&amp;rdquo;，就像嘴巴永远还在，但人类并不是靠嘴巴生存。&lt;/p&gt;&#xA;&lt;p&gt;尼采的批判提醒我们，语言的力量很大，但它从来不是全部。大语言模型已经把&amp;quot;语言这个维度&amp;quot;极限地挖掘了一遍，我们看到了它的光辉，也看到了它的尽头。接下来要发生的，是&amp;quot;从语言走向世界&amp;quot;的跳跃——具身、因果、行动、反馈、真实物理世界的不可预测性。这是语言描述不了的，但智能必须面对。&lt;/p&gt;&#xA;&lt;p&gt;在商业世界里，这意味着：语言模型不再是业务全部的解决方案，而是一个高效的子系统。它解决认知层的问题，但执行层、决策层、模型驱动层，必须有新的东西补上。语言像是一束光，照亮了我们理解世界的方式；但世界本身比这束光更辽阔。&lt;/p&gt;&#xA;&lt;p&gt;如果说 LLM 是语言的极限，那下一步，就是开始重新面对世界本身&lt;/p&gt;</description>
    </item>
    <item>
      <title>情绪的自给自足</title>
      <link>https://www.kingdeguo.com/2025/11/11/%E6%83%85%E7%BB%AA%E7%9A%84%E8%87%AA%E7%BB%99%E8%87%AA%E8%B6%B3/</link>
      <pubDate>Tue, 11 Nov 2025 22:15:00 +0800</pubDate>
      <guid>https://www.kingdeguo.com/2025/11/11/%E6%83%85%E7%BB%AA%E7%9A%84%E8%87%AA%E7%BB%99%E8%87%AA%E8%B6%B3/</guid>
      <description>&lt;p&gt;我这周又把《悲惨世界》从书架上抽出来，想找到冉阿让临死前那句话，结果发现根本不记得页码。于是从中间随便翻开，正看到他背着马吕斯在下水道里走。那种窒息感我太熟了——不是文学意义上的窒息，是真的喘不过气。上个月我重感冒，半夜睡不着起来翻这本书，看到这段时鼻子完全堵死，只能用嘴呼吸，结果把自己读缺氧了。那一刻我觉得自己和冉阿让挺像的，都在某个又脏又臭的管道里，背着个不知道值不值得的东西，想找出口。&lt;/p&gt;&#xA;&lt;p&gt;但我没他那么坚定。我背过很多东西，比如番茄工作法攒够一百个星星换来的成就感，比如读完《纯粹理性批判》以为自己能重建世界观时的那种虚妄的骄傲。背得最重的一次是尼采，那阵子我每天早上读《查拉图斯特拉如是说》，白天在公司跟同事吵架时脑子里都闪着&amp;quot;超人&amp;quot;两个字，觉得自己在演什么末世英雄电影。结果被老板叫到会议室，他说你的PPT逻辑有问题，我当场就泄气了。超人连个PPT都搞不定。&lt;/p&gt;&#xA;&lt;p&gt;康德是更早的债。二十八岁那年我决心要&amp;quot;活得明白&amp;quot;，于是在地铁上、马桶上、失眠的夜里啃他的三大批判。我以为只要理解了&amp;quot;先验感性论&amp;quot;，就能给自己的情绪装上防火墙。后来我发现康德的日程表比他的哲学更管用——他每天下午三点半散步，风雨无阻。这不是自律，是恐惧。害怕一旦停下来，整个体系就散了。我也试过，每天下班后必须绕小区走三圈，数自己的步子。数到第三百天的时候，我忘了数，直接回家了。那天晚上我如释重负，觉得终于从康德那里毕业了。&lt;/p&gt;&#xA;&lt;p&gt;心理学是个陷阱。积极心理学让我写感恩日记，我坚持到第四十天，写了句&amp;quot;今天不想感谢任何人&amp;quot;就停了。存在主义心理学更狠，它告诉我痛苦是本体论的，是出厂设置。我听完之后躺平了三天，不是因为想通了，是因为没力气了。反正怎么折腾都痛苦，不如先睡一觉。睡着的时候没情绪，没情绪的时候最自由。&lt;/p&gt;&#xA;&lt;p&gt;身体是会告密的。有阵子我迷上&amp;quot;身心二元论&amp;quot;，觉得灵魂必须高于肉体。结果发烧到三十九度那天，我躺在床上想明白了：存在主义就是告诉你，别想多了，先喝口水。从那以后我每周跑步三次，不为健康，就为了证明自己还能控制腿。跑步的时候脑子里一片空白，只有呼吸。跑完的两个钟头里，我对外界的容忍度明显提高。身体好了，脑子才肯转。&lt;/p&gt;&#xA;&lt;p&gt;情绪这玩意儿，我现在看它就像看天气预报。我是那种出厂设置就比较阴沉的人，基准线常年在&amp;quot;还行&amp;quot;和&amp;quot;不太行&amp;quot;之间徘徊。以前不服，硬要打鸡血，结果每次都摔得更狠。后来学乖了，低于基准线的时候就承认自己是废物，啥也不干，躺平。等它自己回升。这个过程没招，没方法，没哲学，只有等。像等一锅水开，你盯着它，它就不开。&lt;/p&gt;&#xA;&lt;p&gt;前几天我又翻了翻《悲惨世界》，还是没找到冉阿让临死前那句话。但我找到了另一句，冉阿让对珂赛特说：&amp;ldquo;人必须有爱，否则世界就是一座监狱。&amp;ldquo;我读到这里的时候正在发烧，三十八度五。我心想，拉倒吧，爱不爱不知道，我先得退烧。但过了一会儿，我又觉得这话对。不是因为它对，是因为我需要它是对的。我需要相信点什么，哪怕只是发烧时的幻觉。&lt;/p&gt;&#xA;&lt;p&gt;情绪的自给自足，我现在理解就是这么回事：你得自己生产幻觉，自己消化，自己不信，自己还能接着用。不是让自己永远满电，是接受自己常常没电，然后学会在没电的状态下，也能勉强活着。不求助，不呐喊，不假装自己充满电。就瘫在那儿，等自然来电。或者干脆承认，今天就这么着了。&lt;/p&gt;&#xA;&lt;p&gt;窗外雨声很大。我没开灯，手机屏幕的光照在脸上，像另一场雨。我写下这些，但雨声让我怀疑，我到底有没有写出来。不过没关系，反正明天可能又会变。变好变坏不知道，但总归是自己的。这大概就是所谓的自给自足——自己生产，自己怀疑，自己接着用。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
